{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code analyzes Slide-TCR-Seq data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Set up environment and functions\n",
    "\n",
    "directory = '/broad/thechenlab/Fei/TCR/Data for publication/'  # Put your directory here\n",
    "\n",
    "import ast\n",
    "import bisect\n",
    "from Bio.Seq import Seq\n",
    "from collections import Counter\n",
    "import copy\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import pickle5 as pkl\n",
    "import random\n",
    "import scanpy as sc\n",
    "import scipy.sparse\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import kstest, pearsonr\n",
    "from scipy.stats import gaussian_kde as kde\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "import statsmodels\n",
    "from statistics import mean, stdev\n",
    "from statsmodels import stats\n",
    "import statsmodels.stats.multitest\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def cohens_d(c0, c1):  # c0 is test, c1 is aggregate\n",
    "    return (mean(c0) - mean(c1)) / (math.sqrt(\n",
    "        (stdev(c0)**2 + stdev(c1)**2) / 2))\n",
    "\n",
    "\n",
    "def abline(slope, intercept, ax_name=None):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    if ax_name == None:\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = intercept + slope * x_vals\n",
    "        plt.plot(x_vals, y_vals, '--')\n",
    "    else:\n",
    "        x_vals = np.array(ax_name.get_xlim())\n",
    "        y_vals = intercept + slope * x_vals\n",
    "        ax_name.plot(x_vals, y_vals, '--')\n",
    "\n",
    "\n",
    "def closest_node(node, nodes):\n",
    "    closest_index = distance.cdist([node], nodes).argmin()\n",
    "    return nodes[closest_index]\n",
    "\n",
    "\n",
    "def distance_between_points(pt1, pt2):\n",
    "    return math.sqrt((pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2)\n",
    "\n",
    "\n",
    "def switch_dict(orig_dict):\n",
    "    new_dict = {}\n",
    "    for i in orig_dict:\n",
    "        if orig_dict[i] in new_dict:\n",
    "            new_dict[orig_dict[i]].append(i)\n",
    "        else:\n",
    "            new_dict[orig_dict[i]] = [i]\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def mrna_to_protein(mrna):\n",
    "    mrna = Seq(mrna)\n",
    "    protein = mrna.translate()\n",
    "    return str(protein)\n",
    "\n",
    "\n",
    "def find_identity_of_point(meshgridx, meshgridy, Z, list_of_points):\n",
    "    identities = []\n",
    "    x_vals = list(xx[0])\n",
    "    y_vals = [y[0] for y in yy]\n",
    "    for p in list_of_points:\n",
    "        x_index = bisect.bisect_left(x_vals, float(p[0]))\n",
    "        y_index = bisect.bisect_left(y_vals, float(p[1]))\n",
    "        identities.append(Z[y_index, x_index])\n",
    "    return identities\n",
    "\n",
    "\n",
    "def generate_barcode_loc_dictionary(barcode_file,\n",
    "                                    locations_file,\n",
    "                                    old_status=False):\n",
    "    barcode_loc_dict = {}\n",
    "\n",
    "    if old_status:\n",
    "        with open(barcode_file, \"r\") as file1, open(locations_file,\n",
    "                                                    \"r\") as file2:\n",
    "            for line1, line2 in zip(file1, file2):\n",
    "                line1 = line1.rstrip(\"\\n\")\n",
    "                line2 = line2.rstrip(\"\\n\")\n",
    "                line2_split = list(line2.split(\"\\t\"))\n",
    "                barcode_loc_dict[line1] = (line2_split[1], line2_split[2])\n",
    "\n",
    "    else:\n",
    "        barcodes = []\n",
    "        with open(barcode_file, \"r\") as file1, open(locations_file,\n",
    "                                                    \"r\") as file2:\n",
    "            for line in file1:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                line = line.replace(',', '')\n",
    "                barcodes.append(line)\n",
    "\n",
    "        with open(locations_file, \"r\") as file1:\n",
    "            locations = []\n",
    "            for line in file1:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                line_split = list(line.split(\"\\t\"))\n",
    "                locations.append((line_split[1], line_split[2]))\n",
    "\n",
    "    file1.close()\n",
    "    file2.close()\n",
    "\n",
    "    for i in range(len(barcodes)):\n",
    "        barcode_loc_dict[barcodes[i]] = (float(locations[i][0]),\n",
    "                                         float(locations[i][1]))\n",
    "\n",
    "    return barcode_loc_dict\n",
    "\n",
    "\n",
    "def bc_umis_dict(clonotype_to_barcode):\n",
    "    barcodes_to_umis = {}\n",
    "    # For each clonotype\n",
    "    for tcr_clonotype in clonotype_to_barcode:\n",
    "        bc_umis_per_cl = clonotype_to_barcode[\n",
    "            tcr_clonotype]  \n",
    "\n",
    "        for read in bc_umis_per_cl:  \n",
    "            bc = read[0][0:14]\n",
    "            umi = read[1]\n",
    "            if bc not in barcodes_to_umis:  \n",
    "                barcodes_to_umis[bc] = {}\n",
    "            if umi not in barcodes_to_umis[bc]:\n",
    "                barcodes_to_umis[bc][umi] = 0\n",
    "            barcodes_to_umis[bc][umi] += 1\n",
    "\n",
    "    return barcodes_to_umis\n",
    "\n",
    "\n",
    "def hamming_distance(chaine1, chaine2):\n",
    "    sum_ct = 0\n",
    "    for c1, c2 in zip(chaine1, chaine2):\n",
    "        if c1 != c2:\n",
    "            sum_ct += 1\n",
    "        if sum_ct > 1:\n",
    "            return 'Fail'\n",
    "\n",
    "    if sum_ct == 1:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def clonotype_to_spatial(clonotype_to_barcode,\n",
    "                         barcode_to_spatial,\n",
    "                         display_missed_barcodes=True,\n",
    "                         hamming_correction=True,\n",
    "                         verbose=False):\n",
    "    cl_to_spatial = {}\n",
    "    # For each clonotype\n",
    "    print(len(clonotype_to_barcode), 'total to analyze')\n",
    "\n",
    "    hamming_dict = {}\n",
    "\n",
    "    errors = []\n",
    "    for tcr_clonotype in tqdm(clonotype_to_barcode):\n",
    "        missed_barcodes = []\n",
    "        bc_umis_per_cl = clonotype_to_barcode[\n",
    "            tcr_clonotype] \n",
    "\n",
    "        if tcr_clonotype not in cl_to_spatial:  \n",
    "            cl_to_spatial[tcr_clonotype] = []\n",
    "\n",
    "        all_barcodes = list(set(barcode_to_spatial))\n",
    "        all_barcodes_firsthalf = {}\n",
    "        all_barcodes_secondhalf = {}\n",
    "        for bc in all_barcodes:\n",
    "            if bc[0:7] not in all_barcodes_firsthalf:\n",
    "                all_barcodes_firsthalf[bc[0:7]] = []\n",
    "            all_barcodes_firsthalf[bc[0:7]].append(bc)\n",
    "            if bc[7:] not in all_barcodes_secondhalf:\n",
    "                all_barcodes_secondhalf[bc[7:]] = []\n",
    "            all_barcodes_secondhalf[bc[7:]].append(bc)\n",
    "\n",
    "        for read in bc_umis_per_cl: \n",
    "            bc = read[0][0:14]\n",
    "            if bc in barcode_to_spatial:\n",
    "                cl_to_spatial[tcr_clonotype].append(\n",
    "                    barcode_to_spatial[bc])  \n",
    "                continue\n",
    "            elif bc not in barcode_to_spatial:  \n",
    "                if display_missed_barcodes:\n",
    "                    if bc not in missed_barcodes:\n",
    "                        print(bc,\n",
    "                              \" was not found in in situ barcode sequencing\")\n",
    "                        missed_barcodes.append(bc)\n",
    "\n",
    "                if hamming_correction:\n",
    "                    all_barcodes_searchspace = []\n",
    "                    if bc[7:] in all_barcodes_secondhalf:\n",
    "                        all_barcodes_searchspace = all_barcodes_searchspace + all_barcodes_secondhalf[\n",
    "                            bc[7:]]\n",
    "                    if bc[0:7] in all_barcodes_firsthalf:\n",
    "                        all_barcodes_searchspace = all_barcodes_searchspace + all_barcodes_firsthalf[\n",
    "                            bc[0:7]]\n",
    "                    all_barcodes_pass_hamming = [\n",
    "                        bc2 for bc2 in all_barcodes_searchspace\n",
    "                        if hamming_distance(bc, bc2) == 1\n",
    "                    ]\n",
    "\n",
    "                    if len(all_barcodes_pass_hamming) > 1:\n",
    "                        if verbose:\n",
    "                            print('bc:', bc, 'match?',\n",
    "                                  all_barcodes_pass_hamming)\n",
    "                            print('error not 1 d apart')\n",
    "                        errors.append(all_barcodes_pass_hamming)\n",
    "                        continue\n",
    "                    if len(all_barcodes_pass_hamming) == 1:\n",
    "                        cl_to_spatial[tcr_clonotype].append(\n",
    "                            barcode_to_spatial[all_barcodes_pass_hamming[0]])\n",
    "\n",
    "                continue\n",
    "\n",
    "    return cl_to_spatial, errors\n",
    "\n",
    "\n",
    "def plot_tcrs(tcr_to_loc, new_fig=True):\n",
    "    print(len(list(tcr_to_loc.keys())), 'distinct clonotypes are seen.')\n",
    "\n",
    "    agg_list = [y for x in list(tcr_to_loc.values()) for y in x]\n",
    "\n",
    "    locations = set(agg_list)\n",
    "\n",
    "    x_val = [float(x[0]) for x in locations]\n",
    "    y_val = [float(y[1]) for y in locations]\n",
    "    print(len(x_val), 'total beads contain at least one tcr_a or tcr_b read.')\n",
    "    if new_fig:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "    plt.plot(x_val, y_val, 'o', markersize=5)\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cl_loc_convert_loc_cl(tcr_loc_dict):\n",
    "    loc_to_tcr = {}  # Dictionary of locations to clonotypes\n",
    "    for tcr in tcr_loc_dict:\n",
    "        loc_all = tcr_loc_dict[tcr]\n",
    "        for loc in loc_all:\n",
    "            if loc in loc_to_tcr:\n",
    "                loc_to_tcr[loc].append(tcr)\n",
    "            else:\n",
    "                loc_to_tcr[loc] = [tcr]\n",
    "\n",
    "    # Remove duplicates\n",
    "    loc_to_tcr_dedup = {}\n",
    "    for loc in loc_to_tcr:\n",
    "        loc_to_tcr_dedup[loc] = set(loc_to_tcr[loc])\n",
    "\n",
    "    return loc_to_tcr_dedup\n",
    "\n",
    "\n",
    "def bc_loc_convert_loc_bc(bc_loc_dict):\n",
    "    loc_bc_dict = {}\n",
    "    for bc in bc_loc_dict:\n",
    "        loc_all = bc_loc_dict[bc]\n",
    "\n",
    "        if loc_all not in loc_bc_dict:\n",
    "            loc_bc_dict[loc_all] = []\n",
    "\n",
    "        loc_bc_dict[loc_all].append(bc)\n",
    "\n",
    "    return loc_bc_dict\n",
    "\n",
    "\n",
    "def check_clonotype(cl_string, a_clonotypes_list, b_clonotypes_list):\n",
    "    if cl_string in a_clonotypes_list:\n",
    "        return 'a'\n",
    "    if cl_string in b_clonotypes_list:\n",
    "        return 'b'\n",
    "\n",
    "\n",
    "# Output a csv file with bead barcodes, locations, and clonotypes of tcr_a and tcr_b\n",
    "def save_to_csv(filename,\n",
    "                tcr_loc_dict,\n",
    "                clonotypes,\n",
    "                bc_umi_dict,\n",
    "                output_dataframe=True,\n",
    "                save=True):\n",
    "    loc_to_tcr = cl_loc_convert_loc_cl(\n",
    "        tcr_loc_dict)  # Convert tcr:locations to locations:tcr\n",
    "\n",
    "    # Make list of all locations\n",
    "    locations = loc_to_tcr.keys()\n",
    "    loclist = list(locations)\n",
    "\n",
    "    # Make list of all clonotypes at each location\n",
    "    clonotypes_all = []\n",
    "\n",
    "    for loc in loclist:\n",
    "        loc_to_tcr[loc]\n",
    "        clonotypes_all.append(loc_to_tcr[loc])\n",
    "\n",
    "    # Separate list of all clonotypes into tcr_a and tcr_b\n",
    "    clonotypes_a = []\n",
    "    clonotypes_b = []\n",
    "    for i in clonotypes_all:\n",
    "        insert_a = []\n",
    "        insert_b = []\n",
    "        for j in i:\n",
    "            outcome = check_clonotype(j, clonotypes['1a'], clonotypes['1b'])\n",
    "            if outcome == 'a':\n",
    "                insert_a.append(j)\n",
    "                insert_b.append('')\n",
    "            elif outcome == 'b':\n",
    "                insert_b.append(j)\n",
    "                insert_a.append('')\n",
    "\n",
    "        clonotypes_a.append(insert_a)\n",
    "        clonotypes_b.append(insert_b)\n",
    "\n",
    "    # Make list of bead_barcodes at each location\n",
    "    bead_barcodes = []\n",
    "    for i in loclist:\n",
    "        loc_bc = bc_loc_convert_loc_bc(bc_umi_dict)\n",
    "        bead_barcodes.append(loc_bc[i])\n",
    "\n",
    "    # Save as csv\n",
    "    if save:\n",
    "        with open(filename, 'w') as csvfile:\n",
    "            fieldnames = ['x', 'y', 'tcr_a', 'tcr_b', 'bead_barcodes']\n",
    "\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for i in range(len(loclist)):\n",
    "                writer.writerow({\n",
    "                    'x': loclist[i][0],\n",
    "                    'y': loclist[i][1],\n",
    "                    'tcr_a': clonotypes_a[i],\n",
    "                    'tcr_b': clonotypes_b[i],\n",
    "                    'bead_barcodes': bead_barcodes[i][0]\n",
    "                })\n",
    "\n",
    "    # Output result as dataframe\n",
    "    if output_dataframe:\n",
    "        d = {\n",
    "            'x': [i[0] for i in loclist],\n",
    "            'y': [i[1] for i in loclist],\n",
    "            'tcr_a': clonotypes_a,\n",
    "            'tcr_b': clonotypes_b,\n",
    "            'bead_barcodes': [i[0] for i in bead_barcodes]\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data=d)\n",
    "        return df\n",
    "\n",
    "\n",
    "def import_dge(dge_fn,\n",
    "               skip_lines=0,\n",
    "               print_progress=True\n",
    "               ):  # This skips the first three lines and imports a dge\n",
    "    csv.field_size_limit(sys.maxsize)\n",
    "    line_count = 0\n",
    "    new_dict = {}\n",
    "    if '.mtx' in dge_fn:\n",
    "        new_dict = scipy.io.mmread(dge_fn)\n",
    "        barcodes = list(row.keys())[1:]\n",
    "    else:\n",
    "        with open(dge_fn) as csvfile:\n",
    "\n",
    "            skip_count = 0\n",
    "            while skip_count != skip_lines:\n",
    "                next(csvfile)\n",
    "                skip_count += 1\n",
    "\n",
    "            data = csv.DictReader(csvfile, delimiter='\\t')\n",
    "\n",
    "            for row in data:\n",
    "                line_count += 1\n",
    "                new_dict[list(row.values())[0]] = [\n",
    "                    float(val) for val in list(row.values())[1:]\n",
    "                ]\n",
    "\n",
    "                if line_count % 1000 == 0 and print_progress:\n",
    "                    print(line_count)\n",
    "                    print(datetime.now())\n",
    "\n",
    "            barcodes = list(row.keys())[1:]\n",
    "\n",
    "    return new_dict, barcodes\n",
    "\n",
    "\n",
    "def dge_formatting(dge, barcodes_fn, locations_fn):\n",
    "    #dge = dge.T\n",
    "    coords_barcodes = pd.read_csv(barcodes_fn, sep='\\t', header=None)\n",
    "    coords_barcodes = [i.replace(',', '')\n",
    "                       for i in list(coords_barcodes[0])]  # Remove commas\n",
    "    coords_locations = pd.read_csv(locations_fn, sep='\\t', header=None)\n",
    "    coords = pd.DataFrame(coords_locations)\n",
    "    coords.set_axis(['id', 'xcoord', 'ycoord'], axis=1, inplace=True)\n",
    "    coords['barcodes'] = coords_barcodes\n",
    "    coords.set_index('barcodes', inplace=True)\n",
    "\n",
    "    barcodes_in_dge = dge.index\n",
    "    barcodes_in_coords = coords.index\n",
    "    common_barcodes = [i for i in barcodes_in_dge if i in barcodes_in_coords]\n",
    "    dge = dge.loc[common_barcodes]\n",
    "    coords = coords.loc[common_barcodes]\n",
    "\n",
    "    return dge, coords\n",
    "\n",
    "\n",
    "def find_specific_barcodes(\n",
    "        which_tcr, df_scb\n",
    "):  # df_scb is puck specific df with spatial, clonotype, and barcode\n",
    "\n",
    "    tcr_spec = df_scb[which_tcr]  # Finds all clonotypes of that tcr\n",
    "\n",
    "    tcr_spec_counter = []\n",
    "    ct = 0\n",
    "    for i in tcr_spec:\n",
    "\n",
    "        if type(i) == list:\n",
    "            cl = i\n",
    "        else:\n",
    "            cl = ast.literal_eval(i)\n",
    "        cl = [n.strip() for n in cl]\n",
    "        filt_cl = [j for j in cl if j != '']\n",
    "        if len(filt_cl) == 0:\n",
    "            tcr_spec_counter.append(-1)\n",
    "        else:\n",
    "            tcr_spec_counter.append(ct)\n",
    "        ct += 1\n",
    "\n",
    "    tcr_specific_barcodes = [\n",
    "        df_scb['bead_barcodes'][b] for b in tcr_spec_counter if b != -1\n",
    "    ]\n",
    "\n",
    "    print(len(tcr_specific_barcodes))\n",
    "    return tcr_specific_barcodes\n",
    "\n",
    "\n",
    "def open_sparse_matrix(filename, sample_abbrev):\n",
    "    sparse_matrix = scipy.sparse.load_npz(filename)\n",
    "    sparse_matrix_dense = sparse_matrix.todense()\n",
    "    sparse_matrix_dense = sparse_matrix_dense.astype(float)\n",
    "    rows_cols = pd.read_csv('{}_genenames_barcodes.csv'.format(sample_abbrev))\n",
    "    cols = list(rows_cols['Genes'])\n",
    "    cols = [ast.literal_eval(i) for i in cols][0]\n",
    "    rows = list(rows_cols['Barcodes'])\n",
    "    rows = [ast.literal_eval(i) for i in rows][0]\n",
    "    new_df = pd.DataFrame(data=sparse_matrix_dense, columns=cols, index=rows)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# Plot functions\n",
    "def plot_one_gene(gene, coords, dge_fmtd, sample_name):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.set_cmap('viridis_r')\n",
    "    plt.scatter(coords['xcoord'],\n",
    "                coords['ycoord'],\n",
    "                c=dge_fmtd[gene],\n",
    "                s=1,\n",
    "                alpha=0.7)\n",
    "    plt.axis('equal')\n",
    "    plt.vmin = 0\n",
    "    plt.title('{} in {}'.format(gene, sample_name))\n",
    "    plt.colorbar()\n",
    "    #save_result(gene)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot reads across all beads\n",
    "def plot_readcounts(coords, total_counts, sample_name):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.set_cmap('viridis_r')\n",
    "    plt.title('Read count across all beads in {}'.format(sample_name))\n",
    "    plt.scatter(coords['xcoord'],\n",
    "                coords['ycoord'],\n",
    "                c=total_counts,\n",
    "                s=0.25,\n",
    "                alpha=0.8,\n",
    "                vmax=3000)\n",
    "    plt.axis('equal')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_ticks(ticks)\n",
    "    cbar.set_ticklabels(labels)\n",
    "    plt.show()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot reads across tcr beads\n",
    "def plot_tcr_readcounts(coords, total_counts, dge_fmtd, df_cl_output,\n",
    "                        sample_name):\n",
    "    tcr_bc = list(df_cl_output['bead_barcodes'])\n",
    "    all_bc = list(dge_fmtd.index)\n",
    "    tcr_indices = [all_bc.index(i) for i in tcr_bc if i in all_bc]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.set_cmap('viridis_r')\n",
    "    plt.title(\n",
    "        'Beads with at least one TCRa or TCRb read - Read counts in {}'.format(\n",
    "            sample_name))\n",
    "    plt.scatter([coords['xcoord'][i] for i in tcr_indices],\n",
    "                [coords['ycoord'][i] for i in tcr_indices],\n",
    "                c=[total_counts[i] for i in tcr_indices],\n",
    "                s=2,\n",
    "                alpha=0.8,\n",
    "                vmax=3000)\n",
    "    plt.axis('equal')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot separate tcrs and clonotypes\n",
    "def plot_only_one_tcr_and_clonotype(coords,\n",
    "                                    dge_fmtd,\n",
    "                                    df_cl_output,\n",
    "                                    sample_name,\n",
    "                                    tcr_type,\n",
    "                                    ax=False):\n",
    "    tcr_bc = list(df_cl_output['bead_barcodes'])\n",
    "    all_bc = list(dge_fmtd.index)\n",
    "    tcr_indices = [all_bc.index(i) for i in tcr_bc if i in all_bc]\n",
    "    tcr_specific_barcodes = find_specific_barcodes(tcr_type, df_cl_output)\n",
    "    tcr_specific_indices = [\n",
    "        all_bc.index(i) for i in tcr_specific_barcodes if i in all_bc\n",
    "    ]\n",
    "    tcr_specific_barcodes = [i for i in tcr_specific_barcodes if i in all_bc]\n",
    "    tcr_clonotypes_forthis = list(df_cl_output.loc[\n",
    "        df_cl_output['bead_barcodes'].isin(tcr_specific_barcodes)][tcr_type])\n",
    "\n",
    "    tcr_clonotypes_forthis2 = []\n",
    "    for i in tcr_clonotypes_forthis:\n",
    "        if type(i) == list:\n",
    "            value = i\n",
    "        else:\n",
    "            value = ast.literal_eval(i)\n",
    "        tcr_clonotypes_forthis2.append(tuple(value))\n",
    "\n",
    "    tcr_clonotypes_forthis = tcr_clonotypes_forthis2\n",
    "\n",
    "    d = {ni: indi for indi, ni in enumerate(set(tcr_clonotypes_forthis))}\n",
    "    clis = [d[ni] for ni in tcr_clonotypes_forthis]\n",
    "\n",
    "    if len(clis) < 2:\n",
    "        clis = None\n",
    "        maxclis = None\n",
    "    else:\n",
    "        maxclis = max(clis)\n",
    "    if ax == False:\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.set_cmap('viridis_r')\n",
    "        plt.title('Beads with at least one {} read - clonotypes in {}'.format(\n",
    "            tcr_type, sample_name))\n",
    "        plt.scatter([coords['xcoord'][i] for i in tcr_specific_indices],\n",
    "                    [coords['ycoord'][i] for i in tcr_specific_indices],\n",
    "                    c=clis,\n",
    "                    s=5,\n",
    "                    alpha=1,\n",
    "                    vmax=maxclis)\n",
    "        plt.axis('equal')\n",
    "        if clis != None:\n",
    "            plt.colorbar()\n",
    "        return fig\n",
    "    else:\n",
    "        ax.scatter([coords['xcoord'][i] for i in tcr_specific_indices],\n",
    "                   [coords['ycoord'][i] for i in tcr_specific_indices],\n",
    "                   c=clis,\n",
    "                   s=5,\n",
    "                   alpha=1,\n",
    "                   vmax=maxclis,\n",
    "                   cmap='viridis_r')\n",
    "        ax.title.set_text('Beads with >=1 {} read - clonotypes in {}'.format(\n",
    "            tcr_type, sample_name))\n",
    "        ax.set_xlim(0, 6000)\n",
    "        ax.set_ylim(0, 6000)\n",
    "        return ax\n",
    "\n",
    "\n",
    "def plot_unsupervised(puck, cluster_labels):\n",
    "    bc_to_cluster_label_dict = dict(\n",
    "        zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "    loc_to_cluster_dict = {\n",
    "        puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "        for i in list(bc_to_cluster_label_dict.keys())\n",
    "    }\n",
    "    x_all = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "    y_all = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "\n",
    "    dimensions = math.ceil(cluster_num**0.5)\n",
    "    fig, ax = plt.subplots(dimensions, dimensions, figsize=(20, 20))\n",
    "\n",
    "    for clnum in range(cluster_num):\n",
    "        loc_to_cluster_dict_sub = {\n",
    "            i: loc_to_cluster_dict[i]\n",
    "            for i in loc_to_cluster_dict if loc_to_cluster_dict[i] == clnum\n",
    "        }\n",
    "        # Convert cluster numbers to color palette\n",
    "\n",
    "        x_1 = [float(i[0]) for i in loc_to_cluster_dict_sub]\n",
    "        y_1 = [float(i[1]) for i in loc_to_cluster_dict_sub]\n",
    "        c_1 = [\n",
    "            sns.color_palette(\"deep\", cluster_num)[loc_to_cluster_dict_sub[i]]\n",
    "            for i in loc_to_cluster_dict_sub\n",
    "        ]\n",
    "\n",
    "        #plt.figure(figsize = (5,5))\n",
    "        plot_c_x = math.floor(clnum / dimensions)\n",
    "        plot_c_y = clnum % dimensions\n",
    "        #ax = plt.subplots(plot_c_x,plot_c_y,clnum+1)\n",
    "        ax[plot_c_x, plot_c_y].scatter(x_all,\n",
    "                                       y_all,\n",
    "                                       c='gray',\n",
    "                                       s=0.5,\n",
    "                                       alpha=0.1)\n",
    "        ax[plot_c_x, plot_c_y].scatter(x_1,\n",
    "                                       y_1,\n",
    "                                       c=c_1,\n",
    "                                       s=0.5,\n",
    "                                       alpha=1,\n",
    "                                       vmax=max(c_1))\n",
    "        ax[plot_c_x, plot_c_y].set_title('Cluster {}'.format(clnum))\n",
    "        ax[plot_c_x, plot_c_y].set_xlim(0, 6000)\n",
    "        ax[plot_c_x, plot_c_y].set_ylim(0, 6000)\n",
    "        ax[plot_c_x, plot_c_y].axis('off')\n",
    "\n",
    "    # Convert cluster numbers to color palette\n",
    "    x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "    y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "    c_1 = [\n",
    "        sns.color_palette(\"deep\", cluster_num)[loc_to_cluster_dict[i]]\n",
    "        for i in loc_to_cluster_dict\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(x_1, y_1, c=c_1, s=0.5, alpha=1, vmax=max(c_1))\n",
    "    plt.title('Cluster assignments on bead')\n",
    "    plt.xlim(0, 6000)\n",
    "    plt.ylim(0, 6000)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "def save_as_sparse(filename, abbrev_sample_reference, skip_lines=0):\n",
    "    new_dict, barcodes = import_dge(filename, skip_lines, print_progress=True)\n",
    "    df_dge = pd.DataFrame(data=new_dict, index=barcodes)\n",
    "    df_dge.index.name = 'barcodes'\n",
    "    dge_fmtd = df_dge\n",
    "    cols = [list(dge_fmtd.columns)]\n",
    "    rows = [list(dge_fmtd.index)]\n",
    "    f = pd.DataFrame({'Genes': cols, 'Barcodes': rows})\n",
    "    f.to_csv('{}_genenames_barcodes.csv'.format(abbrev_sample_reference),\n",
    "             header=True,\n",
    "             index=False)\n",
    "    rows_cols = pd.read_csv(\n",
    "        '{}_genenames_barcodes.csv'.format(abbrev_sample_reference),\n",
    "        header=None,\n",
    "        names=['Genes', 'Barcodes'])\n",
    "    array = dge_fmtd.values\n",
    "    sparse_matrix = scipy.sparse.csc_matrix(array)\n",
    "    scipy.sparse.save_npz(\n",
    "        '{}_sparse_matrix.npz'.format(abbrev_sample_reference), sparse_matrix)\n",
    "\n",
    "\n",
    "def read_in_clonotypes(sample_name, fastq_name, full_directory=False):\n",
    "    if full_directory == False:\n",
    "        fn1 = '{}{}_paired_clones.txt'.format(directory, sample_name)\n",
    "        fn2 = '{}{}_paired_cloneID.txt'.format(directory, sample_name)\n",
    "    if full_directory:\n",
    "        fn1 = '{}{}_paired_clones.txt'.format(directory, sample_name)\n",
    "        fn2 = '{}{}_paired_cloneID.txt'.format(directory, sample_name)\n",
    "    cloneids = pd.read_csv(fn1, sep=\"\\t\")\n",
    "    readids = pd.read_csv(fn2, sep=\"\\t\", error_bad_lines=False)\n",
    "    readids = readids[(readids.topChains == 'TRB') |\n",
    "                      (readids.topChains == 'TRA')]\n",
    "    cloneids = cloneids[(cloneids.topChains == 'TRB') |\n",
    "                        (cloneids.topChains == 'TRA')]\n",
    "    return cloneids, readids\n",
    "\n",
    "\n",
    "# Make readID to barcode dictionary\n",
    "# This function finds the barcodes and the UMIs from any reads that contain a TCR clonotype\n",
    "def readIDtobarcode(fastq_file_r1, up2_filter):\n",
    "    readIDtobarcode = {}\n",
    "    line_count = 0\n",
    "    all_read_count = 0\n",
    "    up2_present_ct = 0\n",
    "    up2_not_present_ct = 0\n",
    "    up2_shifted_ct = 0\n",
    "    with open(fastq_file_r1, \"r\") as file1:\n",
    "        for line1 in file1:\n",
    "            keep_this_line = False\n",
    "            if line_count % 4 == 0:  #readID name\n",
    "                line1 = line1.strip()\n",
    "                read_name = line1[1:]\n",
    "            if line_count % 4 == 1:  # This is to check if the line is the fastq sequence\n",
    "                all_read_count += 1\n",
    "                barcode = line1[0:8] + line1[26:32]\n",
    "                if line1[8:26] == 'TCTTCAGCGTTCCCGAGA':\n",
    "                    up2_present_ct += 1\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if 'TCTTCAGCGTTCCCGAGA' in line1:\n",
    "                        up2_shifted_ct += 1\n",
    "                    else:\n",
    "                        up2_not_present_ct += 1\n",
    "                    if up2_filter:\n",
    "                        line_count += 1\n",
    "                        continue\n",
    "\n",
    "                umi = line1[32:41]\n",
    "\n",
    "                readIDtobarcode[read_name] = [barcode, umi]\n",
    "            line_count += 1\n",
    "            if line_count % 1000000 == 0:\n",
    "                print(line_count)\n",
    "                print(datetime.now())\n",
    "    file1.close()\n",
    "    print('Total reads:', all_read_count)\n",
    "    print('UP2 present reads:', up2_present_ct, 'UP2 not present reads:',\n",
    "          up2_not_present_ct, '. UP2 shifted: ', up2_shifted_ct)\n",
    "    return readIDtobarcode\n",
    "\n",
    "\n",
    "def tcr_bcumi_dict_f(readbarcode, cloneids, readids):\n",
    "    aa_to_clid = {}\n",
    "    aa_to_tcr = {}\n",
    "    for index, row in cloneids.iterrows():\n",
    "        clid = row['cloneId']\n",
    "        aa_seq = row['aaSeqImputedCDR3']\n",
    "        tcr_seq = row['targetSequences']\n",
    "        if aa_seq not in aa_to_clid:\n",
    "            aa_to_clid[aa_seq] = []\n",
    "        aa_to_clid[aa_seq].append(clid)\n",
    "\n",
    "        if aa_seq not in aa_to_tcr:\n",
    "            aa_to_tcr[aa_seq] = []\n",
    "        aa_to_tcr[aa_seq].append(tcr_seq)\n",
    "\n",
    "    clid_to_r1name = {}\n",
    "    r1name_all = list(readids['descrsR1'])\n",
    "    clid_all = list(readids['cloneId'])\n",
    "    for i in tqdm(range(len(r1name_all))):\n",
    "        r1name = r1name_all[i]\n",
    "        clid = clid_all[i]\n",
    "        if clid not in clid_to_r1name:\n",
    "            clid_to_r1name[clid] = []\n",
    "\n",
    "        clid_to_r1name[clid].append(r1name)\n",
    "\n",
    "    cl_aa_to_barcode_umis = {}\n",
    "    for aa in tqdm(aa_to_clid):\n",
    "        if aa not in cl_aa_to_barcode_umis:\n",
    "            cl_aa_to_barcode_umis[aa] = []\n",
    "        for clid in aa_to_clid[aa]:\n",
    "            if clid not in clid_to_r1name:\n",
    "                continue\n",
    "            for r1name in clid_to_r1name[clid]:\n",
    "                if r1name in readbarcode:\n",
    "                    cl_aa_to_barcode_umis[aa].append(tuple(\n",
    "                        readbarcode[r1name]))\n",
    "\n",
    "    return cl_aa_to_barcode_umis\n",
    "\n",
    "\n",
    "def merge_hamming_clonotype(clonotype_dict):\n",
    "    tcrs_to_remove = []\n",
    "    hamming_sets = []\n",
    "    found = False\n",
    "    clonotype_dict_hamming = {}\n",
    "    for i in clonotype_dict:\n",
    "        found = False\n",
    "        for hset in hamming_sets:\n",
    "            for cl in hset:\n",
    "                if hamming_distance(i, cl) != 'Fail':\n",
    "                    hset.append(i)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if found:\n",
    "            continue\n",
    "        hamming_sets.append([i])\n",
    "\n",
    "    for hset in hamming_sets:\n",
    "        hset_lengths = [len(clonotype_dict[i]) for i in hset]\n",
    "        pref_clonotype = hset[hset_lengths.index(max(hset_lengths))]\n",
    "\n",
    "        clonotype_dict_hamming[pref_clonotype] = []\n",
    "        for cl in hset:\n",
    "            clonotype_dict_hamming[pref_clonotype] = clonotype_dict_hamming[\n",
    "                pref_clonotype] + clonotype_dict[cl]\n",
    "    return clonotype_dict_hamming\n",
    "\n",
    "\n",
    "def plot_variable_vs_constant(dge_output,\n",
    "                              tcr_type,\n",
    "                              tcr_loc_dict_s1,\n",
    "                              loc_to_bc_s1,\n",
    "                              human=False,\n",
    "                              cutoff=15,\n",
    "                              plot_histogram=True):\n",
    "    if tcr_type == 'tcr_b':\n",
    "        gene_name = 'Trbc2'\n",
    "    if tcr_type == 'tcr_a':\n",
    "        gene_name = 'Trac'\n",
    "    if human:\n",
    "        if tcr_type == 'tcr_b':\n",
    "            gene_name = 'TRBC2'\n",
    "        if tcr_type == 'tcr_a':\n",
    "            gene_name = 'TRAC'\n",
    "\n",
    "    bc_umis = {\n",
    "    }  #This converts dictionary to barcodes:UMIs instead of clonotypes:[bc,umi]\n",
    "    for cl in tcr_loc_dict_s1:\n",
    "        for loc in tcr_loc_dict_s1[cl]:\n",
    "            bc = loc_to_bc_s1[loc]\n",
    "            if bc not in bc_umis:\n",
    "                bc_umis[bc] = []\n",
    "            bc_umis[bc].append(loc)\n",
    "    #tcr_bc = list(df_output['bead_barcodes'])\n",
    "\n",
    "    tcr_barcodes = list(dge_output[\n",
    "        dge_output[gene_name] >= 1].index)  # all constant tcr barcodes\n",
    "\n",
    "    # for every barcode record constant counts\n",
    "    cons_counts = []\n",
    "    for j in tcr_barcodes:\n",
    "        cons_counts.append(dge_output.loc[j][gene_name])\n",
    "\n",
    "    var_counts = []  # record umi counts\n",
    "    for i in tcr_barcodes:\n",
    "        if i in bc_umis:\n",
    "            var_counts.append(len(bc_umis[i]))\n",
    "        if i not in bc_umis:\n",
    "            var_counts.append(0)\n",
    "\n",
    "    frac_count = [j / i for i, j in zip(cons_counts, var_counts)]\n",
    "\n",
    "    frac_count_adj = []\n",
    "\n",
    "    for i in frac_count:\n",
    "        if i > 0:\n",
    "            frac_count_adj.append(1)\n",
    "        else:\n",
    "            frac_count_adj.append(0)\n",
    "\n",
    "    ##### groups counts based on constant counts\n",
    "\n",
    "    t = int(max(cons_counts))  # maximum number of constant counts\n",
    "\n",
    "    output = [0] * t  # Summed beads passing test for this bin\n",
    "    counts = [0] * t  # Number of bead barcodes for each bin\n",
    "\n",
    "    for i in range(len(cons_counts)):\n",
    "        idxcount = int(cons_counts[i]) - 1\n",
    "        output[idxcount] += frac_count_adj[i]\n",
    "        counts[idxcount] += 1\n",
    "\n",
    "    frac_fin = []\n",
    "    cutoff_sum = [[], []]  #output, beads\n",
    "    for i in range(len(output)):\n",
    "        if i < cutoff:\n",
    "            if counts[i] == 0:  # If there are no beads, append 0\n",
    "                frac_fin.append(0)\n",
    "            else:\n",
    "                frac_fin.append(\n",
    "                    float(output[i]) / float(counts[i])\n",
    "                )  # number of beads passing test divided by total constant beads\n",
    "        else:\n",
    "            cutoff_sum[0].append(output[i])\n",
    "            cutoff_sum[1].append(counts[i])\n",
    "    frac_fin.append([sum(cutoff_sum[0]) / sum(cutoff_sum[1])])\n",
    "    fig, ax = plt.subplots(figsize=(cutoff, 5))\n",
    "    print(cutoff)\n",
    "    if tcr_type == 'tcr_a':\n",
    "        color_to_use = \"#9FB7CD\"\n",
    "    if tcr_type == 'tcr_b':\n",
    "        color_to_use = '#0F4C81'\n",
    "\n",
    "    ax.bar(np.array([i + 1 for i in range(cutoff + 1)]),\n",
    "           frac_fin,\n",
    "           color=color_to_use)\n",
    "    labels = [str(i) for i in counts]\n",
    "    updated_labels = []\n",
    "    for v, i in enumerate(frac_fin):\n",
    "        if v < cutoff:\n",
    "            ax.text(v + 1,\n",
    "                    1.03,\n",
    "                    labels[v],\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    rotation='vertical')\n",
    "            updated_labels.append(int(labels[v]))\n",
    "        if v == cutoff:\n",
    "            ax.text(v + 1,\n",
    "                    1.03,\n",
    "                    str(sum(cutoff_sum[1])),\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    rotation='vertical')\n",
    "            updated_labels.append(sum(cutoff_sum[1]))\n",
    "    plt.ylim([0, 1])\n",
    "    if tcr_type == 'tcr_b':\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('')\n",
    "        plt.xlabel('Number of constant reads')\n",
    "\n",
    "    else:\n",
    "        plt.ylabel('Fraction')\n",
    "        plt.ylabel('')\n",
    "        plt.yticks([])\n",
    "        plt.xlabel('')\n",
    "    plt.xticks([i + 1 for i in range(cutoff + 1)])\n",
    "    print(frac_fin)\n",
    "    if plot_histogram:\n",
    "        plt.figure(figsize=(cutoff, 1))\n",
    "        print(updated_labels)\n",
    "        plt.plot(range(len(updated_labels)), updated_labels)\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "def calculate_mixing(tcr_bcumi_dict_type, clonotype_list, verbose=False):\n",
    "    aggregate_ct_a = []\n",
    "    aggregate_ct_b = []\n",
    "    outs_a = {}\n",
    "    outs_b = {}\n",
    "    for clonotype in tcr_bcumi_dict_type:\n",
    "        if clonotype in clonotype_list['1a']:\n",
    "            clono_class = 'A'\n",
    "        elif clonotype in clonotype_list['1b']:\n",
    "            clono_class = 'B'\n",
    "        if verbose:\n",
    "            print(clono_class, clonotype)\n",
    "        mouse_spleen_bcs = list(\n",
    "            set([i[0] for i in tcr_bcumi_dict_type[clonotype]])\n",
    "            & set(bc_loc_dict_mouseS.keys()))\n",
    "        bcumis_both_spleen = [\n",
    "            i for i in set(tcr_bcumi_dict_type[clonotype])\n",
    "            if i[0] in mouse_spleen_bcs\n",
    "        ]\n",
    "        mouse_spleen = len(mouse_spleen_bcs)\n",
    "\n",
    "        mouse_brain_bcs = list(\n",
    "            set([i[0] for i in tcr_bcumi_dict_type[clonotype]])\n",
    "            & set(bc_loc_dict_mouseB.keys()))\n",
    "        bcumis_both_brain = [\n",
    "            i for i in set(tcr_bcumi_dict_type[clonotype])\n",
    "            if i[0] in mouse_brain_bcs\n",
    "        ]\n",
    "        just_bcs = [i[0] for i in bcumis_both_brain]\n",
    "        ct = Counter(\n",
    "            just_bcs\n",
    "        )  # see how many umis are on each bead barcode for mouse brain\n",
    "        if clono_class == 'A':\n",
    "            aggregate_ct_a = aggregate_ct_a + list(ct.values())\n",
    "        elif clono_class == 'B':\n",
    "            aggregate_ct_b = aggregate_ct_b + list(ct.values())\n",
    "\n",
    "        mouse_brain = len(mouse_brain_bcs)\n",
    "\n",
    "        human_bcs = list(\n",
    "            set([i[0] for i in tcr_bcumi_dict_type[clonotype]])\n",
    "            & set(bc_loc_dict_human.keys()))\n",
    "        bcumis_both_human = [\n",
    "            i for i in set(tcr_bcumi_dict_type[clonotype]) if i[0] in human_bcs\n",
    "        ]\n",
    "        human = len(human_bcs)\n",
    "\n",
    "        test1 = list(set(mouse_spleen_bcs) & set(mouse_brain_bcs))\n",
    "        test2 = list(set(mouse_brain_bcs) & set(human_bcs))\n",
    "        test3 = list(set(mouse_spleen_bcs) & set(human_bcs))\n",
    "        if verbose:\n",
    "            if len(test1) > 0:\n",
    "                print('OVERLAP!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            if len(test2) > 0:\n",
    "                print('OVERLAP!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            if len(test3) > 0:\n",
    "                print('OVERLAP!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "\n",
    "            print('Barcodes: Human', human, 'Mouse Brain', mouse_brain,\n",
    "                  'Mouse Spleen', mouse_spleen)\n",
    "            print('BC_umis: Human', len(bcumis_both_human), 'Mouse Brain',\n",
    "                  len(bcumis_both_brain), 'Mouse Spleen',\n",
    "                  len(bcumis_both_spleen))\n",
    "        all_reads = len(bcumis_both_human) + len(bcumis_both_brain) + len(\n",
    "            bcumis_both_spleen)\n",
    "        if verbose:\n",
    "            if all_reads == 0:\n",
    "                print('No Percentages')\n",
    "            else:\n",
    "                print('Percentages: Human',\n",
    "                      round(len(bcumis_both_human) / all_reads * 100,\n",
    "                            2), 'Mouse Brain',\n",
    "                      round(len(bcumis_both_brain) / all_reads * 100, 2),\n",
    "                      'Mouse Spleen',\n",
    "                      round(len(bcumis_both_spleen) / all_reads * 100, 2))\n",
    "\n",
    "        if all_reads != 0:\n",
    "            if clono_class == 'A':\n",
    "                outs_a[clonotype] = [\n",
    "                    all_reads,\n",
    "                    round(len(bcumis_both_human) / all_reads * 100, 2),\n",
    "                    round(len(bcumis_both_brain) / all_reads * 100, 2),\n",
    "                    round(len(bcumis_both_spleen) / all_reads * 100, 2)\n",
    "                ]\n",
    "            elif clono_class == 'B':\n",
    "                outs_b[clonotype] = [\n",
    "                    all_reads,\n",
    "                    round(len(bcumis_both_human) / all_reads * 100, 2),\n",
    "                    round(len(bcumis_both_brain) / all_reads * 100, 2),\n",
    "                    round(len(bcumis_both_spleen) / all_reads * 100, 2)\n",
    "                ]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(aggregate_ct_a)\n",
    "    plt.title('TCRa')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(aggregate_ct_b)\n",
    "    plt.title('TCRb')\n",
    "    plt.show()\n",
    "\n",
    "    filter_val = 10  # number of reads at minimum\n",
    "    [(i, outs_a[i]) for i in outs_a if outs_a[i][0] > filter_val\n",
    "     ]  # total and % distributions of each clonotype\n",
    "    [(i, max(outs_a[i][1:])) for i in outs_a\n",
    "     if outs_a[i][0] > filter_val]  # max % for each clonotype\n",
    "    max_pcts = [\n",
    "        max(outs_a[i][1:]) for i in outs_a if outs_a[i][0] > filter_val\n",
    "    ]  # max %\n",
    "    print('Average and STD for A', np.average(max_pcts), np.std(max_pcts))\n",
    "    df_report = pd.DataFrame.from_dict({\n",
    "        'clonotype': [i for i in outs_a if outs_a[i][0] > filter_val],\n",
    "        'total_reads':\n",
    "        [outs_a[i][0] for i in outs_a if outs_a[i][0] > filter_val],\n",
    "        'human': [outs_a[i][1] for i in outs_a if outs_a[i][0] > filter_val],\n",
    "        'mouse_brain':\n",
    "        [outs_a[i][2] for i in outs_a if outs_a[i][0] > filter_val],\n",
    "        'mouse_spleen':\n",
    "        [outs_a[i][3] for i in outs_a if outs_a[i][0] > filter_val]\n",
    "    })\n",
    "    pd.set_option('display.max_rows', df_report.shape[0] + 1)\n",
    "    display(df_report)\n",
    "\n",
    "    filter_val = 10  # number of reads at minimum\n",
    "    [(i, outs_b[i]) for i in outs_b if outs_b[i][0] > filter_val\n",
    "     ]  # total and % distributions of each clonotype\n",
    "    [(i, max(outs_b[i][1:])) for i in outs_b\n",
    "     if outs_b[i][0] > filter_val]  # max % for each clonotype\n",
    "    max_pcts = [\n",
    "        max(outs_b[i][1:]) for i in outs_b if outs_b[i][0] > filter_val\n",
    "    ]  # max %\n",
    "    print('Average and STD for B', np.average(max_pcts), np.std(max_pcts))\n",
    "    df_report = pd.DataFrame.from_dict({\n",
    "        'clonotype': [i for i in outs_b if outs_b[i][0] > filter_val],\n",
    "        'total_reads':\n",
    "        [outs_b[i][0] for i in outs_b if outs_b[i][0] > filter_val],\n",
    "        'human': [outs_b[i][1] for i in outs_b if outs_b[i][0] > filter_val],\n",
    "        'mouse_brain':\n",
    "        [outs_b[i][2] for i in outs_b if outs_b[i][0] > filter_val],\n",
    "        'mouse_spleen':\n",
    "        [outs_b[i][3] for i in outs_b if outs_b[i][0] > filter_val]\n",
    "    })\n",
    "    pd.set_option('display.max_rows', df_report.shape[0] + 1)\n",
    "    display(df_report)\n",
    "\n",
    "\n",
    "def c(l1, l2):\n",
    "    return scipy.spatial.distance.cdist(l1, l2)\n",
    "\n",
    "\n",
    "def find_le(a, x):\n",
    "    # Finds index of rightmost value less than or equal to x\n",
    "    i = bisect.bisect_right(a, x)\n",
    "    if i:\n",
    "        return i - 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def find_ge(a, x):\n",
    "    # Finds index of leftmost value greater than or equal to x\n",
    "    i = bisect.bisect_left(a, x)\n",
    "    if i <= len(a):\n",
    "        return i\n",
    "    raise ValueError\n",
    "\n",
    "\n",
    "def bc_list_to_clusters_vector(barcode_list,\n",
    "                               cell_type_list,\n",
    "                               bc_to_cluster_label_dict,\n",
    "                               verbose=False):\n",
    "    clusters = [0 for i in range(len(cell_type_list))]\n",
    "    for barcode in barcode_list:\n",
    "        if barcode not in bc_to_cluster_label_dict:\n",
    "            if verbose:\n",
    "                print(barcode, 'not in cluster labels')\n",
    "            continue\n",
    "\n",
    "        cl = bc_to_cluster_label_dict[barcode]\n",
    "        clusters[cl] += 1\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a puck class\n",
    "class PuckReplicate:\n",
    "    def __init__(self,\n",
    "                 puck_name,\n",
    "                 genome,\n",
    "                 clonotype_sample_name,\n",
    "                 clonotype_fastq_name,\n",
    "                 umi_filter_number,\n",
    "                 resave,\n",
    "                 resave_sparse=False,\n",
    "                 skip_clonotype=False):\n",
    "        self.puck_name = puck_name\n",
    "        self.abbrev_sample_reference = '_'.join(puck_name.split('_')[1:])\n",
    "        self.genome = genome\n",
    "        self.clonotype_sample_name = clonotype_sample_name\n",
    "        self.clonotype_fastq_name = clonotype_fastq_name\n",
    "        self.resave_state = resave\n",
    "\n",
    "        self.spatial_barcodes_s1 = \"{}{}_matched_bead_barcodes.txt\".format(\n",
    "            directory, self.abbrev_sample_reference)\n",
    "        self.spatial_locations_s1 = \"{}{}_matched_bead_locations.txt\".format(\n",
    "            directory, self.abbrev_sample_reference)\n",
    "        self.bc_loc_dict_s1 = generate_barcode_loc_dictionary(\n",
    "            self.spatial_barcodes_s1,\n",
    "            self.spatial_locations_s1,\n",
    "            old_status=False)\n",
    "        self.loc_to_bc_s1 = {y: x for x, y in self.bc_loc_dict_s1.items()}\n",
    "\n",
    "        if skip_clonotype == False:\n",
    "\n",
    "            if ((path.exists('cloneids_readids_{}.pickle'.format(\n",
    "                    self.puck_name)) == False) or (self.resave_state)):\n",
    "                self.cloneids, self.readids = read_in_clonotypes(\n",
    "                    sample_name=self.clonotype_sample_name,\n",
    "                    fastq_name=self.clonotype_fastq_name)\n",
    "                with open('cloneids_readids_{}.pickle'.format(self.puck_name),\n",
    "                          'wb') as handle:\n",
    "                    pkl.dump([self.cloneids, self.readids],\n",
    "                             handle,\n",
    "                             protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "            else:\n",
    "                with open('cloneids_readids_{}.pickle'.format(self.puck_name),\n",
    "                          'rb') as p_f:\n",
    "                    self.cloneids, self.readids = pkl.load(p_f)\n",
    "\n",
    "            if (path.exists('readIDtobarcode_dict_{}.pickle'.format(\n",
    "                    self.puck_name)) == False or (self.resave_state)):\n",
    "                self.readIDtobarcode_dict = readIDtobarcode(\n",
    "                    '{}{}_L001_R1_001.fastq'.format(directory,\n",
    "                                                    self.clonotype_fastq_name),\n",
    "                    up2_filter=False)\n",
    "                with open(\n",
    "                        'readIDtobarcode_dict_{}.pickle'.format(\n",
    "                            self.puck_name), 'wb') as handle:\n",
    "                    pkl.dump(self.readIDtobarcode_dict,\n",
    "                             handle,\n",
    "                             protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            else:\n",
    "                with open(\n",
    "                        'readIDtobarcode_dict_{}.pickle'.format(\n",
    "                            self.puck_name), 'rb') as p_f:\n",
    "                    self.readIDtobarcode_dict = pkl.load(p_f)\n",
    "\n",
    "            self.tcr_bcumi_dict = tcr_bcumi_dict_f(self.readIDtobarcode_dict,\n",
    "                                                   self.cloneids, self.readids)\n",
    "\n",
    "            self.clonotypes = {}\n",
    "            self.clonotypes['1a'] = list(self.cloneids[\n",
    "                self.cloneids.topChains == 'TRA'].aaSeqImputedCDR3)\n",
    "            self.clonotypes['1b'] = list(self.cloneids[\n",
    "                self.cloneids.topChains == 'TRB'].aaSeqImputedCDR3)\n",
    "\n",
    "            self.tcr_bcumi_dict_filtered = {}\n",
    "\n",
    "            for clonotype in self.tcr_bcumi_dict:\n",
    "                bcumis_deduped = list(set(\n",
    "                    self.tcr_bcumi_dict[clonotype]))  #dedup list\n",
    "                bcs_only = [i[0] for i in bcumis_deduped]  #take barcodes\n",
    "                bcs_only_cter = Counter(\n",
    "                    bcs_only)  # count unique umis per barcode\n",
    "                bcs_only_cter_pass_filter = [\n",
    "                    i for i in bcs_only_cter\n",
    "                    if bcs_only_cter[i] > umi_filter_number\n",
    "                ]  #only keep barcodes with more than one umi\n",
    "                # only keep barcodes passing the filter\n",
    "                self.tcr_bcumi_dict_filtered[clonotype] = [\n",
    "                    i for i in self.tcr_bcumi_dict[clonotype]\n",
    "                    if i[0] in bcs_only_cter_pass_filter\n",
    "                ]\n",
    "\n",
    "            self.tcr_bcumi_dict = merge_hamming_clonotype(self.tcr_bcumi_dict)\n",
    "            self.tcr_bcumi_dict_filtered = merge_hamming_clonotype(\n",
    "                self.tcr_bcumi_dict_filtered)\n",
    "\n",
    "            filename = 'tcr_loc_dict_s1_filtered_{}.pickle'.format(puck_name)\n",
    "            if (path.exists(filename) == False or (self.resave_state)):\n",
    "                self.tcr_loc_dict_s1_filtered, errors = clonotype_to_spatial(\n",
    "                    self.tcr_bcumi_dict_filtered,\n",
    "                    self.bc_loc_dict_s1,\n",
    "                    display_missed_barcodes=False,\n",
    "                    hamming_correction=True)\n",
    "                with open(filename, 'wb') as handle:\n",
    "                    pkl.dump(self.tcr_loc_dict_s1_filtered,\n",
    "                             handle,\n",
    "                             protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            else:\n",
    "                with open(filename, 'rb') as p_f:\n",
    "                    self.tcr_loc_dict_s1_filtered = pkl.load(p_f)\n",
    "\n",
    "            filename = 'tcr_loc_dict_s1_{}.pickle'.format(puck_name)\n",
    "            if (path.exists(filename) == False or (self.resave_state)):\n",
    "                self.tcr_loc_dict_s1, errors = clonotype_to_spatial(\n",
    "                    self.tcr_bcumi_dict,\n",
    "                    self.bc_loc_dict_s1,\n",
    "                    display_missed_barcodes=False,\n",
    "                    hamming_correction=True)\n",
    "                with open(filename, 'wb') as handle:\n",
    "                    pkl.dump(self.tcr_loc_dict_s1,\n",
    "                             handle,\n",
    "                             protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            else:\n",
    "                with open(filename, 'rb') as p_f:\n",
    "                    self.tcr_loc_dict_s1 = pkl.load(p_f)\n",
    "\n",
    "            self.tcr_loc_dict_s1 = merge_hamming_clonotype(\n",
    "                self.tcr_loc_dict_s1)\n",
    "            self.tcr_loc_dict_s1_filtered = merge_hamming_clonotype(\n",
    "                self.tcr_loc_dict_s1_filtered)\n",
    "\n",
    "        if resave_sparse:\n",
    "            save_as_sparse('{}{}.digital_expression.txt'.format(\n",
    "                directory,self.abbrev_sample_reference),\n",
    "                           self.abbrev_sample_reference,\n",
    "                           skip_lines=0)\n",
    "        self.s1_dge_fmtd = open_sparse_matrix(\n",
    "            '{}{}_sparse_matrix.npz'.format(directory,\n",
    "                                            self.abbrev_sample_reference),\n",
    "            self.abbrev_sample_reference)\n",
    "        self.s1_dge_fmtd, self.s1_coords = dge_formatting(\n",
    "            self.s1_dge_fmtd, self.spatial_barcodes_s1,\n",
    "            self.spatial_locations_s1)\n",
    "        self.s1_total_counts = self.s1_dge_fmtd.sum(axis=1)\n",
    "\n",
    "        # Output a csv file with bead barcodes, locations, and clonotypes of tcr_a and tcr_b\n",
    "        if skip_clonotype == False:\n",
    "\n",
    "            if (path.exists('{}dfs1_{}.csv'.format(directory, self.puck_name))\n",
    "                    == False or (self.resave_state)):\n",
    "                self.df_s1 = save_to_csv('{}dfs1_{}.csv'.format(\n",
    "                    directory, self.puck_name),\n",
    "                                         self.tcr_loc_dict_s1,\n",
    "                                         self.clonotypes,\n",
    "                                         self.bc_loc_dict_s1,\n",
    "                                         save=True)\n",
    "            else:\n",
    "                self.df_s1 = pd.read_csv('{}dfs1_{}.csv'.format(\n",
    "                    directory, self.puck_name))  #s1, s08, s9 & _filtered mods\n",
    "\n",
    "            # BC and UMIs of constant reads\n",
    "            with open('trac_trbc2_constant_umis_{}.pickle'.format(puck_name),\n",
    "                      'rb') as p_f:\n",
    "                self.trac_trbc2_constant = pkl.load(p_f)\n",
    "\n",
    "            ### add back constant UMIs\n",
    "            if self.genome == 'hg19':\n",
    "                tcra_gene_name = 'TRAC'\n",
    "            else:\n",
    "                tcra_gene_name = 'Trac'\n",
    "            if self.genome == 'hg19':\n",
    "                tcrb_gene_name = 'TRBC2'\n",
    "            else:\n",
    "                tcrb_gene_name = 'Trbc2'\n",
    "            all_constant_bc_umis = list(\n",
    "                tuple(i)\n",
    "                for i in self.trac_trbc2_constant[tcra_gene_name]) + list(\n",
    "                    tuple(i) for i in self.trac_trbc2_constant[tcrb_gene_name])\n",
    "            all_constant_bc_umis = set(all_constant_bc_umis)\n",
    "\n",
    "            self.tcr_bcumi_dict_filt3 = {}\n",
    "\n",
    "            added_umis = 0\n",
    "            for clonotype in self.tcr_bcumi_dict:\n",
    "                bcumis_deduped = list(set(\n",
    "                    self.tcr_bcumi_dict[clonotype]))  #dedup list\n",
    "                bcs_only = [i[0] for i in bcumis_deduped]  #take barcodes\n",
    "                bcs_only_cter = Counter(\n",
    "                    bcs_only)  # count unique umis per barcode\n",
    "                bcs_only_cter_pass_filter = set([\n",
    "                    i for i in bcs_only_cter if bcs_only_cter[i] > 1\n",
    "                ])  #only keep barcodes with more than one umi\n",
    "                # only keep barcodes passing the filter\n",
    "                self.tcr_bcumi_dict_filt3[clonotype] = [\n",
    "                    i for i in self.tcr_bcumi_dict[clonotype]\n",
    "                    if i[0] in bcs_only_cter_pass_filter\n",
    "                ]\n",
    "                # for barcodes failing filter\n",
    "                bcs_only_cter_fail_filter = set([\n",
    "                    i for i in bcs_only_cter if bcs_only_cter[i] <= 1\n",
    "                ])  #only keep barcodes with more than one umi\n",
    "                self.tcr_bcumi_dict_filt3[\n",
    "                    clonotype] = self.tcr_bcumi_dict_filt3[clonotype] + [\n",
    "                        i for i in self.tcr_bcumi_dict[clonotype]\n",
    "                        if (i[0] in bcs_only_cter_fail_filter\n",
    "                            and i in all_constant_bc_umis)\n",
    "                    ]\n",
    "                added_umis += len(\n",
    "                    set([\n",
    "                        i for i in self.tcr_bcumi_dict[clonotype]\n",
    "                        if (i[0] in bcs_only_cter_fail_filter\n",
    "                            and i in all_constant_bc_umis)\n",
    "                    ]))\n",
    "            self.tcr_loc_dict_s1_filtered3, errors = clonotype_to_spatial(\n",
    "                self.tcr_bcumi_dict_filt3,\n",
    "                self.bc_loc_dict_s1,\n",
    "                display_missed_barcodes=False,\n",
    "                hamming_correction=True)\n",
    "        self.tcr_loc_dict_s1_filtered3 = merge_hamming_clonotype(\n",
    "            self.tcr_loc_dict_s1_filtered3)\n",
    "        if (path.exists('{}dfs1_filtered_{}.csv'.format(\n",
    "                directory, self.puck_name)) == False\n",
    "                or (self.resave_state)):\n",
    "            self.df_s1_filtered3 = save_to_csv('{}dfs1_filtered_{}.csv'.format(\n",
    "                directory, self.puck_name),\n",
    "                                               self.tcr_loc_dict_s1_filtered3,\n",
    "                                               self.clonotypes,\n",
    "                                               self.bc_loc_dict_s1,\n",
    "                                               save=True)\n",
    "        else:\n",
    "            self.df_s1_filtered3 = pd.read_csv('{}dfs1_filtered_{}.csv'.format(\n",
    "                directory, self.puck_name))  #s1, s08, s9 & _filtered mods\n",
    "\n",
    "        self.unsupervised_fn = '{}{}_clusterassignments.csv'.format(\n",
    "            directory, self.puck_name)\n",
    "\n",
    "        self.cluster_labels = pd.read_csv(self.unsupervised_fn)\n",
    "        cluster_num = len(list(set(self.cluster_labels.cluster)))\n",
    "        self.cluster_labels['x'] = [\n",
    "            self.bc_loc_dict_s1[bc][0] for bc in self.cluster_labels.barcode\n",
    "        ]\n",
    "        self.cluster_labels['y'] = [\n",
    "            self.bc_loc_dict_s1[bc][1] for bc in self.cluster_labels.barcode\n",
    "        ]\n",
    "\n",
    "        self.bc_to_cluster_label_dict = dict(\n",
    "            zip(self.cluster_labels.barcode, self.cluster_labels.cluster))\n",
    "        self.loc_to_cluster_dict = {\n",
    "            self.bc_loc_dict_s1[i]: self.bc_to_cluster_label_dict[i]\n",
    "            for i in list(self.bc_to_cluster_label_dict.keys())\n",
    "        }\n",
    "        self.all_locs = list(self.loc_to_bc_s1.keys())\n",
    "\n",
    "    def get_nearest_neighbors(self,\n",
    "                              n_neighbors=100,\n",
    "                              metric='euclidean',\n",
    "                              algorithm='brute'):\n",
    "        X = np.array(self.all_locs)\n",
    "        nn = NearestNeighbors(n_neighbors, metric, algorithm).fit(X)\n",
    "        self.dists, self.idxs = nn.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clonotype naming\n",
    "\n",
    "post_treatment_df = pd.read_csv(\n",
    "    '{}post_treatment_clonotype_fraction_slide_seq.csv'.format(directory)\n",
    ")  # Supplementary table with clonotype naming\n",
    "pretty_clonotype_name = dict(zip(list(post_treatment_df.clonotype),\n",
    "                    list(post_treatment_df.name)))\n",
    "\n",
    "ugly_clonotype_name = {\n",
    "    pretty_clonotype_name[i]: i\n",
    "    for i in pretty_clonotype_name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2021-04-19 17:39:28.893329\n",
      "2000000\n",
      "2021-04-19 17:39:29.784667\n",
      "3000000\n",
      "2021-04-19 17:39:30.640519\n",
      "4000000\n",
      "2021-04-19 17:39:31.454182\n",
      "5000000\n",
      "2021-04-19 17:39:32.283882\n",
      "6000000\n",
      "2021-04-19 17:39:33.235831\n",
      "7000000\n",
      "2021-04-19 17:39:34.061805\n",
      "8000000\n",
      "2021-04-19 17:39:34.893927\n",
      "9000000\n",
      "2021-04-19 17:39:35.732271\n",
      "10000000\n",
      "2021-04-19 17:39:36.572582\n",
      "11000000\n",
      "2021-04-19 17:39:37.421536\n",
      "12000000\n",
      "2021-04-19 17:39:38.439258\n",
      "13000000\n",
      "2021-04-19 17:39:39.270148\n",
      "14000000\n",
      "2021-04-19 17:39:40.097686\n",
      "15000000\n",
      "2021-04-19 17:39:40.928892\n",
      "16000000\n",
      "2021-04-19 17:39:41.759973\n",
      "17000000\n",
      "2021-04-19 17:39:42.589159\n",
      "18000000\n",
      "2021-04-19 17:39:43.610090\n",
      "19000000\n",
      "2021-04-19 17:40:05.763104\n",
      "20000000\n",
      "2021-04-19 17:40:06.610867\n",
      "21000000\n",
      "2021-04-19 17:40:07.552580\n",
      "22000000\n",
      "2021-04-19 17:40:08.411279\n",
      "23000000\n",
      "2021-04-19 17:40:09.906350\n",
      "24000000\n",
      "2021-04-19 17:40:10.734638\n",
      "25000000\n",
      "2021-04-19 17:40:11.561743\n",
      "26000000\n",
      "2021-04-19 17:40:12.383736\n",
      "27000000\n",
      "2021-04-19 17:40:13.217084\n",
      "28000000\n",
      "2021-04-19 17:40:14.046198\n",
      "29000000\n",
      "2021-04-19 17:40:14.863923\n",
      "30000000\n",
      "2021-04-19 17:40:15.695599\n",
      "31000000\n",
      "2021-04-19 17:40:16.532184\n",
      "32000000\n",
      "2021-04-19 17:40:17.370906\n",
      "33000000\n",
      "2021-04-19 17:40:18.212389\n",
      "34000000\n",
      "2021-04-19 17:40:19.052756\n",
      "35000000\n",
      "2021-04-19 17:40:19.891545\n",
      "36000000\n",
      "2021-04-19 17:40:20.738740\n",
      "37000000\n",
      "2021-04-19 17:40:21.756325\n",
      "38000000\n",
      "2021-04-19 17:40:22.607664\n",
      "39000000\n",
      "2021-04-19 17:40:23.607790\n",
      "40000000\n",
      "2021-04-19 17:40:24.456984\n",
      "41000000\n",
      "2021-04-19 17:40:25.316458\n",
      "42000000\n",
      "2021-04-19 17:40:26.180756\n",
      "43000000\n",
      "2021-04-19 17:40:27.404440\n",
      "44000000\n",
      "2021-04-19 17:40:28.265409\n",
      "45000000\n",
      "2021-04-19 17:40:29.941618\n",
      "46000000\n",
      "2021-04-19 17:40:39.690174\n",
      "47000000\n",
      "2021-04-19 17:40:40.517662\n",
      "48000000\n",
      "2021-04-19 17:40:41.342888\n",
      "49000000\n",
      "2021-04-19 17:40:42.162745\n",
      "50000000\n",
      "2021-04-19 17:40:42.985814\n",
      "51000000\n",
      "2021-04-19 17:40:43.811398\n",
      "52000000\n",
      "2021-04-19 17:40:44.642169\n",
      "53000000\n",
      "2021-04-19 17:40:45.472131\n",
      "54000000\n",
      "2021-04-19 17:40:46.301483\n",
      "55000000\n",
      "2021-04-19 17:40:47.130488\n",
      "56000000\n",
      "2021-04-19 17:40:47.964750\n",
      "57000000\n",
      "2021-04-19 17:40:48.798761\n",
      "58000000\n",
      "2021-04-19 17:40:49.631101\n",
      "59000000\n",
      "2021-04-19 17:40:50.461965\n",
      "60000000\n",
      "2021-04-19 17:40:51.294563\n",
      "61000000\n",
      "2021-04-19 17:40:52.132132\n",
      "62000000\n",
      "2021-04-19 17:40:52.972123\n",
      "63000000\n",
      "2021-04-19 17:40:53.964454\n",
      "64000000\n",
      "2021-04-19 17:40:54.800923\n",
      "65000000\n",
      "2021-04-19 17:40:55.641792\n",
      "66000000\n",
      "2021-04-19 17:40:56.483976\n",
      "67000000\n",
      "2021-04-19 17:40:57.322516\n",
      "68000000\n",
      "2021-04-19 17:40:58.161684\n",
      "69000000\n",
      "2021-04-19 17:40:59.009888\n",
      "70000000\n",
      "2021-04-19 17:40:59.858079\n",
      "71000000\n",
      "2021-04-19 17:41:00.703449\n",
      "72000000\n",
      "2021-04-19 17:41:01.552310\n",
      "73000000\n",
      "2021-04-19 17:41:02.398436\n",
      "74000000\n",
      "2021-04-19 17:41:03.247951\n",
      "75000000\n",
      "2021-04-19 17:41:04.230536\n",
      "76000000\n",
      "2021-04-19 17:41:05.078701\n",
      "77000000\n",
      "2021-04-19 17:41:05.926554\n",
      "78000000\n",
      "2021-04-19 17:41:06.778699\n",
      "79000000\n",
      "2021-04-19 17:41:19.026972\n",
      "80000000\n",
      "2021-04-19 17:41:19.878799\n",
      "81000000\n",
      "2021-04-19 17:41:20.747866\n",
      "82000000\n",
      "2021-04-19 17:41:21.614636\n",
      "83000000\n",
      "2021-04-19 17:41:22.537836\n",
      "84000000\n",
      "2021-04-19 17:41:23.439870\n",
      "85000000\n",
      "2021-04-19 17:41:24.370768\n",
      "Total reads: 21271858\n",
      "UP2 present reads: 12153523 UP2 not present reads: 8756766 . UP2 shifted:  361569\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf52e17babc944769c8fd55f18be49e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1591512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1de4689a0db40f894d4d639e020a8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 total to analyze\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce1a85608a745a781236fdc32a5dd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 total to analyze\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59c7bb240ad40f9854eeced3ae05336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2021-04-19 17:45:20.030400\n",
      "2000\n",
      "2021-04-19 17:45:46.275869\n",
      "3000\n",
      "2021-04-19 17:46:13.419425\n",
      "4000\n",
      "2021-04-19 17:46:39.753866\n",
      "5000\n",
      "2021-04-19 17:47:06.371717\n",
      "6000\n",
      "2021-04-19 17:47:33.064887\n",
      "7000\n",
      "2021-04-19 17:47:59.700906\n",
      "8000\n",
      "2021-04-19 17:48:26.069145\n",
      "9000\n",
      "2021-04-19 17:48:52.463436\n",
      "10000\n",
      "2021-04-19 17:49:19.428351\n",
      "11000\n",
      "2021-04-19 17:49:48.671335\n",
      "12000\n",
      "2021-04-19 17:50:15.302150\n",
      "13000\n",
      "2021-04-19 17:50:41.737371\n",
      "14000\n",
      "2021-04-19 17:51:08.890219\n",
      "15000\n",
      "2021-04-19 17:51:35.331113\n",
      "16000\n",
      "2021-04-19 17:52:02.053366\n",
      "17000\n",
      "2021-04-19 17:52:28.531096\n",
      "18000\n",
      "2021-04-19 17:52:55.000753\n",
      "19000\n",
      "2021-04-19 17:53:24.817785\n",
      "20000\n",
      "2021-04-19 17:53:51.231409\n"
     ]
    }
   ],
   "source": [
    "load_spleen = True\n",
    "\n",
    "# Spleen \n",
    "if load_spleen:\n",
    "    puckSpleen = PuckReplicate(puck_name='2020-08-31_Puck_200727_02', # This is the name of the Slide-seq puck\n",
    "                               genome='GRCm38.81', # This is the genome\n",
    "                               clonotype_sample_name='Merged_mouse_spleen', # This is the name of the MiXCR outputs\n",
    "                               clonotype_fastq_name='Merged_mouse_spleen2', # This is the name of the rhPCR sequencing results\n",
    "                               umi_filter_number=1, # We consider clonotypes on beads with > umi_filter_number UMIs.\n",
    "                               resave=True, # See note below\n",
    "                               resave_sparse=True) # Set note below \n",
    "\n",
    "# Set True if this is your first time running this file.\n",
    "# Otherwise you can set to False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1c - Spatial reconstruction of Slide-TCR-seq array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RCTD\n",
    "pixels_needed = 500 / 0.65\n",
    "point_size = 10\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "gray_filt = puckSpleen.s1_dge_fmtd\n",
    "plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in gray_filt.index],\n",
    "            [puckSpleen.bc_loc_dict_s1[i][1] for i in gray_filt.index],\n",
    "            s=point_size,\n",
    "            alpha=0.05,\n",
    "            c='gray')  #c=list(marco_filt['Marco']),\n",
    "\n",
    "fn = \"./spleen_rctd_clusters_aging.csv\"\n",
    "cluster_labels = pd.read_csv(fn)\n",
    "cluster_labels['cluster'] = cluster_labels['cell_label']\n",
    "cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "\n",
    "# Merge all macrophage labels\n",
    "macrophage_dict = {\n",
    "    'CD8 macrophage': 'MP',\n",
    "    'CD4 macrophage': 'MP',\n",
    "    'activated macrophage': 'MP'\n",
    "}\n",
    "cluster_labels.cell_label = [\n",
    "    macrophage_dict[i] if i in macrophage_dict else i\n",
    "    for i in cluster_labels.cell_label\n",
    "]\n",
    "cluster_labels.cluster = [\n",
    "    macrophage_dict[i] if i in macrophage_dict else i\n",
    "    for i in cluster_labels.cluster\n",
    "]\n",
    "\n",
    "groups = cluster_labels.groupby(\n",
    "    \"cell_label\"\n",
    ")  # can change to translated to visualize by translation or clonotype\n",
    "cell_type_list = list(set(cluster_labels.cluster))\n",
    "colors_to_use = [\n",
    "    sns.color_palette('deep')[idx] for idx in range(len(cell_type_list))\n",
    "]\n",
    "colors_to_use_dict = {\n",
    "    'CD8 T cell': sns.color_palette()[3],\n",
    "    'natural killer cell': sns.color_palette()[1],\n",
    "    'MP': sns.color_palette()[0],\n",
    "    'memory T cell': sns.color_palette()[5],\n",
    "    'CD4 T cell': sns.color_palette()[2],\n",
    "    'B cell': sns.color_palette()[4]\n",
    "}\n",
    "# plot MP first\n",
    "for name, group in groups:\n",
    "    if name == 'CD8 T cell':\n",
    "        continue\n",
    "    plt.scatter(group[\"x\"],\n",
    "                group[\"y\"],\n",
    "                s=point_size,\n",
    "                label=name,\n",
    "                marker='o',\n",
    "                alpha=1,\n",
    "                color=colors_to_use_dict[name])\n",
    "\n",
    "for name, group in groups:\n",
    "    if name != 'CD8 T cell':\n",
    "        continue\n",
    "    plt.scatter(group[\"x\"],\n",
    "                group[\"y\"],\n",
    "                s=point_size,\n",
    "                label=name,\n",
    "                marker='o',\n",
    "                alpha=1,\n",
    "                color=colors_to_use_dict[name])\n",
    "\n",
    "plt.title('Cluster assignments on bead')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlim([0, 6000])\n",
    "plt.ylim([0, 6000])\n",
    "plt.axis('off')\n",
    "fontprops = fm.FontProperties(size=18)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "plt.savefig('./vectorized_figures/figure1d.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_pre_rcc = False\n",
    "load_post_rcc = False\n",
    "# Post-treatment RCC\n",
    "if load_post_rcc:\n",
    "    puck8 = PuckReplicate(puck_name='2020-09-02_Puck_200727_08',\n",
    "                          genome='hg19',\n",
    "                          clonotype_sample_name='B10_8',\n",
    "                          clonotype_fastq_name='B10-8_S1',\n",
    "                          umi_filter_number=1,\n",
    "                          resave=False,\n",
    "                          resave_sparse=False)\n",
    "\n",
    "    puck9 = PuckReplicate(puck_name='2020-09-02_Puck_200727_09',\n",
    "                          genome='hg19',\n",
    "                          clonotype_sample_name='B10_9',\n",
    "                          clonotype_fastq_name='B10-9_S2',\n",
    "                          umi_filter_number=1,\n",
    "                          resave=False,\n",
    "                          resave_sparse=False)\n",
    "\n",
    "    puck10 = PuckReplicate(puck_name='2020-09-02_Puck_200727_10',\n",
    "                           genome='hg19',\n",
    "                           clonotype_sample_name='B10_10',\n",
    "                           clonotype_fastq_name='B10-10_S1',\n",
    "                           umi_filter_number=1,\n",
    "                           resave=False,\n",
    "                           resave_sparse=False)\n",
    "\n",
    "# Pre-treatment RCC\n",
    "if load_pre_rcc:\n",
    "    puck12 = PuckReplicate(puck_name='2020-09-02_Puck_200727_12',\n",
    "                           genome='hg19',\n",
    "                           clonotype_sample_name='B10_12',\n",
    "                           clonotype_fastq_name='B10-12_S1',\n",
    "                           umi_filter_number=1,\n",
    "                           resave=False,\n",
    "                           resave_sparse=False)\n",
    "\n",
    "    puck13 = PuckReplicate(puck_name='2020-09-02_Puck_200727_13',\n",
    "                           genome='hg19',\n",
    "                           clonotype_sample_name='B10_13',\n",
    "                           clonotype_fastq_name='B10-13_S2',\n",
    "                           umi_filter_number=1,\n",
    "                           resave=False,\n",
    "                           resave_sparse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell type assignments and k-means for tumor, lung, and normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate kmeans and load in cell type assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load in cell type assignments for pretreatment\n",
    "\n",
    "cluster_num_to_name_dict = {}\n",
    "cluster_num_to_name_list = [\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'Tumor',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',  \n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'Immune',  \n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None'\n",
    "]\n",
    "cluster_num_to_name_dict = {\n",
    "    idx: cluster_num_to_name_list[idx]\n",
    "    for idx in range(len(cluster_num_to_name_list))\n",
    "}\n",
    "\n",
    "fn = './Aggregated_clusterassignments_pretreatment.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "if puck == puck12:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep12']\n",
    "elif puck == puck13:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep13']\n",
    "\n",
    "cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "cluster_labels['x'] = [\n",
    "    puck.bc_loc_dict_s1[bc][0] for bc in cluster_labels.barcode\n",
    "]\n",
    "cluster_labels['y'] = [\n",
    "    puck.bc_loc_dict_s1[bc][1] for bc in cluster_labels.barcode\n",
    "]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(\n",
    "    zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "c_1 = [loc_to_cluster_dict[i] for i in loc_to_cluster_dict]\n",
    "\n",
    "loc_to_bc_s1 = {y: x for x, y in puck.bc_loc_dict_s1.items()}\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "cluster_labels['cluster_name'] = [\n",
    "    cluster_num_to_name_list[i] for i in cluster_labels.cluster\n",
    "]\n",
    "\n",
    "###### KNN Classifier\n",
    "loc_cluster_dict = {}\n",
    "loc_cluster_dict_all = {}\n",
    "cell_type_list = ['Tumor', 'Immune']\n",
    "\n",
    "\n",
    "for index, row in cluster_labels.iterrows():\n",
    "    loc_cluster_dict_all[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "    if row['cluster_name'] in cell_type_list:\n",
    "        loc_cluster_dict[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "\n",
    "unassigned_points = set(\n",
    "    [i for i in puck.all_locs if i not in list(loc_cluster_dict.keys())])\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=500)\n",
    "print('Begin classifier process')\n",
    "X = np.array(list(loc_cluster_dict.keys()))\n",
    "y = np.array(list(loc_cluster_dict.values()))\n",
    "neigh.fit(X, y)\n",
    "cl_assignment = {}\n",
    "for pt in tqdm(unassigned_points):\n",
    "    cl_assignment[pt] = neigh.predict([pt])[0]\n",
    "for pt in tqdm(loc_cluster_dict):\n",
    "    cl_assignment[pt] = neigh.predict([pt])[0]\n",
    "\n",
    "# Plots results of classifier\n",
    "testtil = []\n",
    "testtu = []\n",
    "testb = []\n",
    "for loc in cl_assignment:\n",
    "    if cl_assignment[loc] == 'Tumor':\n",
    "        testtu.append(loc)\n",
    "    if cl_assignment[loc] == 'Immune':\n",
    "        testtil.append(loc)\n",
    "\n",
    "loc_cluster_dict = copy.deepcopy(cl_assignment)\n",
    "puck.tll_loc_cluster_dict = loc_cluster_dict\n",
    "\n",
    "puck.tumor_beads = [\n",
    "    j for j in [i for i in loc_cluster_dict if loc_cluster_dict[i] == 'Tumor']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load in cell type assignments for posttreatment\n",
    "# Perform KNN to assign tumor, lung, and TIL regions\n",
    "\n",
    "use_constant_umis = True\n",
    "if use_constant_umis == False:\n",
    "    puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered\n",
    "else:\n",
    "    puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered3\n",
    "\n",
    "cluster_num_to_name_dict = {}\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'IghM B',\n",
    "    'No markers',\n",
    "    'Igll5 and Iglv3.25',\n",
    "    'No markers',  #cxcl9\n",
    "    'IghD',\n",
    "    'Iglv3.19',\n",
    "    'Ighg2',\n",
    "    'Blood',\n",
    "    'TIL Chemokines',\n",
    "    'Iglv3.1',  #ccl21\n",
    "    'Iglv8.61',\n",
    "    'Iglv3.21',\n",
    "    'Iglv1.40',\n",
    "    'Iglv3.10',\n",
    "    'Iglj3',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'IghM B',\n",
    "    'No markers',\n",
    "    'Igll5 and Iglv3.25',\n",
    "    'No markers',  \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'RBC',\n",
    "    'TIL Chemokines',\n",
    "    'B', \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "\n",
    "cluster_num_to_name_dict = {\n",
    "    idx: cluster_num_to_name_list[idx]\n",
    "    for idx in range(len(cluster_num_to_name_list))\n",
    "}\n",
    "\n",
    "fn = './Aggregated_clusterassignments.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "if puck == puck8:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep8']\n",
    "if puck == puck9:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep9']\n",
    "if puck == puck10:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep10']\n",
    "\n",
    "cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "cluster_labels['x'] = [\n",
    "    puck.bc_loc_dict_s1[bc][0] for bc in cluster_labels.barcode\n",
    "]\n",
    "cluster_labels['y'] = [\n",
    "    puck.bc_loc_dict_s1[bc][1] for bc in cluster_labels.barcode\n",
    "]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(\n",
    "    zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "c_1 = [loc_to_cluster_dict[i] for i in loc_to_cluster_dict]\n",
    "\n",
    "loc_to_bc_s1 = {y: x for x, y in puck.bc_loc_dict_s1.items()}\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "cluster_labels['cluster_name'] = [\n",
    "    cluster_num_to_name_list[i] for i in cluster_labels.cluster\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "###### KNN Classifier\n",
    "loc_cluster_dict = {}\n",
    "loc_cluster_dict_all = {}\n",
    "cell_type_list = ['Tumor', 'Lung', 'TIL Chemokines']\n",
    "#cell_type_list = ['Tumor','Normal']\n",
    "#cell_type_list = ['TumorCell_CA9','NonImmuneCell','PlasmaCell']\n",
    "\n",
    "for index, row in cluster_labels.iterrows():\n",
    "    loc_cluster_dict_all[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "    if row['cluster_name'] in cell_type_list:\n",
    "        loc_cluster_dict[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "\n",
    "unassigned_points = set(\n",
    "    [i for i in puck.all_locs if i not in list(loc_cluster_dict.keys())])\n",
    "\n",
    "neigh = KNeighborsClassifier(\n",
    "    n_neighbors=500)  # nearest neighbors was 500 for post treatment. trying 10\n",
    "print('Begin classifier process')\n",
    "X = np.array(list(loc_cluster_dict.keys()))\n",
    "y = np.array(list(loc_cluster_dict.values()))\n",
    "neigh.fit(X, y)\n",
    "cl_assignment = {}\n",
    "for pt in tqdm(unassigned_points):\n",
    "    cl_assignment[pt] = neigh.predict([pt])[0]\n",
    "for pt in tqdm(loc_cluster_dict):\n",
    "    cl_assignment[pt] = neigh.predict([pt])[0]\n",
    "\n",
    "# Plots results of classifier\n",
    "testl = []\n",
    "testtil = []\n",
    "testtu = []\n",
    "testb = []\n",
    "for loc in cl_assignment:\n",
    "    if cl_assignment[loc] == 'Lung':\n",
    "        testl.append(loc)\n",
    "    if cl_assignment[loc] == 'Tumor':\n",
    "        testtu.append(loc)\n",
    "    if cl_assignment[loc] == 'TIL Chemokines':\n",
    "        testtil.append(loc)\n",
    "\n",
    "loc_cluster_dict = copy.deepcopy(cl_assignment)\n",
    "puck.tll_loc_cluster_dict = loc_cluster_dict\n",
    "puck.tumor_beads = [\n",
    "    j for j in [i for i in loc_cluster_dict if loc_cluster_dict[i] == 'Tumor']\n",
    "]\n",
    "\n",
    "puck.loc_to_cluster_dict = loc_to_cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Perform KNN to tumor, lung, and TIL regions (check neighbors number)\n",
    "\n",
    "use_constant_umis = True\n",
    "if use_constant_umis == False:\n",
    "    puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered\n",
    "else:\n",
    "    puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered3\n",
    "\n",
    "cluster_num_to_name_dict = {}\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'IghM B',\n",
    "    'No markers',\n",
    "    'Igll5 and Iglv3.25',\n",
    "    'No markers', \n",
    "    'IghD',\n",
    "    'Iglv3.19',\n",
    "    'Ighg2',\n",
    "    'Blood',\n",
    "    'TIL Chemokines',\n",
    "    'Iglv3.1',  \n",
    "    'Iglv8.61',\n",
    "    'Iglv3.21',\n",
    "    'Iglv1.40',\n",
    "    'Iglv3.10',\n",
    "    'Iglj3',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "\n",
    "cluster_num_to_name_dict = {\n",
    "    idx: cluster_num_to_name_list[idx]\n",
    "    for idx in range(len(cluster_num_to_name_list))\n",
    "}\n",
    "\n",
    "fn = './Aggregated_clusterassignments.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "if puck == puck8:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep8']\n",
    "if puck == puck9:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep9']\n",
    "if puck == puck10:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep10']\n",
    "\n",
    "cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "cluster_labels['x'] = [\n",
    "    puck.bc_loc_dict_s1[bc][0] for bc in cluster_labels.barcode\n",
    "]\n",
    "cluster_labels['y'] = [\n",
    "    puck.bc_loc_dict_s1[bc][1] for bc in cluster_labels.barcode\n",
    "]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(\n",
    "    zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "c_1 = [loc_to_cluster_dict[i] for i in loc_to_cluster_dict]\n",
    "\n",
    "loc_to_bc_s1 = {y: x for x, y in puck.bc_loc_dict_s1.items()}\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "cluster_labels['cluster_name'] = [\n",
    "    cluster_num_to_name_list[i] for i in cluster_labels.cluster\n",
    "]\n",
    "\n",
    "#puck.get_nearest_neighbors()\n",
    "\n",
    "###### KNN Classifier\n",
    "loc_cluster_dict = {}\n",
    "loc_cluster_dict_all = {}\n",
    "cell_type_list = ['Tumor', 'Lung', 'TIL Chemokines']\n",
    "#cell_type_list = ['Tumor','Normal']\n",
    "#cell_type_list = ['TumorCell_CA9','NonImmuneCell','PlasmaCell']\n",
    "\n",
    "for index, row in cluster_labels.iterrows():\n",
    "    loc_cluster_dict_all[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "    if row['cluster_name'] in cell_type_list:\n",
    "        loc_cluster_dict[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "\n",
    "unassigned_points = set(\n",
    "    [i for i in puck.all_locs if i not in list(loc_cluster_dict.keys())])\n",
    "\n",
    "neigh = KNeighborsClassifier(\n",
    "    n_neighbors=500) \n",
    "print('Begin classifier process')\n",
    "X = np.array(list(loc_cluster_dict.keys()))\n",
    "y = np.array(list(loc_cluster_dict.values()))\n",
    "neigh.fit(X, y)\n",
    "cl_assignment = {}\n",
    "for pt in tqdm(unassigned_points):\n",
    "    cl_assignment[pt] = neigh.predict([pt])[0]\n",
    "for pt in tqdm(loc_cluster_dict):\n",
    "    cl_assignment[pt] = neigh.predict([pt])[0]\n",
    "\n",
    "# Plots results of classifier\n",
    "testl = []\n",
    "testtil = []\n",
    "testtu = []\n",
    "testb = []\n",
    "for loc in cl_assignment:\n",
    "    if cl_assignment[loc] == 'Lung':\n",
    "        testl.append(loc)\n",
    "    if cl_assignment[loc] == 'Tumor':\n",
    "        testtu.append(loc)\n",
    "    if cl_assignment[loc] == 'TIL Chemokines':\n",
    "        testtil.append(loc)\n",
    "#     if cl_assignment[loc] == 'B':\n",
    "#         testb.append(loc)\n",
    "\n",
    "# plt.scatter([i[0] for i in testb],[i[1] for i in testb],label='B',s=0.5)\n",
    "#plt.legend()\n",
    "\n",
    "loc_cluster_dict = copy.deepcopy(cl_assignment)\n",
    "puck.tll_loc_cluster_dict = loc_cluster_dict\n",
    "\n",
    "puck.tumor_beads = [\n",
    "    j for j in [i for i in loc_cluster_dict if loc_cluster_dict[i] == 'Tumor']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boundaries on all pucks\n",
    "\n",
    "for puck in tqdm([puck8]):  #puck8,puck9,puck10\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    puck.tumor_beads = [\n",
    "        j for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "        ]\n",
    "    ]\n",
    "    puck.til_beads = [\n",
    "        j for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "        ]\n",
    "    ]\n",
    "    puck.lung_beads = [\n",
    "        j for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    plt.scatter([i[0] for i in puck.tumor_beads],\n",
    "                [i[1] for i in puck.tumor_beads],\n",
    "                label='tumor',\n",
    "                s=0.5,\n",
    "                alpha=1,\n",
    "                color=sns.color_palette()[0])\n",
    "    plt.scatter([i[0] for i in puck.til_beads], [i[1] for i in puck.til_beads],\n",
    "                label='tll',\n",
    "                s=0.5,\n",
    "                alpha=1,\n",
    "                color=sns.color_palette()[1])\n",
    "    plt.scatter([i[0] for i in puck.lung_beads],\n",
    "                [i[1] for i in puck.lung_beads],\n",
    "                label='lung',\n",
    "                s=0.5,\n",
    "                alpha=1,\n",
    "                color=sns.color_palette()[2])\n",
    "\n",
    "    plt.axis('off')\n",
    "    fontprops = fm.FontProperties(size=18)\n",
    "    scalebar = AnchoredSizeBar(ax.transData,\n",
    "                               pixels_needed,\n",
    "                               '',\n",
    "                               'lower right',\n",
    "                               pad=0.1,\n",
    "                               color='black',\n",
    "                               frameon=False,\n",
    "                               size_vertical=1,\n",
    "                               fontproperties=fontprops)\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    plt.savefig('./vectorized_figures/figure2g_{}.pdf'.format(puck.puck_name))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save or load pucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Build normalized DGE as part of saved pucks\n",
    "puck = puck9\n",
    "puck.s1_dge_fmtd_norm = puck.s1_dge_fmtd.div(puck.s1_dge_fmtd.sum(axis=1),\n",
    "                                             axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save or load pucks that you have been analyzing\n",
    "\n",
    "save = False  # Set to true if you want to re-save everything again and false if you want to load a previously saved puck\n",
    "\n",
    "all_puck_names = [\n",
    "    '2020-09-02_Puck_200727_08',\n",
    "    '2020-09-02_Puck_200727_09',\n",
    "    '2020-09-02_Puck_200727_10',  # Post-treatment\n",
    "    '2020-08-31_Puck_200727_02',  # Spleen\n",
    "    '2020-09-02_Puck_200727_12',\n",
    "    '2020-09-02_Puck_200727_12'\n",
    "]  # Pre-treatment\n",
    "puck_name = '2020-09-02_Puck_200727_08'\n",
    "puck = puck8\n",
    "\n",
    "if save:\n",
    "    with open('{}_object.pickle'.format(puck_name), 'wb') as handle:\n",
    "        pkl.dump(puck, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('{}_object.pickle'.format(puck_name), 'rb') as handle:\n",
    "        puck8 = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Clonotype and other cell Interaction Analyses (descriptive plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# generate vector for all clonotypes\n",
    "# only looks at tcr betas, clonotypes with at least ten beads per puck\n",
    "d = 50  # distance in microns\n",
    "d = d / 0.65\n",
    "cl_cell_counter = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate nearest cell types vectors(unsupervised)\n",
    "\n",
    "cluster_num_to_name_dict = {}\n",
    "\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'B',\n",
    "    'No markers',\n",
    "    'B',\n",
    "    'No markers', \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Blood',\n",
    "    'TIL Chemokines',\n",
    "    'B',  \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "\n",
    "cluster_num_to_name_dict = {\n",
    "    idx: cluster_num_to_name_list[idx]\n",
    "    for idx in range(len(cluster_num_to_name_list))\n",
    "}\n",
    "\n",
    "fn = './Aggregated_clusterassignments.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "\n",
    "for puck in tqdm([puck8, puck9, puck10]):\n",
    "    if puck == puck8:\n",
    "        cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep8']\n",
    "    if puck == puck9:\n",
    "        cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep9']\n",
    "    if puck == puck10:\n",
    "        cluster_labels = aggregated_clusters[aggregated_clusters.rep ==\n",
    "                                             'rep10']\n",
    "\n",
    "    cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "    cluster_labels['x'] = [\n",
    "        puck.bc_loc_dict_s1[bc][0] for bc in cluster_labels.barcode\n",
    "    ]\n",
    "    cluster_labels['y'] = [\n",
    "        puck.bc_loc_dict_s1[bc][1] for bc in cluster_labels.barcode\n",
    "    ]\n",
    "\n",
    "    bc_to_cluster_label_dict = dict(\n",
    "        zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "    loc_to_cluster_dict = {\n",
    "        puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "        for i in list(bc_to_cluster_label_dict.keys())\n",
    "    }\n",
    "\n",
    "    x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "    y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "    c_1 = [loc_to_cluster_dict[i] for i in loc_to_cluster_dict]\n",
    "\n",
    "    loc_to_bc_s1 = {y: x for x, y in puck.bc_loc_dict_s1.items()}\n",
    "    loc_to_cluster_dict = {\n",
    "        puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "        for i in list(bc_to_cluster_label_dict.keys())\n",
    "    }\n",
    "\n",
    "    cluster_labels['cluster_name'] = [\n",
    "        cluster_num_to_name_list[i] for i in cluster_labels.cluster\n",
    "    ]\n",
    "\n",
    "    puck.loc_cluster_dict = loc_to_cluster_dict\n",
    "\n",
    "    # Find nearest beads and generate dictionary of normalized nearest neighbors vectors\n",
    "    # for every point\n",
    "\n",
    "    tcr_locs = []\n",
    "    for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "        for loc in set(puck.tcr_loc_dict_s1_filtered3[cl]):\n",
    "            tcr_locs.append(loc)\n",
    "    tcr_locs = list(set(tcr_locs))\n",
    "    distarray = c(tcr_locs, list(puck.loc_to_bc_s1.keys())\n",
    "                  )  # CAN CHANGE TO TUMOR BEADS FOR JUST IN TUMOR\n",
    "\n",
    "    loc_list_sort = sorted(puck.tumor_beads, key=lambda x: x[0])\n",
    "    loc_list_sort_x = [i[0] for i in loc_list_sort]\n",
    "\n",
    "    cluster_num_to_name_dict = {\n",
    "        idx: cluster_num_to_name_list[idx]\n",
    "        for idx in range(len(cluster_num_to_name_list))\n",
    "    }\n",
    "    cell_type_name_to_num_dict = {\n",
    "        cluster_num_to_name_dict[i]: i\n",
    "        for i in cluster_num_to_name_dict\n",
    "    }\n",
    "    cell_type_list = list(cluster_num_to_name_dict.keys())\n",
    "\n",
    "    tumor_beads_loc_to_index = {}\n",
    "    for i in range(len(puck.tumor_beads)):\n",
    "        tumor_beads_loc_to_index[puck.tumor_beads[i]] = i\n",
    "\n",
    "    random_tumor_dict = {}\n",
    "    for each_loc in tqdm(tcr_locs):\n",
    "\n",
    "        # Filter for x values within distance in either direction to reduce number of points needed to search.\n",
    "\n",
    "        x_lower_bound = each_loc[0] - d\n",
    "        x_upper_bound = each_loc[0] + d\n",
    "\n",
    "        locs_within_bounds = loc_list_sort[\n",
    "            find_le(loc_list_sort_x, x_lower_bound\n",
    "                    ):find_ge(loc_list_sort_x, x_upper_bound) + 1]\n",
    "        locs_within_bounds = [\n",
    "            loc for loc in locs_within_bounds\n",
    "            if ((each_loc[0] - loc[0])**2 + (each_loc[1] - loc[1])**2)**0.5 < d\n",
    "        ]\n",
    "        cl_convert = bc_list_to_clusters_vector(\n",
    "            [puck.loc_to_bc_s1[loc] for loc in locs_within_bounds],\n",
    "            cell_type_list, bc_to_cluster_label_dict)\n",
    "        random_tumor_dict[each_loc] = np.array(cl_convert)\n",
    "    puck.random_tumor_dict = random_tumor_dict\n",
    "\n",
    "    for tcr in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "        # only look at TCRbeta\n",
    "        if tcr not in puck.clonotypes['1b']:\n",
    "            continue\n",
    "        if len(set(puck.tcr_loc_dict_s1_filtered3[tcr])) < 10:\n",
    "            continue\n",
    "        if tcr not in cl_cell_counter:\n",
    "            cl_cell_counter[tcr] = np.array([0] * len(cell_type_list))\n",
    "        for loc in set(puck.tcr_loc_dict_s1_filtered3[tcr]):\n",
    "            cl_cell_counter[tcr] = cl_cell_counter[tcr] + np.array(\n",
    "                random_tumor_dict[loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate nearest cell types vectors(RCTD)\n",
    "#fn = 'rcc_rctd_clusters_{}.csv'.format(puck8.puck_name)\n",
    "fn = 'rcc_rctd_clusters_{}.csv'.format(puck13.puck_name)\n",
    "cluster_labels = pd.read_csv(fn)\n",
    "cluster_labels.rename(columns={\"cell_label\": \"cluster_name\"}, inplace=True)\n",
    "cell_type_list = list(set(cluster_labels.cluster_name))\n",
    "\n",
    "fn = 'rcc_rctd_clusters_{}.csv'.format(puck12.puck_name)\n",
    "cluster_labels = pd.read_csv(fn)\n",
    "cluster_labels.rename(columns={\"cell_label\": \"cluster_name\"}, inplace=True)\n",
    "cell_type_list = list(\n",
    "    set(cell_type_list + list(set(cluster_labels.cluster_name))))\n",
    "\n",
    "cluster_num_to_name_dict = {\n",
    "    i: cell_type_list[i]\n",
    "    for i in range(len(cell_type_list))\n",
    "}\n",
    "cluster_name_to_num_dict = {\n",
    "    cell_type_list[i]: i\n",
    "    for i in range(len(cell_type_list))\n",
    "}\n",
    "\n",
    "for puck in tqdm([puck12, puck13]):  #[puck8,puck9,puck10]\n",
    "    fn = 'rcc_rctd_clusters_{}.csv'.format(puck.puck_name)\n",
    "    cluster_labels = pd.read_csv(fn)\n",
    "    cluster_labels.rename(columns={\"cell_label\": \"cluster_name\"}, inplace=True)\n",
    "\n",
    "    barcodes = [\n",
    "        puck.loc_to_bc_s1[i, j]\n",
    "        for i, j in zip(cluster_labels.x, cluster_labels.y)\n",
    "    ]\n",
    "    cluster_num = [\n",
    "        cluster_name_to_num_dict[i] for i in cluster_labels.cluster_name\n",
    "    ]\n",
    "    cluster_labels['cluster'] = cluster_num\n",
    "    cluster_labels['barcode'] = barcodes\n",
    "    bc_to_cluster_label_dict = dict(\n",
    "        zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "    loc_to_cluster_dict = {\n",
    "        puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "        for i in list(bc_to_cluster_label_dict.keys())\n",
    "    }\n",
    "    puck.loc_cluster_dict = loc_to_cluster_dict\n",
    "\n",
    "    # Find nearest beads and generate dictionary of normalized nearest neighbors vectors\n",
    "    # for every point\n",
    "\n",
    "    tcr_locs = []\n",
    "    for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "        for loc in set(puck.tcr_loc_dict_s1_filtered3[cl]):\n",
    "            tcr_locs.append(loc)\n",
    "    tcr_locs = list(set(tcr_locs))\n",
    "    distarray = c(tcr_locs, list(puck.loc_to_bc_s1.keys())\n",
    "                  )  # CAN CHANGE TO TUMOR BEADS FOR JUST IN TUMOR\n",
    "\n",
    "    loc_list_sort = sorted(puck.tumor_beads, key=lambda x: x[0])\n",
    "    loc_list_sort_x = [i[0] for i in loc_list_sort]\n",
    "\n",
    "    tumor_beads_loc_to_index = {}\n",
    "    for i in range(len(puck.tumor_beads)):\n",
    "        tumor_beads_loc_to_index[puck.tumor_beads[i]] = i\n",
    "\n",
    "    random_tumor_dict = {}\n",
    "    for each_loc in tqdm(tcr_locs):\n",
    "\n",
    "        # Filter for x values within distance in either direction to reduce number of points needed to search.\n",
    "\n",
    "        x_lower_bound = each_loc[0] - d\n",
    "        x_upper_bound = each_loc[0] + d\n",
    "\n",
    "        locs_within_bounds = loc_list_sort[\n",
    "            find_le(loc_list_sort_x, x_lower_bound\n",
    "                    ):find_ge(loc_list_sort_x, x_upper_bound) + 1]\n",
    "        locs_within_bounds = [\n",
    "            loc for loc in locs_within_bounds\n",
    "            if ((each_loc[0] - loc[0])**2 + (each_loc[1] - loc[1])**2)**0.5 < d\n",
    "        ]\n",
    "        cl_convert = bc_list_to_clusters_vector(\n",
    "            [puck.loc_to_bc_s1[loc] for loc in locs_within_bounds],\n",
    "            cell_type_list,\n",
    "            bc_to_cluster_label_dict,\n",
    "            verbose=False)\n",
    "        random_tumor_dict[each_loc] = np.array(cl_convert)\n",
    "    puck.random_tumor_dict = random_tumor_dict\n",
    "\n",
    "    for tcr in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "        # only look at TCRbeta\n",
    "        if tcr not in puck.clonotypes['1b']:\n",
    "            continue\n",
    "        if len(set(puck.tcr_loc_dict_s1_filtered3[tcr])) < 10:\n",
    "            continue\n",
    "        if tcr not in cl_cell_counter:\n",
    "            cl_cell_counter[tcr] = np.array([0] * len(cell_type_list))\n",
    "        for loc in set(puck.tcr_loc_dict_s1_filtered3[tcr]):\n",
    "            cl_cell_counter[tcr] = cl_cell_counter[tcr] + np.array(\n",
    "                random_tumor_dict[loc])\n",
    "    puck.cluster_labels = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretty_cell_type_names = {\n",
    "    'Bcell': 'B',\n",
    "    'MastCell': 'Mast',\n",
    "    'MyeloidCell_02_CD11c_CD14': 'Myeloid CD11c CD14',\n",
    "    'Myeloid_01_CD11c': 'Myeloid CD11c',\n",
    "    'Myeloid_03_CD16': 'Myeloid CD16',\n",
    "    'Myeloid_04_CD14_CD16': 'Myeloid CD14 CD16',\n",
    "    'Myeloid_DC1_CD141': 'Myeloid DC CD141',\n",
    "    'Myeloid_pDC': 'Myeloid pDC',\n",
    "    'NK': 'NK',\n",
    "    'NKT': 'NKT',\n",
    "    'NonImmuneCell': 'Lung',\n",
    "    'PlasmaCell': 'Plasma B',\n",
    "    'Tcell_CD4': 'CD4 T',\n",
    "    'Tcell_CD8': 'CD8 T',\n",
    "    'Tcell_Treg': 'Treg',\n",
    "    'TumorCell_CA9': 'Tumor',\n",
    "    'Kidney_DistalTubule': 'Kidney',\n",
    "    'Kidney_ProximalTubule': 'Kidney',\n",
    "    'Epithelial_EPCAM': 'Epithelial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "agg_interactions = pd.DataFrame.from_dict(cl_cell_counter)\n",
    "agg_interactions.columns = [naming_dict[i] for i in agg_interactions.columns]\n",
    "agg_interactions.index = [pretty_cell_type_names[i] for i in cell_type_list]\n",
    "agg_interactions.columns\n",
    "agg_interactions_no_zero = agg_interactions.loc[(\n",
    "    agg_interactions.sum(axis=1) != 0), (agg_interactions.sum(axis=0) != 0)]\n",
    "\n",
    "# Sum same cell type rows\n",
    "#agg_interactions_no_zero = agg_interactions_no_zero.groupby(agg_interactions_no_zero.index).agg({i:sum for i in agg_interactions_no_zero.columns})\n",
    "# Drop some rows\n",
    "#agg_interactions_no_zero.drop(['Ftl','No markers','RNA28S5'],inplace=True)\n",
    "#agg_interactions_no_zero.drop(['No markers'],inplace=True)\n",
    "\n",
    "# normalize by dividing each column by sum\n",
    "for col in agg_interactions_no_zero.columns:\n",
    "    agg_interactions_no_zero[col] = agg_interactions_no_zero[col] / sum(\n",
    "        agg_interactions_no_zero[col])\n",
    "\n",
    "set_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "#sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "#sns.diverging_palette(220, 20, as_cmap=True)\n",
    "#sns.color_palette(\"icefire\", as_cmap=True)\n",
    "#\n",
    "\n",
    "agg_interactions_no_zero = agg_interactions_no_zero\n",
    "agg_interactions_no_zero.sort_index(inplace=True)\n",
    "# For post-treatment, use this:\n",
    "# g = sns.clustermap(agg_interactions_no_zero,z_score=0,\n",
    "#                yticklabels=True,\n",
    "#                xticklabels=True,\n",
    "#                cmap=set_cmap,center=0,\n",
    "#               figsize=(15,7))\n",
    "\n",
    "#For pre-treatment, use this:\n",
    "g = sns.heatmap(agg_interactions_no_zero,\n",
    "                yticklabels=True,\n",
    "                xticklabels=True,\n",
    "                cmap=set_cmap,\n",
    "                center=0)\n",
    "plt.savefig('./vectorized_figures/figure2f_clustermap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agg_interactions_no_zero_zscore = pd.DataFrame(\n",
    "    stats.zscore(agg_interactions_no_zero, axis=1, ddof=1),\n",
    "    columns=agg_interactions_no_zero.columns,\n",
    "    index=agg_interactions_no_zero.index)\n",
    "agg_interactions_no_zero_zscore = agg_interactions_no_zero_zscore.T\n",
    "agg_interactions_no_zero_zscore.sort_values('Tumor', inplace=True)\n",
    "agg_interactions_no_zero_zscore.sort_values('Tumor', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agg_interactions_no_zero_zscore = agg_interactions_no_zero_zscore[\n",
    "    agg_interactions_no_zero_zscore.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "agg_interactions_no_zero_zscore = agg_interactions_no_zero_zscore.T\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(agg_interactions_no_zero_zscore,\n",
    "            yticklabels=True,\n",
    "            xticklabels=True,\n",
    "            cmap=set_cmap,\n",
    "            center=0)\n",
    "\n",
    "plt.savefig('./vectorized_figures/figure2f_heatmap.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1 plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variable recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = [\n",
    "    'Arial', 'Tahoma', 'DejaVu Sans', 'Lucida Grande', 'Verdana'\n",
    "]\n",
    "plot_variable_vs_constant(puckSpleen.s1_dge_fmtd,\n",
    "                          'tcr_b',\n",
    "                          puckSpleen.tcr_loc_dict_s1_filtered3,\n",
    "                          puckSpleen.loc_to_bc_s1,\n",
    "                          human=False,\n",
    "                          cutoff=10,\n",
    "                          plot_histogram=False)\n",
    "plt.savefig('./vectorized_figures/figure1h_TCRb.pdf',\n",
    "            dpi=fig.dpi,\n",
    "            bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plot_variable_vs_constant(puckSpleen.s1_dge_fmtd,\n",
    "                          'tcr_a',\n",
    "                          puckSpleen.tcr_loc_dict_s1_filtered3,\n",
    "                          puckSpleen.loc_to_bc_s1,\n",
    "                          human=False,\n",
    "                          cutoff=2,\n",
    "                          plot_histogram=False)\n",
    "plt.savefig('./vectorized_figures/figure1h_TCRa_ticks.pdf',\n",
    "            dpi=fig.dpi,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot spleen RCTD cell types and pie plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_plots_one_dim = int(round(np.sqrt(len(set(cluster_labels.cluster)))))\n",
    "fig, ax = plt.subplots(num_plots_one_dim,\n",
    "                       num_plots_one_dim + 1,\n",
    "                       figsize=(9 * 2, 6 * 2))\n",
    "\n",
    "gray_filt = puckSpleen.s1_dge_fmtd\n",
    "gray_filt_x = [puckSpleen.bc_loc_dict_s1[i][0] for i in gray_filt.index]\n",
    "gray_filt_y = [puckSpleen.bc_loc_dict_s1[i][1] for i in gray_filt.index]\n",
    "\n",
    "for idx in range(len(cell_type_list)):\n",
    "    c = cell_type_list[idx]\n",
    "    x = cluster_labels[cluster_labels.cluster == c].x\n",
    "    y = cluster_labels[cluster_labels.cluster == c].y\n",
    "    ax[math.floor(idx / 3), idx % 3].scatter(gray_filt_x,\n",
    "                                             gray_filt_y,\n",
    "                                             s=3,\n",
    "                                             alpha=0.05,\n",
    "                                             c='gray')\n",
    "    ax[math.floor(idx / 3), idx % 3].scatter(x, y, s=3)\n",
    "    ax[math.floor(idx / 3), idx % 3].axis('off')\n",
    "    #ax[math.floor(idx/3),idx%3].set_title()\n",
    "\n",
    "    ######\n",
    "    fontprops = fm.FontProperties(size=18)\n",
    "    scalebar = AnchoredSizeBar(ax[math.floor(idx / 3), idx % 3].transData,\n",
    "                               pixels_needed,\n",
    "                               '',\n",
    "                               'lower right',\n",
    "                               pad=0.1,\n",
    "                               color='black',\n",
    "                               frameon=False,\n",
    "                               size_vertical=1,\n",
    "                               fontproperties=fontprops)\n",
    "\n",
    "    ax[math.floor(idx / 3), idx % 3].add_artist(scalebar)\n",
    "    ax[math.floor(idx / 3), idx % 3].set_xlim([0, 6000])\n",
    "    ax[math.floor(idx / 3), idx % 3].set_ylim([0, 6000])\n",
    "\n",
    "#plt.title('Cluster assignments on bead')\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.axis('off')\n",
    "plt.savefig(\n",
    "    './vectorized_figures/figure2_rctd_cell_type_assignment_{}.pdf'.format(\n",
    "        puckSpleen.puck_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cter = Counter(cluster_labels.cell_label)\n",
    "cell_type = list(cter.keys())\n",
    "counts = list(cter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Using matplotlib\n",
    "plot = plt.pie(counts, labels=cell_type)\n",
    "plt.savefig('./vectorized_figures/Figure1D_pie.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gene and TCR heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "color_map = plt.cm.get_cmap('Blues')\n",
    "reversed_color_map = color_map.reversed()\n",
    "\n",
    "nbins = 125\n",
    "num_bins = 100  # 100 for spleen\n",
    "\n",
    "for gene in ['Marco', 'Gypa', 'Cd8a', 'Cd4', 'Trbc2', 'Trac']:  #,\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    point_size = 20\n",
    "    gray_filt = puckSpleen.s1_dge_fmtd\n",
    "    plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in gray_filt.index],\n",
    "                [puckSpleen.bc_loc_dict_s1[i][1] for i in gray_filt.index],\n",
    "                s=point_size,\n",
    "                alpha=0.1,\n",
    "                c='gray')  #c=list(marco_filt['Marco']),\n",
    "\n",
    "    marco_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd[gene] > 0]\n",
    "    plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in marco_filt.index],\n",
    "                [puckSpleen.bc_loc_dict_s1[i][1] for i in marco_filt.index],\n",
    "                s=point_size,\n",
    "                alpha=1,\n",
    "                label=gene,\n",
    "                c='green')  #c=list(marco_filt['Marco']),\n",
    "    #plt.title('Cluster assignments on bead')\n",
    "    plt.xlim([0, 6000])\n",
    "    plt.ylim([0, 6000])\n",
    "    plt.axis('off')\n",
    "    #plt.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    marco_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd[gene] > 0]\n",
    "    x = [puckSpleen.bc_loc_dict_s1[i][0] for i in marco_filt.index]\n",
    "    y = [puckSpleen.bc_loc_dict_s1[i][1] for i in marco_filt.index]\n",
    "\n",
    "    data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "    k = kde(data.T)\n",
    "    #xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "    # Bin size\n",
    "\n",
    "    print('real life size:', (min(x) - max(x)) / num_bins * 0.65)\n",
    "\n",
    "    Z, xedges, yedges = np.histogram2d(x, y, bins=num_bins)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    Z = gaussian_filter(Z, sigma=0.5)\n",
    "    this_plot = plt.pcolormesh(xedges[:-1],\n",
    "                               yedges[:-1],\n",
    "                               Z.T,\n",
    "                               cmap=reversed_color_map,\n",
    "                               shading='gouraud',\n",
    "                               vmin=0,\n",
    "                               vmax=3)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\n",
    "        'right',\n",
    "        size=\"7%\",\n",
    "        pad=0.2,\n",
    "    )\n",
    "    cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    ax.set_xlim([0, 6000])\n",
    "    ax.set_ylim([0, 6000])\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    cbar.ax.text(0.5,\n",
    "                 -0.01,\n",
    "                 '0',\n",
    "                 transform=cbar.ax.transAxes,\n",
    "                 va='top',\n",
    "                 ha='center')\n",
    "    cbar.ax.text(0.5,\n",
    "                 1.0,\n",
    "                 '3',\n",
    "                 transform=cbar.ax.transAxes,\n",
    "                 va='bottom',\n",
    "                 ha='center')\n",
    "    cbar.outline.set_visible(False)\n",
    "    plt.savefig('./vectorized_figures/figure1f_Trbc2.pdf')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    cbar.outline.set_visible(False)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    scalebar = ScaleBar(0.65, 'um', length_fraction=.25)  # 1 pixel = 0.2 meter\n",
    "    plt.gca().add_artist(scalebar)\n",
    "    plt.savefig('./vectorized_figures/figure1e_{}.pdf'.format(gene))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Unsupervised clustering and individual clonotype plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Post-treatment\n",
    "\n",
    "## Unsupervised\n",
    "fn = './Aggregated_clusterassignments.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "if puck == puck8:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep8']\n",
    "if puck == puck9:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep9']\n",
    "if puck == puck10:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep10']\n",
    "\n",
    "cluster_labels['x'] = [\n",
    "    puck.bc_loc_dict_s1[bc][0] for bc in cluster_labels.barcode\n",
    "]\n",
    "cluster_labels['y'] = [\n",
    "    puck.bc_loc_dict_s1[bc][1] for bc in cluster_labels.barcode\n",
    "]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(\n",
    "    zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "c_1 = [loc_to_cluster_dict[i] for i in loc_to_cluster_dict]\n",
    "\n",
    "loc_to_bc_s1 = {y: x for x, y in puck.bc_loc_dict_s1.items()}\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'IghM B',\n",
    "    'No markers',\n",
    "    'Igll5 and Iglv3.25',\n",
    "    'No markers',  \n",
    "    'IghD',\n",
    "    'Iglv3.19',\n",
    "    'Ighg2',\n",
    "    'Blood',\n",
    "    'TIL Chemokines',\n",
    "    'Iglv3.1',  \n",
    "    'Iglv8.61',\n",
    "    'Iglv3.21',\n",
    "    'Iglv1.40',\n",
    "    'Iglv3.10',\n",
    "    'Iglj3',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'B',\n",
    "    'No markers',\n",
    "    'B',\n",
    "    'No markers',  \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Blood',\n",
    "    'TIL Chemokines',\n",
    "    'B',  \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'B',\n",
    "    'MGP',\n",
    "    'RNA28S5',\n",
    "    'Lung',\n",
    "    'TIL Chemokines',\n",
    "    'B',\n",
    "    'No markers',\n",
    "    'B',\n",
    "    'No markers',  \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Blood',\n",
    "    'TIL Chemokines',\n",
    "    'B',  \n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'B',\n",
    "    'Ftl',\n",
    "    'Tmsb4x'\n",
    "]\n",
    "cluster_num_to_name_list = [\n",
    "    'Tumor',\n",
    "    'Immune',\n",
    "    'No markers',\n",
    "    'No markers',\n",
    "    'Lung',\n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'No markers',\n",
    "    'Immune',\n",
    "    'No markers',  \n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'No markers',\n",
    "    'Immune',\n",
    "    'Immune',  \n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'Immune',\n",
    "    'No markers',\n",
    "    'No markers'\n",
    "]\n",
    "cluster_num_to_name_dict = {\n",
    "    idx: cluster_num_to_name_list[idx]\n",
    "    for idx in range(len(cluster_num_to_name_list))\n",
    "}\n",
    "c_1 = [cluster_num_to_name_dict[i] for i in c_1]\n",
    "cluster_labels['cluster_filtered'] = c_1\n",
    "\n",
    "dfPlot = pd.DataFrame.from_dict({'x': x_1, 'y': y_1, 'cluster': c_1})\n",
    "point_size = 8\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(list(dfPlot[dfPlot.cluster == 'No markers'].x),\n",
    "            list(dfPlot[dfPlot.cluster == 'No markers'].y),\n",
    "            color='gray',\n",
    "            alpha=0.01,\n",
    "            s=point_size)\n",
    "dfPlot = dfPlot[dfPlot.cluster != 'No markers']\n",
    "cluster_labels = cluster_labels[\n",
    "    cluster_labels.cluster_filtered != 'No markers']\n",
    "groups = cluster_labels.groupby(\n",
    "    \"cluster_filtered\"\n",
    ")  # can change to translated to visualize by translation or clonotype\n",
    "for name, group in groups:\n",
    "    if name == 'Lung':\n",
    "        color_to_use = sns.color_palette()[2]\n",
    "    if name == 'Tumor':\n",
    "        color_to_use = sns.color_palette()[0]\n",
    "    if name == 'Immune':\n",
    "        color_to_use = sns.color_palette()[1]\n",
    "\n",
    "    plt.scatter(group[\"x\"],\n",
    "                group[\"y\"],\n",
    "                s=point_size,\n",
    "                label=name,\n",
    "                marker='o',\n",
    "                alpha=1,\n",
    "                color=color_to_use)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#plt.tight_layout()\n",
    "plt.axis('off')\n",
    "\n",
    "# plt.figure()\n",
    "# # image = plt.imread(cbook.get_sample_data('grace_hopper.png'))\n",
    "# # plt.imshow(image)\n",
    "scalebar = ScaleBar(0.65, 'um', length_fraction=.25)  # 1 pixel = 0.2 meter\n",
    "plt.gca().add_artist(scalebar)\n",
    "\n",
    "plt.savefig('./vectorized_figures/figure2b_post10_scalebar.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pre-treatment\n",
    "\n",
    "puck = puck12\n",
    "\n",
    "## Unsupervised\n",
    "fn = './Aggregated_clusterassignments_pretreatment.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "if puck == puck12:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep12']\n",
    "if puck == puck13:\n",
    "    cluster_labels = aggregated_clusters[aggregated_clusters.rep == 'rep13']\n",
    "\n",
    "cluster_labels['x'] = [\n",
    "    puck.bc_loc_dict_s1[bc][0] for bc in cluster_labels.barcode\n",
    "]\n",
    "cluster_labels['y'] = [\n",
    "    puck.bc_loc_dict_s1[bc][1] for bc in cluster_labels.barcode\n",
    "]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(\n",
    "    zip(cluster_labels.barcode, cluster_labels.cluster))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "x_1 = [float(i[0]) for i in loc_to_cluster_dict]\n",
    "y_1 = [float(i[1]) for i in loc_to_cluster_dict]\n",
    "c_1 = [loc_to_cluster_dict[i] for i in loc_to_cluster_dict]\n",
    "\n",
    "loc_to_bc_s1 = {y: x for x, y in puck.bc_loc_dict_s1.items()}\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "cluster_num_to_name_list = [\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'Tumor',\n",
    "    'None',  \n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',  \n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',  \n",
    "    'Immune',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None',\n",
    "    'None'\n",
    "]\n",
    "\n",
    "cluster_num_to_name_dict = {\n",
    "    idx: cluster_num_to_name_list[idx]\n",
    "    for idx in range(len(cluster_num_to_name_list))\n",
    "}\n",
    "c_1 = [cluster_num_to_name_dict[i] for i in c_1]\n",
    "cluster_labels['cluster_filtered'] = c_1\n",
    "\n",
    "dfPlot = pd.DataFrame.from_dict({'x': x_1, 'y': y_1, 'cluster': c_1})\n",
    "point_size = 100\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "dfPlot = dfPlot[dfPlot.cluster != 'No markers']\n",
    "cluster_labels = cluster_labels[\n",
    "    cluster_labels.cluster_filtered != 'No markers']\n",
    "groups = cluster_labels.groupby(\n",
    "    \"cluster_filtered\"\n",
    ")  # can change to translated to visualize by translation or clonotype\n",
    "for name, group in groups:\n",
    "    if name == 'Tumor':\n",
    "\n",
    "        color_to_use = sns.color_palette()[0]\n",
    "    if name == 'Immune':\n",
    "        continue\n",
    "        color_to_use = sns.color_palette()[1]\n",
    "    if name == 'None':\n",
    "        plt.scatter(group[\"x\"],\n",
    "                    group[\"y\"],\n",
    "                    s=point_size,\n",
    "                    label=name,\n",
    "                    marker='o',\n",
    "                    alpha=0.01,\n",
    "                    color='gray')\n",
    "\n",
    "    else:\n",
    "        plt.scatter(group[\"x\"],\n",
    "                    group[\"y\"],\n",
    "                    s=point_size,\n",
    "                    label=name,\n",
    "                    marker='o',\n",
    "                    alpha=1,\n",
    "                    color=color_to_use)\n",
    "#     plt.title(name)\n",
    "#     plt.show()\n",
    "\n",
    "for name, group in groups:\n",
    "    if name == 'Tumor':\n",
    "        continue\n",
    "        color_to_use = sns.color_palette()[0]\n",
    "    if name == 'Immune':\n",
    "        color_to_use = sns.color_palette()[1]\n",
    "    if name == 'None':\n",
    "        plt.scatter(group[\"x\"],\n",
    "                    group[\"y\"],\n",
    "                    s=point_size,\n",
    "                    label=name,\n",
    "                    marker='o',\n",
    "                    alpha=0.01,\n",
    "                    color='gray')\n",
    "\n",
    "    else:\n",
    "        plt.scatter(group[\"x\"],\n",
    "                    group[\"y\"],\n",
    "                    s=point_size,\n",
    "                    label=name,\n",
    "                    marker='o',\n",
    "                    alpha=1,\n",
    "                    color=color_to_use)\n",
    "#     plt.title(name)\n",
    "#     plt.show()\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.axis('off')\n",
    "#plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure2b_pre12.pdf')\n",
    "plt.show()\n",
    "\n",
    "# For each cluster in unsupervised\n",
    "\n",
    "#for cluster in u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "point_size=20\n",
    "plt.scatter(list(dfPlot[dfPlot.cluster=='No markers'].x),list(dfPlot[dfPlot.cluster=='No markers'].y),\n",
    "            color='gray',alpha=0.1,s=point_size)\n",
    "dfPlot = dfPlot[dfPlot.cluster!= 'No markers']\n",
    "cluster_labels = cluster_labels[cluster_labels.cluster_filtered!='No markers']\n",
    "groups =cluster_labels.groupby(\"cluster_filtered\") # can change to translated to visualize by translation or clonotype\n",
    "for name, group in groups:\n",
    "    if name == 'Immune':\n",
    "        continue\n",
    "    if name == 'None':\n",
    "        continue\n",
    "#     if name == 'Tumor':\n",
    "#         color_to_use = sns.color_palette()[2]\n",
    "#     elif name == 'Immune':\n",
    "#         color_to_use = sns.color_palette()[0]\n",
    "    plt.scatter(group[\"x\"], group[\"y\"],s=point_size, label=name,marker = 'o',alpha = 0.7,\n",
    "               color = sns.color_palette()[0])\n",
    "#     plt.title(name)\n",
    "#     plt.show()\n",
    "for name, group in groups:\n",
    "    if name == 'Tumor':\n",
    "        continue\n",
    "    if name == 'None':\n",
    "        continue\n",
    "#     if name == 'Tumor':\n",
    "#         color_to_use = sns.color_palette()[2]\n",
    "#     elif name == 'Immune':\n",
    "#         color_to_use = sns.color_palette()[0]\n",
    "    plt.scatter(group[\"x\"], group[\"y\"],s=point_size, label=name,marker = 'o',alpha = 0.7,\n",
    "               color = sns.color_palette()[1])\n",
    "#     plt.title(name)\n",
    "#     plt.show()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck12\n",
    "clonotypes_to_plot = ['CASSMGTAYEQYF']  #CASSQGLAGVLGQFF\n",
    "#clonotypes_to_plot = ['CASSQGLAGVLGQFF']#CASSQGLAGVLGQFF\n",
    "for idx in range(len(clonotypes_to_plot)):\n",
    "    clonotype = clonotypes_to_plot[idx]\n",
    "    #####\n",
    "    loc_for_this_cl = list(set(puck.tcr_loc_dict_s1_filtered3[clonotype]))\n",
    "\n",
    "    x_val = [float(i[0]) for i in loc_for_this_cl]\n",
    "    y_val = [float(i[1]) for i in loc_for_this_cl]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    t_plotx = [\n",
    "        j[0] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "        ]\n",
    "    ]\n",
    "    t_ploty = [\n",
    "        j[1] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "        ]\n",
    "    ]\n",
    "    plt.scatter(t_plotx, t_ploty, s=0.5, alpha=0.1, label='Tumor')\n",
    "\n",
    "    til_plotx = [\n",
    "        j[0] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "        ]\n",
    "    ]\n",
    "    til_ploty = [\n",
    "        j[1] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "        ]\n",
    "    ]\n",
    "    plt.scatter(til_plotx, til_ploty, s=0.5, alpha=0.1, label='Immune')\n",
    "\n",
    "    til_plotx = [\n",
    "        j[0] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "        ]\n",
    "    ]\n",
    "    til_ploty = [\n",
    "        j[1] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "        ]\n",
    "    ]\n",
    "    plt.scatter(til_plotx, til_ploty, s=0.5, alpha=0.1, label='Lung')\n",
    "\n",
    "    plt.scatter(x_val,\n",
    "                y_val,\n",
    "                label='TCR',\n",
    "                c=sns.color_palette('hls', 3)[0],\n",
    "                edgecolors='k',\n",
    "                linewidth=1,\n",
    "                s=200)\n",
    "    plt.xlim(0, 6000)\n",
    "    plt.ylim(0, 6000)\n",
    "    plt.title(clonotype)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./vectorized_figures/figure2d_pre12.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot RCC cell types (RCTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "condensed_cell_type_names = {\n",
    "    'Bcell': 'B',\n",
    "    'MastCell': 'Mast',\n",
    "    'MyeloidCell_02_CD11c_CD14': 'Myeloid',\n",
    "    'Myeloid_01_CD11c': 'Myeloid',\n",
    "    'Myeloid_03_CD16': 'Myeloid',\n",
    "    'Myeloid_04_CD14_CD16': 'Myeloid',\n",
    "    'Myeloid_DC1_CD141': 'Myeloid',\n",
    "    'Myeloid_pDC': 'Myeloid',\n",
    "    'NK': 'NK',\n",
    "    'NKT': 'NK',\n",
    "    'NonImmuneCell': 'Lung',\n",
    "    'PlasmaCell': 'B',\n",
    "    'Tcell_CD4': 'CD4 T',\n",
    "    'Tcell_CD8': 'CD8 T',\n",
    "    'Tcell_Treg': 'Treg',\n",
    "    'TumorCell_CA9': 'Tumor',\n",
    "    'Kidney_DistalTubule': 'Kidney',\n",
    "    'Kidney_ProximalTubule': 'Kidney',\n",
    "    'Epithelial_EPCAM': 'Epithelial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot RCTD\n",
    "puck = puck8\n",
    "point_size = 3\n",
    "\n",
    "pixels_needed = 500 / 0.65\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "gray_filt = puck.s1_dge_fmtd\n",
    "plt.scatter([puck.bc_loc_dict_s1[i][0] for i in gray_filt.index],\n",
    "            [puck.bc_loc_dict_s1[i][1] for i in gray_filt.index],\n",
    "            s=point_size,\n",
    "            alpha=0.05,\n",
    "            c='gray')  #c=list(marco_filt['Marco']),\n",
    "\n",
    "fn = \"./vectorized_figures/rcc_rctd_clusters_{}.csv\".format(puck.puck_name)\n",
    "cluster_labels = pd.read_csv(fn)\n",
    "cluster_labels['cluster'] = cluster_labels['cell_label']\n",
    "\n",
    "cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "\n",
    "cell_type_list = sorted(list(set(list(condensed_cell_type_names.values()))))\n",
    "# move myeloid to position 1 for coloring and tumor to purple\n",
    "cell_type_list.remove('Myeloid')\n",
    "cell_type_list.insert(1, 'Myeloid')\n",
    "cell_type_list.remove('Tumor')\n",
    "cell_type_list.insert(7, 'Tumor')\n",
    "\n",
    "cluster_labels['condensed'] = [\n",
    "    condensed_cell_type_names[i] for i in cluster_labels['cluster']\n",
    "]\n",
    "colors_to_use_condensed = [\n",
    "    sns.color_palette('hls', len(cell_type_list))[idx]\n",
    "    for idx in range(len(cell_type_list))\n",
    "]\n",
    "\n",
    "groups = cluster_labels.groupby(\n",
    "    \"cell_label\"\n",
    ")  # can change to translated to visualize by translation or clonotype\n",
    "groups_condensed = cluster_labels.groupby(\n",
    "    \"condensed\"\n",
    ")  # can change to translated to visualize by translation or clonotype\n",
    "# for name, group in groups: #Plot tumor first\n",
    "#     if name in ['TumorCell_CA9','PlasmaCell','Bcell']:\n",
    "#         plt.scatter(group[\"x\"], group[\"y\"],s=point_size, label=name,marker = 'o',alpha = 1,color = colors_to_use[cell_type_list.index(name)])\n",
    "\n",
    "# for name, group in groups:\n",
    "#     if name not in ['TumorCell_CA9','PlasmaCell','Bcell']:\n",
    "#         plt.scatter(group[\"x\"], group[\"y\"],s=point_size, label=name,marker = 'o',alpha = 1,color = colors_to_use[cell_type_list.index(name)])\n",
    "\n",
    "# # for name, group in groups:\n",
    "# #     if name in ['Tcell_CD4','Tcell_CD8','Tcell_Treg']:\n",
    "# #         plt.scatter(group[\"x\"], group[\"y\"],s=point_size, label=name,marker = 'o',alpha = 1,color = colors_to_use[cell_type_list.index(name)])\n",
    "\n",
    "##### CONDENSED VERSIONS\n",
    "\n",
    "for name, group in groups_condensed:  #Plot tumor first\n",
    "    if name in ['Tumor', 'B']:\n",
    "        plt.scatter(group[\"x\"],\n",
    "                    group[\"y\"],\n",
    "                    s=point_size,\n",
    "                    label=name,\n",
    "                    marker='o',\n",
    "                    alpha=1,\n",
    "                    color=colors_to_use_condensed[cell_type_list.index(name)])\n",
    "\n",
    "for name, group in groups_condensed:\n",
    "    if name not in ['Tumor', 'B']:\n",
    "        plt.scatter(group[\"x\"],\n",
    "                    group[\"y\"],\n",
    "                    s=point_size,\n",
    "                    label=name,\n",
    "                    marker='o',\n",
    "                    alpha=1,\n",
    "                    color=colors_to_use_condensed[cell_type_list.index(name)])\n",
    "\n",
    "######\n",
    "fontprops = fm.FontProperties(size=18)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.title('Cluster assignments on bead')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.axis('off')\n",
    "plt.savefig(\n",
    "    './vectorized_figures/figure2_rctd_cell_type_assignment_{}.pdf'.format(\n",
    "        puck.puck_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot each cell type individually\n",
    "\n",
    "num_plots_one_dim = int(round(np.sqrt(len(set(cluster_labels.condensed)))))\n",
    "fig, ax = plt.subplots(num_plots_one_dim,\n",
    "                       num_plots_one_dim + 1,\n",
    "                       figsize=(8 * 2, 6 * 2))\n",
    "\n",
    "gray_filt = puck.s1_dge_fmtd\n",
    "gray_filt_x = [puck.bc_loc_dict_s1[i][0] for i in gray_filt.index]\n",
    "gray_filt_y = [puck.bc_loc_dict_s1[i][1] for i in gray_filt.index]\n",
    "\n",
    "for idx in range(len(cell_type_list)):\n",
    "    c = cell_type_list[idx]\n",
    "    x = cluster_labels[cluster_labels.condensed == c].x\n",
    "    y = cluster_labels[cluster_labels.condensed == c].y\n",
    "    ax[math.floor(idx / 4), idx % 4].scatter(gray_filt_x,\n",
    "                                             gray_filt_y,\n",
    "                                             s=3,\n",
    "                                             alpha=0.05,\n",
    "                                             c='gray')\n",
    "    ax[math.floor(idx / 4), idx % 4].scatter(x, y, s=2)\n",
    "    ax[math.floor(idx / 4), idx % 4].axis('off')\n",
    "    fontprops = fm.FontProperties(size=18)\n",
    "    scalebar = AnchoredSizeBar(ax[math.floor(idx / 4), idx % 4].transData,\n",
    "                               pixels_needed,\n",
    "                               '',\n",
    "                               'lower right',\n",
    "                               pad=0.1,\n",
    "                               color='black',\n",
    "                               frameon=False,\n",
    "                               size_vertical=1,\n",
    "                               fontproperties=fontprops)\n",
    "\n",
    "    ax[math.floor(idx / 4), idx % 4].add_artist(scalebar)\n",
    "\n",
    "    #ax[math.floor(idx/4),idx%4].set_title(c)\n",
    "    plt.savefig('./vectorized_figures/sf3a_puckSpleen.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RCTD clustering and other plots for figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "color_map = plt.cm.get_cmap('Blues')\n",
    "reversed_color_map = color_map.reversed()\n",
    "\n",
    "n_bins = 100\n",
    "nbins = 100\n",
    "num_bins = 100  # 100 for spleen\n",
    "\n",
    "for gene in ['Marco', 'Gypa', 'Cd8a', 'Cd4', 'Trbc2',\n",
    "             'Trac']:  #,'Itgax','Gypa','Cd163','Pecam1','Ncr1'\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    point_size = 20\n",
    "    gray_filt = puckSpleen.s1_dge_fmtd\n",
    "    plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in gray_filt.index],\n",
    "                [puckSpleen.bc_loc_dict_s1[i][1] for i in gray_filt.index],\n",
    "                s=point_size,\n",
    "                alpha=0.1,\n",
    "                c='gray')  #c=list(marco_filt['Marco']),\n",
    "\n",
    "    marco_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd[gene] > 0]\n",
    "    plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in marco_filt.index],\n",
    "                [puckSpleen.bc_loc_dict_s1[i][1] for i in marco_filt.index],\n",
    "                s=point_size,\n",
    "                alpha=1,\n",
    "                label=gene,\n",
    "                c='green')  #c=list(marco_filt['Marco']),\n",
    "    #plt.title('Cluster assignments on bead')\n",
    "    plt.axis('off')\n",
    "    plt.xlim([0, 6000])\n",
    "    plt.ylim([0, 6000])\n",
    "    #plt.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    marco_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd[gene] > 0]\n",
    "    x = [puckSpleen.bc_loc_dict_s1[i][0] for i in marco_filt.index]\n",
    "    y = [puckSpleen.bc_loc_dict_s1[i][1] for i in marco_filt.index]\n",
    "\n",
    "    data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "    k = kde(data.T)\n",
    "    #xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "    # Bin size\n",
    "\n",
    "    print('real life size:', (min(x) - max(x)) / num_bins * 0.65)\n",
    "\n",
    "    Z, xedges, yedges = np.histogram2d(x, y, bins=num_bins)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    Z = gaussian_filter(Z, sigma=0.5)\n",
    "    this_plot = plt.pcolormesh(xedges[:-1],\n",
    "                               yedges[:-1],\n",
    "                               Z.T,\n",
    "                               cmap=reversed_color_map,\n",
    "                               shading='gouraud',\n",
    "                               vmin=0,\n",
    "                               vmax=3)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\n",
    "        'right',\n",
    "        size=\"7%\",\n",
    "        pad=0.2,\n",
    "    )\n",
    "    cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_xlim([0, 6000])\n",
    "    ax.set_ylim([0, 6000])\n",
    "\n",
    "    cbar.ax.text(0.5,\n",
    "                 -0.01,\n",
    "                 '0',\n",
    "                 transform=cbar.ax.transAxes,\n",
    "                 va='top',\n",
    "                 ha='center')\n",
    "    cbar.ax.text(0.5,\n",
    "                 1.0,\n",
    "                 '3',\n",
    "                 transform=cbar.ax.transAxes,\n",
    "                 va='bottom',\n",
    "                 ha='center')\n",
    "    cbar.outline.set_visible(False)\n",
    "    plt.savefig('./vectorized_figures/figure1f_Trbc2.pdf')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    cbar.outline.set_visible(False)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    fontprops = fm.FontProperties(size=18)\n",
    "    scalebar = AnchoredSizeBar(ax.transData,\n",
    "                               pixels_needed,\n",
    "                               '',\n",
    "                               'lower right',\n",
    "                               pad=0.1,\n",
    "                               color='white',\n",
    "                               frameon=False,\n",
    "                               size_vertical=1,\n",
    "                               fontproperties=fontprops)\n",
    "\n",
    "    ax.add_artist(scalebar)\n",
    "    plt.savefig('./vectorized_figures/figure1e_{}.pdf'.format(gene))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot kdeplot on for Spleen\n",
    "# plot for figure\n",
    "\n",
    "puck = puckSpleen\n",
    "tcr_locs = list(set(list(sum(puck.tcr_loc_dict_s1_filtered3.values(),\n",
    "                             []))))  # variable locations\n",
    "alpha = 'CAASDNYQLIW'\n",
    "beta = 'CASSRANYEQYF'\n",
    "tcr_locs_alpha = list(set(\n",
    "    puck.tcr_loc_dict_s1_filtered3[alpha]))  # variable locations\n",
    "tcr_locs_beta = list(set(\n",
    "    puck.tcr_loc_dict_s1_filtered3[beta]))  # variable locations\n",
    "kde_plot_df = pd.DataFrame.from_dict({\n",
    "    'x': [float(i[0]) for i in tcr_locs],\n",
    "    'y': [float(i[1]) for i in tcr_locs],\n",
    "    'type': ['T'] * len(tcr_locs)\n",
    "})\n",
    "kde_plot_df_alpha = pd.DataFrame.from_dict({\n",
    "    'x': [float(i[0]) for i in tcr_locs_alpha],\n",
    "    'y': [float(i[1]) for i in tcr_locs_alpha],\n",
    "    'type': ['T'] * len(tcr_locs_alpha)\n",
    "})\n",
    "kde_plot_df_beta = pd.DataFrame.from_dict({\n",
    "    'x': [float(i[0]) for i in tcr_locs_beta],\n",
    "    'y': [float(i[1]) for i in tcr_locs_beta],\n",
    "    'type': ['T'] * len(tcr_locs_beta)\n",
    "})\n",
    "\n",
    "point_size = 8\n",
    "alpha_value = 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gray_filt = puck.s1_dge_fmtd\n",
    "plt.scatter([puck.bc_loc_dict_s1[i][0] for i in gray_filt.index],\n",
    "            [puck.bc_loc_dict_s1[i][1] for i in gray_filt.index],\n",
    "            s=point_size,\n",
    "            alpha=0.1,\n",
    "            label='No Cluster',\n",
    "            c='gray')  #c=list(marco_filt['Marco']),\n",
    "fn = \"{}spleen_rctd_clusters_aging.csv\".format(directory)\n",
    "cluster_labels = pd.read_csv(fn)\n",
    "cluster_labels['cluster'] = cluster_labels['cell_label']\n",
    "cluster_num = len(list(set(cluster_labels.cluster)))\n",
    "\n",
    "groups = cluster_labels.groupby(\n",
    "    \"cell_label\"\n",
    ")  # can change to translated to visualize by translation or clonotype\n",
    "for name, group in groups:\n",
    "    if name == 'Granul':\n",
    "        continue\n",
    "    if name == 'MonoNucPhag':\n",
    "        continue\n",
    "    plt.scatter(group[\"x\"],\n",
    "                group[\"y\"],\n",
    "                s=point_size,\n",
    "                label=name,\n",
    "                marker='o',\n",
    "                alpha=alpha_value)\n",
    "\n",
    "marco_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd['Marco'] > 0]\n",
    "plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in marco_filt.index],\n",
    "            [puckSpleen.bc_loc_dict_s1[i][1] for i in marco_filt.index],\n",
    "            s=point_size,\n",
    "            alpha=alpha_value,\n",
    "            label='MARCO - Marginal Zone')  #c=list(marco_filt['Marco']),\n",
    "plt.title('Cluster assignments on bead')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "gene_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd['Gypa'] > 0]\n",
    "plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in gene_filt.index],\n",
    "            [puckSpleen.bc_loc_dict_s1[i][1] for i in gene_filt.index],\n",
    "            s=point_size,\n",
    "            alpha=alpha_value,\n",
    "            label='GYPA - RBCs')  #c=list(marco_filt['Marco']),\n",
    "plt.title('Cluster assignments on bead')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "gene_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd['Cd163'] > 0]\n",
    "plt.scatter(\n",
    "    [puckSpleen.bc_loc_dict_s1[i][0] for i in gene_filt.index],\n",
    "    [puckSpleen.bc_loc_dict_s1[i][1] for i in gene_filt.index],\n",
    "    s=point_size,\n",
    "    alpha=alpha_value,\n",
    "    label='CD163 - Red pulp macrophages')  #c=list(marco_filt['Marco']),\n",
    "plt.title('Cluster assignments on bead')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "gene_filt = puckSpleen.s1_dge_fmtd[puckSpleen.s1_dge_fmtd['Pecam1'] > 0]\n",
    "plt.scatter([puckSpleen.bc_loc_dict_s1[i][0] for i in gene_filt.index],\n",
    "            [puckSpleen.bc_loc_dict_s1[i][1] for i in gene_filt.index],\n",
    "            s=point_size,\n",
    "            alpha=alpha_value,\n",
    "            label='PECAM1 - Endothelial')  #c=list(marco_filt['Marco']),\n",
    "plt.title('Cluster assignments on bead')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#plt.axis('off')\n",
    "\n",
    "plt.xlim([0, 6000])\n",
    "plt.ylim([0, 6000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot kdeplot on for Human or Spleen\n",
    "# plot for figure\n",
    "puck = puckSpleen\n",
    "species = 'mouse'\n",
    "if species == 'mouse':\n",
    "    tcra_gene_name = 'Trac'\n",
    "    tcrb_gene_name = 'Trbc2'\n",
    "else:\n",
    "    tcra_gene_name = 'Trac'\n",
    "    tcrb_gene_name = 'Trbc2'\n",
    "\n",
    "tcr_locs = list(set(list(sum(puck.tcr_loc_dict_s1_filtered3.values(),\n",
    "                             []))))  # variable locations\n",
    "\n",
    "tcr_locs_alpha = []  # variable locations\n",
    "tcr_locs_beta = []\n",
    "for tcr in puck.tcr_loc_dict_s1_filtered3:\n",
    "    if tcr in puck.clonotypes['1a']:\n",
    "        tcr_locs_alpha = tcr_locs_alpha + list(\n",
    "            set(puck.tcr_loc_dict_s1_filtered3[tcr]))\n",
    "    else:\n",
    "        tcr_locs_beta = tcr_locs_beta + list(\n",
    "            set(puck.tcr_loc_dict_s1_filtered3[tcr]))\n",
    "\n",
    "kde_plot_df = pd.DataFrame.from_dict({\n",
    "    'x': [float(i[0]) for i in tcr_locs],\n",
    "    'y': [float(i[1]) for i in tcr_locs],\n",
    "    'type': ['T'] * len(tcr_locs)\n",
    "})\n",
    "kde_plot_df_alpha = pd.DataFrame.from_dict({\n",
    "    'x': [float(i[0]) for i in tcr_locs_alpha],\n",
    "    'y': [float(i[1]) for i in tcr_locs_alpha],\n",
    "    'type': ['T'] * len(tcr_locs_alpha)\n",
    "})\n",
    "kde_plot_df_beta = pd.DataFrame.from_dict({\n",
    "    'x': [float(i[0]) for i in tcr_locs_beta],\n",
    "    'y': [float(i[1]) for i in tcr_locs_beta],\n",
    "    'type': ['T'] * len(tcr_locs_beta)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Contour plot with gaussian smoothing\n",
    "\n",
    "color_map = plt.cm.get_cmap('Blues')\n",
    "reversed_color_map = color_map.reversed()\n",
    "\n",
    "point_size = 20\n",
    "#how many pixels is this?\n",
    "pixels_needed = 500 / 0.65\n",
    "bin_pixels = 0.65 * 6000 / num_bins\n",
    "bins_needed = pixels_needed / bin_pixels\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "\n",
    "# Create data: 200 points\n",
    "kde_plot_to_use = kde_plot_df  # kde_plot_df_alpha or beta\n",
    "\n",
    "vmin_val = 0\n",
    "vmax_val_both = 2\n",
    "vmin_val = 0\n",
    "vmax_val_alpha = 4\n",
    "vmax_val_beta = 4\n",
    "\n",
    "x = kde_plot_to_use.x\n",
    "y = kde_plot_to_use.y\n",
    "\n",
    "data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "k = kde(data.T)\n",
    "#xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "# Gaussian smoothed plot\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "print('real life size:',\n",
    "      (min(kde_plot_to_use.x) - max(kde_plot_to_use.x)) / num_bins * 0.65)\n",
    "\n",
    "Z, xedges, yedges = np.histogram2d(kde_plot_to_use.x,\n",
    "                                   kde_plot_to_use.y,\n",
    "                                   bins=num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "Z = gaussian_filter(Z, sigma=0.5)\n",
    "this_plot = plt.pcolormesh(xedges[:-1],\n",
    "                           yedges[:-1],\n",
    "                           Z.T,\n",
    "                           cmap=reversed_color_map,\n",
    "                           shading='gouraud',\n",
    "                           vmin=vmin_val,\n",
    "                           vmax=vmax_val_both)\n",
    "ax.contour(xi,\n",
    "           yi,\n",
    "           zi.reshape(xi.shape),\n",
    "           levels=15,\n",
    "           linewidths=0.5,\n",
    "           colors='white')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\n",
    "    'right',\n",
    "    size=\"7%\",\n",
    "    pad=0.2,\n",
    ")\n",
    "cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "ax.set_axis_off()\n",
    "\n",
    "cbar.ax.text(0.5,\n",
    "             -0.01,\n",
    "             str(vmin_val),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='top',\n",
    "             ha='center')\n",
    "cbar.ax.text(0.5,\n",
    "             1.0,\n",
    "             str(vmax_val_both),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='bottom',\n",
    "             ha='center')\n",
    "cbar.outline.set_visible(False)\n",
    "fontprops = fm.FontProperties(size=18)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "##########\n",
    "##########\n",
    "if species == 'mouse':\n",
    "    plt.savefig('./vectorized_figures/figure2c_post.pdf')\n",
    "else:\n",
    "    plt.savefig(\n",
    "        './vectorized_figures/Supplementary Figure TCRa and TCRb variable.pdf')\n",
    "##########\n",
    "##########\n",
    "fig.canvas.draw()\n",
    "#fig.colorbar(this_plot, cax=ax)\n",
    "\n",
    "# Create data: 200 points\n",
    "kde_plot_to_use = kde_plot_df_alpha  # kde_plot_df_alpha or beta\n",
    "\n",
    "x = kde_plot_to_use.x\n",
    "y = kde_plot_to_use.y\n",
    "\n",
    "data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "k = kde(data.T)\n",
    "#xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "# Gaussian smoothed plot\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "print('real life size:',\n",
    "      (min(kde_plot_to_use.x) - max(kde_plot_to_use.x)) / num_bins * 0.65)\n",
    "\n",
    "Z, xedges, yedges = np.histogram2d(kde_plot_to_use.x,\n",
    "                                   kde_plot_to_use.y,\n",
    "                                   bins=num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "Z = gaussian_filter(Z, sigma=0.5)\n",
    "this_plot = plt.pcolormesh(xedges[:-1],\n",
    "                           yedges[:-1],\n",
    "                           Z.T,\n",
    "                           cmap=reversed_color_map,\n",
    "                           shading='gouraud',\n",
    "                           vmin=vmin_val,\n",
    "                           vmax=vmax_val_alpha)\n",
    "ax.contour(xi,\n",
    "           yi,\n",
    "           zi.reshape(xi.shape),\n",
    "           levels=15,\n",
    "           linewidths=0.5,\n",
    "           colors='white')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\n",
    "    'right',\n",
    "    size=\"7%\",\n",
    "    pad=0.2,\n",
    ")\n",
    "cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "ax.set_axis_off()\n",
    "\n",
    "cbar.ax.text(0.5,\n",
    "             -0.01,\n",
    "             str(vmin_val),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='top',\n",
    "             ha='center')\n",
    "cbar.ax.text(0.5,\n",
    "             1.0,\n",
    "             str(vmax_val_alpha),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='bottom',\n",
    "             ha='center')\n",
    "cbar.outline.set_visible(False)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "##########\n",
    "##########\n",
    "if species == 'mouse':\n",
    "    plt.savefig('./vectorized_figures/figure1f_TCRa.pdf')\n",
    "else:\n",
    "    plt.savefig('./vectorized_figures/Supplementary Figure TCRa.pdf')\n",
    "##########\n",
    "##########\n",
    "fig.canvas.draw()\n",
    "#fig.colorbar(this_plot, cax=ax)\n",
    "\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "\n",
    "# Create data: 200 points\n",
    "kde_plot_to_use = kde_plot_df_beta  # kde_plot_df_alpha or beta\n",
    "\n",
    "x = kde_plot_to_use.x\n",
    "y = kde_plot_to_use.y\n",
    "\n",
    "data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "k = kde(data.T)\n",
    "#xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "# Gaussian smoothed plot\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "print('real life size:',\n",
    "      (min(kde_plot_to_use.x) - max(kde_plot_to_use.x)) / num_bins * 0.65)\n",
    "\n",
    "Z, xedges, yedges = np.histogram2d(kde_plot_to_use.x,\n",
    "                                   kde_plot_to_use.y,\n",
    "                                   bins=num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "Z = gaussian_filter(Z, sigma=0.5)\n",
    "plt.pcolormesh(xedges[:-1],\n",
    "               yedges[:-1],\n",
    "               Z.T,\n",
    "               cmap=reversed_color_map,\n",
    "               shading='gouraud',\n",
    "               vmin=vmin_val,\n",
    "               vmax=vmax_val_beta)\n",
    "ax.contour(xi,\n",
    "           yi,\n",
    "           zi.reshape(xi.shape),\n",
    "           levels=15,\n",
    "           linewidths=0.5,\n",
    "           colors='white')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\n",
    "    'right',\n",
    "    size=\"7%\",\n",
    "    pad=0.2,\n",
    ")\n",
    "cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "ax.set_axis_off()\n",
    "\n",
    "cbar.ax.text(0.5,\n",
    "             -0.01,\n",
    "             str(vmin_val),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='top',\n",
    "             ha='center')\n",
    "cbar.ax.text(0.5,\n",
    "             1.0,\n",
    "             str(vmax_val_beta),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='bottom',\n",
    "             ha='center')\n",
    "cbar.outline.set_visible(False)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "###########\n",
    "###########\n",
    "if species == 'mouse':\n",
    "    plt.savefig('./vectorized_figures/figure1f_TCRb.pdf')\n",
    "else:\n",
    "    plt.savefig('./vectorized_figures/Supplementary Figure TCRb.pdf')\n",
    "##########\n",
    "##########\n",
    "fig.canvas.draw()\n",
    "#fig.colorbar(this_plot, cax=ax)\n",
    "\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "\n",
    "print('Alpha')\n",
    "\n",
    "marco_filt = puck.s1_dge_fmtd[puck.s1_dge_fmtd[tcra_gene_name] > 0]\n",
    "x = [puck.bc_loc_dict_s1[i][0] for i in marco_filt.index]\n",
    "y = [puck.bc_loc_dict_s1[i][1] for i in marco_filt.index]\n",
    "\n",
    "data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "k = kde(data.T)\n",
    "#xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "# Gaussian smoothed plot\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "print('real life size:', (min(x) - max(x)) / num_bins * 0.65)\n",
    "\n",
    "Z, xedges, yedges = np.histogram2d(x, y, bins=num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "Z = gaussian_filter(Z, sigma=0.5)\n",
    "plt.pcolormesh(xedges[:-1],\n",
    "               yedges[:-1],\n",
    "               Z.T,\n",
    "               cmap=reversed_color_map,\n",
    "               shading='gouraud',\n",
    "               vmin=0,\n",
    "               vmax=vmax_val_alpha)\n",
    "ax.contour(xi,\n",
    "           yi,\n",
    "           zi.reshape(xi.shape),\n",
    "           levels=15,\n",
    "           linewidths=0.5,\n",
    "           colors='white')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\n",
    "    'right',\n",
    "    size=\"7%\",\n",
    "    pad=0.2,\n",
    ")\n",
    "cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "ax.set_axis_off()\n",
    "\n",
    "cbar.ax.text(0.5,\n",
    "             -0.01,\n",
    "             '0',\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='top',\n",
    "             ha='center')\n",
    "cbar.ax.text(0.5,\n",
    "             1.0,\n",
    "             str(vmax_val_alpha),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='bottom',\n",
    "             ha='center')\n",
    "cbar.outline.set_visible(False)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "##########\n",
    "##########\n",
    "if species == 'mouse':\n",
    "    plt.savefig('./vectorized_figures/figure1f_Trac.pdf')\n",
    "else:\n",
    "    plt.savefig('./vectorized_figures/Supplementary Figure Trac.pdf')\n",
    "\n",
    "##########\n",
    "##########\n",
    "fig.canvas.draw()\n",
    "#fig.colorbar(this_plot, cax=ax)\n",
    "\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "\n",
    "print('Beta')\n",
    "\n",
    "marco_filt = puck.s1_dge_fmtd[puck.s1_dge_fmtd[tcrb_gene_name] > 0]\n",
    "x = [puck.bc_loc_dict_s1[i][0] for i in marco_filt.index]\n",
    "y = [puck.bc_loc_dict_s1[i][1] for i in marco_filt.index]\n",
    "\n",
    "data = np.array([np.array([i, j]) for i, j in zip(x, y)])\n",
    "k = kde(data.T)\n",
    "#xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "xi, yi = np.mgrid[0:6000:nbins * 1j, 0:6000:nbins * 1j]\n",
    "zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "# Gaussian smoothed plot\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "print('real life size:', (min(x) - max(x)) / num_bins * 0.65)\n",
    "\n",
    "Z, xedges, yedges = np.histogram2d(x, y, bins=num_bins)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "Z = gaussian_filter(Z, sigma=0.5)\n",
    "plt.pcolormesh(xedges[:-1],\n",
    "               yedges[:-1],\n",
    "               Z.T,\n",
    "               cmap=reversed_color_map,\n",
    "               shading='gouraud',\n",
    "               vmin=0,\n",
    "               vmax=vmax_val_beta)\n",
    "ax.contour(xi,\n",
    "           yi,\n",
    "           zi.reshape(xi.shape),\n",
    "           levels=15,\n",
    "           linewidths=0.5,\n",
    "           colors='white')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\n",
    "    'right',\n",
    "    size=\"7%\",\n",
    "    pad=0.2,\n",
    ")\n",
    "cbar = fig.colorbar(this_plot, cax=cax, ticks=[])\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "ax.set_axis_off()\n",
    "\n",
    "cbar.ax.text(0.5,\n",
    "             -0.01,\n",
    "             '0',\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='top',\n",
    "             ha='center')\n",
    "cbar.ax.text(0.5,\n",
    "             1.0,\n",
    "             str(vmax_val_beta),\n",
    "             transform=cbar.ax.transAxes,\n",
    "             va='bottom',\n",
    "             ha='center')\n",
    "cbar.outline.set_visible(False)\n",
    "\n",
    "#Extent defines the images max and min of the horizontal and vertical values.\n",
    "\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "##########\n",
    "##########\n",
    "if species == 'mouse':\n",
    "    plt.savefig('./vectorized_figures/figure1f_Trbc2.pdf')\n",
    "else:\n",
    "    plt.savefig('./vectorized_figures/Supplementary Figure Trbc2.pdf')\n",
    "##########\n",
    "##########\n",
    "fig.canvas.draw()\n",
    "#fig.colorbar(this_plot, cax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pairing venn diagram and circos plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "locs_all_a = []\n",
    "locs_all_b = []\n",
    "for cl in puckSpleen.tcr_loc_dict_s1_filtered3:\n",
    "    if cl in puckSpleen.clonotypes['1a']:\n",
    "        locs_all_a = locs_all_a + puckSpleen.tcr_loc_dict_s1_filtered3[cl]\n",
    "    elif cl in puckSpleen.clonotypes['1b']:\n",
    "        locs_all_b = locs_all_b + puckSpleen.tcr_loc_dict_s1_filtered3[cl]\n",
    "        print(cl)\n",
    "locs_all_a = set(locs_all_a)\n",
    "locs_all_b = set(locs_all_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot pairing\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "all_bc = list(puckSpleen.s1_dge_fmtd.index)\n",
    "bc_s1_tcrb = locs_all_b\n",
    "bc_s1_tcra = locs_all_a\n",
    "paired_bcs = list(set(bc_s1_tcrb) & set(bc_s1_tcra))\n",
    "# Second way\n",
    "v = venn2([bc_s1_tcra, bc_s1_tcrb], set_labels=['tcrA', 'tcrB'])\n",
    "c = venn2_circles([bc_s1_tcra, bc_s1_tcrb])\n",
    "c[0].set_color(\"white\")\n",
    "c[0].set_ls('solid')\n",
    "c[0].set_edgecolor('blue')\n",
    "\n",
    "c[1].set_color(\"white\")\n",
    "c[1].set_ls('solid')\n",
    "c[1].set_edgecolor('red')\n",
    "\n",
    "plt.savefig('./vectorized_figures/Supplementary Figure 1B.pdf')\n",
    "plt.show()\n",
    "len(paired_bcs) / (len(bc_s1_tcrb) + len(bc_s1_tcra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Circos plot\n",
    "df_use = puckSpleen.df_s1_filtered3\n",
    "\n",
    "all_bc = list(puckSpleen.s1_dge_fmtd.index)\n",
    "puckSpleen.df_s1\n",
    "bc_s1_tcrb = set(\n",
    "    [i for i in find_specific_barcodes('tcr_b', df_use) if i in all_bc])\n",
    "bc_s1_tcra = set(\n",
    "    [i for i in find_specific_barcodes('tcr_a', df_use) if i in all_bc])\n",
    "paired_bcs = list(set(bc_s1_tcrb) & set(bc_s1_tcra))\n",
    "paired_df = puckSpleen.df_s1_filtered3[(df_use.tcr_a.map(len) > 0)\n",
    "                                       & (df_use.tcr_b.map(len) > 0)]\n",
    "\n",
    "circos_plot_df = paired_df.copy(deep=True)\n",
    "circos_plot_df['tcr_a'] = paired_df.tcr_a\n",
    "circos_plot_df['tcr_b'] = paired_df.tcr_b\n",
    "\n",
    "true_ot1_tcra = 'CAASDNYQLIW'\n",
    "true_ot1_tcrb = 'CASSRANYEQYF'\n",
    "tcr_a_hamming = []\n",
    "tcr_b_hamming = []\n",
    "for i in circos_plot_df['tcr_a']:\n",
    "    i = ast.literal_eval(i)\n",
    "    this_list = []\n",
    "    for j in i:\n",
    "        #         if hamming_distance(j,true_ot1_tcra) == 1:\n",
    "        #             this_list.append(true_ot1_tcra)\n",
    "        #         else:\n",
    "        this_list.append(j)\n",
    "    tcr_a_hamming.append(this_list)\n",
    "\n",
    "for i in circos_plot_df['tcr_b']:\n",
    "    i = ast.literal_eval(i)\n",
    "    this_list = []\n",
    "    for j in i:\n",
    "        #         if hamming_distance(j,true_ot1_tcrb) == 1:\n",
    "        #             this_list.append(true_ot1_tcrb)\n",
    "        #         else:\n",
    "        this_list.append(j)\n",
    "    tcr_b_hamming.append(list(set(this_list)))\n",
    "\n",
    "circos_plot_df['tcr_a_hamming'] = tcr_a_hamming\n",
    "circos_plot_df['tcr_b_hamming'] = tcr_b_hamming\n",
    "\n",
    "tcr_a_top = []\n",
    "tcr_b_top = []\n",
    "tcr_bc_counter_dict = {}  # A dictionary for counting (tcr,bc) pairs\n",
    "for cl in puckSpleen.tcr_loc_dict_s1_filtered3:\n",
    "    cl_name = cl\n",
    "    for loc in puckSpleen.tcr_loc_dict_s1_filtered3[cl_name]:\n",
    "        bc = puckSpleen.loc_to_bc_s1[loc]\n",
    "        if (cl, bc) not in tcr_bc_counter_dict:\n",
    "            tcr_bc_counter_dict[(cl_name, bc)] = 0\n",
    "        tcr_bc_counter_dict[tuple((cl_name, bc))] += 1\n",
    "\n",
    "\n",
    "def find_highest_expressing_clonotype(barcode, list_of_clonotypes):\n",
    "    errors = []\n",
    "    counts = 0\n",
    "    cl_keep = ''\n",
    "    for cl in list_of_clonotypes:\n",
    "        if (cl, barcode) not in tcr_bc_counter_dict:\n",
    "            errors.append((cl, barcode))\n",
    "        else:\n",
    "            bc_count = tcr_bc_counter_dict[(cl, barcode)]\n",
    "            if bc_count > counts:\n",
    "                counts = bc_count\n",
    "                cl_keep = cl\n",
    "        if errors != []:\n",
    "            print(errors)\n",
    "    return cl_keep\n",
    "\n",
    "\n",
    "circos_bcs = list(circos_plot_df['bead_barcodes'])\n",
    "circos_a = list(circos_plot_df['tcr_a_hamming'])\n",
    "circos_b = list(circos_plot_df['tcr_b_hamming'])\n",
    "circos_plot_df['tcr_a_top'] = [\n",
    "    find_highest_expressing_clonotype(circos_bcs[idx], circos_a[idx])\n",
    "    for idx in range(len(circos_plot_df))\n",
    "]\n",
    "circos_plot_df['tcr_b_top'] = [\n",
    "    find_highest_expressing_clonotype(circos_bcs[idx], circos_b[idx])\n",
    "    for idx in range(len(circos_plot_df))\n",
    "]\n",
    "\n",
    "# circos_plot_df['tcr_a_hamming'].apply(pd.Series).reset_index().melt(id_vars='index').dropna()[['index', 'value']].set_index('index')\n",
    "circos_plot_df = circos_plot_df.groupby(\n",
    "    by=[\"tcr_a_top\", \"tcr_b_top\"]).count()[[\"bead_barcodes\"\n",
    "                                            ]].rename(columns={\n",
    "                                                \"bead_barcodes\": \"Count\"\n",
    "                                            }).reset_index()\n",
    "# circos_plot_df = circos_plot_df.sort_values(by=\"tcr_a_top\", ascending=False)\n",
    "# circos_plot_df = circos_plot_df[~circos_plot_df['tcr_a_top'].str.contains(\"_\")]\n",
    "# circos_plot_df= circos_plot_df[~circos_plot_df['tcr_a_top'].str.contains('*',regex=False)]\n",
    "# circos_plot_df\n",
    "# chord = hv.Chord(circos_plot_df)\n",
    "# print(chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "circos_plot_df.sort_values(by=['tcr_b_top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "circos_plot_df.columns = ['TCRa', 'TCRb', 'Count']\n",
    "circos_plot_df.to_csv('./vectorized_figures/spleen_pairing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot all clonotypes on puck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot all clonotypes in different colors\n",
    "pixels_needed = 500 / 0.65\n",
    "puck = puck8\n",
    "\n",
    "clonotypes_to_plot = []\n",
    "clonotypes_to_plot_names = []\n",
    "for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "    if cl not in puck.clonotypes['1b']:\n",
    "        continue\n",
    "    if len(set(\n",
    "            puck.tcr_loc_dict_s1_filtered3[cl])) >= 0:  ### FOR A COUNT FILTER\n",
    "        clonotypes_to_plot = clonotypes_to_plot + [cl]\n",
    "        clonotypes_to_plot_names.append(cl)\n",
    "\n",
    "print(len(clonotypes_to_plot_names), 'total number of clonotypes on this puck')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "t_plotx = [\n",
    "    j[0] for j in [\n",
    "        i for i in puck.tll_loc_cluster_dict\n",
    "        if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "    ]\n",
    "]\n",
    "t_ploty = [\n",
    "    j[1] for j in [\n",
    "        i for i in puck.tll_loc_cluster_dict\n",
    "        if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "    ]\n",
    "]\n",
    "ax.scatter(t_plotx, t_ploty, s=0.5, alpha=0.1, label='Tumor')\n",
    "\n",
    "til_plotx = [\n",
    "    j[0] for j in [\n",
    "        i for i in puck.tll_loc_cluster_dict\n",
    "        if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "    ]\n",
    "]\n",
    "til_ploty = [\n",
    "    j[1] for j in [\n",
    "        i for i in puck.tll_loc_cluster_dict\n",
    "        if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "    ]\n",
    "]\n",
    "ax.scatter(til_plotx, til_ploty, s=0.5, alpha=0.1, label='Immune')\n",
    "\n",
    "til_plotx = [\n",
    "    j[0] for j in [\n",
    "        i for i in puck.tll_loc_cluster_dict\n",
    "        if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "    ]\n",
    "]\n",
    "til_ploty = [\n",
    "    j[1] for j in [\n",
    "        i for i in puck.tll_loc_cluster_dict\n",
    "        if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "    ]\n",
    "]\n",
    "ax.scatter(til_plotx, til_ploty, s=0.5, alpha=0.1, label='Lung')\n",
    "\n",
    "for idx in tqdm(range(len(clonotypes_to_plot))):\n",
    "    clonotype = clonotypes_to_plot[idx]\n",
    "    #####\n",
    "    loc_for_this_cl = list(set(puck.tcr_loc_dict_s1_filtered3[clonotype]))\n",
    "\n",
    "    x_val = [float(i[0]) for i in loc_for_this_cl]\n",
    "    y_val = [float(i[1]) for i in loc_for_this_cl]\n",
    "\n",
    "    plt.scatter(x_val,\n",
    "                y_val,\n",
    "                label=clonotype,\n",
    "                color=sns.color_palette('hls', len(clonotypes_to_plot))[idx],\n",
    "                edgecolors='k',\n",
    "                linewidth=1,\n",
    "                s=50)\n",
    "    plt.xlim(0, 6000)\n",
    "    plt.ylim(0, 6000)\n",
    "\n",
    "    plt.axis('off')\n",
    "fontprops = fm.FontProperties(size=18)\n",
    "scalebar = AnchoredSizeBar(ax.transData,\n",
    "                           pixels_needed,\n",
    "                           '',\n",
    "                           'lower right',\n",
    "                           pad=0.1,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1,\n",
    "                           fontproperties=fontprops)\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "plt.savefig('./vectorized_figures/figure2d_{}.pdf'.format(puck.puck_name))\n",
    "plt.show()\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metagene DE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     24
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pixels_needed = 500 / 0.65\n",
    "puck = puck8\n",
    "load_genesets = True\n",
    "run_geneset_qc = False\n",
    "# Read in gene sets\n",
    "if load_genesets:\n",
    "    gene_df = pd.read_excel('T cell signatures.xls',\n",
    "                            sheet_name='published signatures')\n",
    "    gene_groups = {}\n",
    "    for name in gene_df.columns:\n",
    "        gene_groups[name] = [i for i in list(gene_df[name]) if type(i) == str]\n",
    "    ss_genes = puck.s1_dge_fmtd.columns\n",
    "\n",
    "    missing_genes = []\n",
    "    for group in gene_groups:\n",
    "        for gene in gene_groups[group]:\n",
    "            if gene in ss_genes:\n",
    "                pass\n",
    "            if gene not in ss_genes:\n",
    "                missing_genes.append(gene)\n",
    "    if len(missing_genes) > 0:\n",
    "        print('These genes are missing:', missing_genes)\n",
    "    # Remove missing genes\n",
    "    for group in gene_groups:\n",
    "        gene_groups[group] = [\n",
    "            i for i in gene_groups[group] if i not in missing_genes\n",
    "        ]\n",
    "if run_geneset_qc:\n",
    "    # Geneset QC (see reads per bead for each geneset)\n",
    "    for group in gene_group_cl_agg:\n",
    "        print(group)\n",
    "        print(np.mean([i for i in gene_group_cl_agg[group] if i != 0]))\n",
    "    print('-----------')\n",
    "    for group in gene_group_cl_agg_not_norm:\n",
    "        print(group)\n",
    "        #print([i for i in gene_group_cl_agg_not_norm[group] if i >= 10])\n",
    "        #if np.median([i for i in gene_group_cl_agg_not_norm[group] if i >= 1])>=0:\n",
    "\n",
    "        plt.figure()\n",
    "        plt.hist([i for i in gene_group_cl_agg_not_norm[group] if i >= 1])\n",
    "        plt.title(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the plots by clonotype:\n",
    "# Calculate gene expression for each gene group for clonotypes separately and then all together\n",
    "\n",
    "puck = puck8\n",
    "\n",
    "# INDIVIDUAL CLONOTYPE ANALYSIS\n",
    "gene_group_cl = {}\n",
    "gene_group_cl_less = {}\n",
    "gene_group_cl_greater = {}\n",
    "all_cl_bcs = []\n",
    "for clonotype in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "    cl_locs = [\n",
    "        i for i in set(puck.tcr_loc_dict_s1_filtered3[clonotype])\n",
    "        if i in puck.tumor_beads\n",
    "    ]  #  if i in puck.tumor_beads\n",
    "    cl_bcs = [puck.loc_to_bc_s1[i] for i in cl_locs]\n",
    "    all_cl_bcs = all_cl_bcs + cl_bcs\n",
    "    if len(cl_bcs) < 10:\n",
    "        continue\n",
    "\n",
    "    # This is a distribution of the summed normalized expression of all the genes in each group\n",
    "    if group not in gene_group_cl:\n",
    "        gene_group_cl[group] = {}\n",
    "        gene_group_cl_less[group] = {}\n",
    "        gene_group_cl_greater[group] = {}\n",
    "    gene_group_cl[group][clonotype] = list(\n",
    "        puck.s1_dge_fmtd_norm.loc[cl_bcs, gene_groups[group]].sum(axis=1))\n",
    "\n",
    "    cutoff = np.median(gene_group_cl[group][clonotype])\n",
    "    gene_group_cl_less[group][clonotype] = [\n",
    "        cl_locs[idx] for idx in range(len(gene_group_cl[group][clonotype]))\n",
    "        if gene_group_cl[group][clonotype][idx] < cutoff\n",
    "    ]\n",
    "    gene_group_cl_greater[group][clonotype] = [\n",
    "        cl_locs[idx] for idx in range(len(gene_group_cl[group][clonotype]))\n",
    "        if gene_group_cl[group][clonotype][idx] >= cutoff\n",
    "    ]\n",
    "\n",
    "# AGGREGATE CLONOTYPE ANALYSIS\n",
    "gene_group_cl_agg = {}\n",
    "gene_group_cl_agg_less = {}\n",
    "gene_group_cl_agg_greater = {}\n",
    "gene_group_cl_agg_not_norm = {}\n",
    "all_cl_bcs = list(set(all_cl_bcs))\n",
    "all_locs = [puck.bc_loc_dict_s1[i] for i in all_cl_bcs]\n",
    "\n",
    "gene_group_cl_agg[group] = list(\n",
    "    puck.s1_dge_fmtd_norm.loc[all_cl_bcs, gene_groups[group]].sum(axis=1))\n",
    "cutoff = np.median(gene_group_cl_agg[group])\n",
    "gene_group_cl_agg_less = [\n",
    "    all_locs[idx] for idx in range(len(gene_group_cl_agg[group]))\n",
    "    if gene_group_cl_agg[group][idx] < cutoff\n",
    "]\n",
    "gene_group_cl_agg_greater = [\n",
    "    all_locs[idx] for idx in range(len(gene_group_cl_agg[group]))\n",
    "    if gene_group_cl_agg[group][idx] >= cutoff\n",
    "]\n",
    "less_agg_dist = [\n",
    "    distance_between_points(pt, closest_node(pt, puck.boundary_points))\n",
    "    for pt in gene_group_cl_agg_less if pt in puck.tumor_beads\n",
    "]\n",
    "greater_agg_dist = [\n",
    "    distance_between_points(pt, closest_node(pt, puck.boundary_points))\n",
    "    for pt in gene_group_cl_agg_greater if pt in puck.tumor_beads\n",
    "]\n",
    "\n",
    "# PLOT\n",
    "plt.figure(figsize=(6, 3))\n",
    "df_greater = pd.DataFrame.from_dict(\n",
    "    {'Distance distribution': [i * 0.65 for i in greater_agg_dist]})\n",
    "df_less = pd.DataFrame.from_dict(\n",
    "    {'Distance distribution': [i * 0.65 for i in less_agg_dist]})\n",
    "sns.distplot(df_greater['Distance distribution'],\n",
    "             hist=False,\n",
    "             kde=True,\n",
    "             bins=int(180 / 5),\n",
    "             color='darkblue',\n",
    "             hist_kws={\n",
    "                 'edgecolor': 'gray',\n",
    "                 'alpha': 0.75\n",
    "             },\n",
    "             kde_kws={\n",
    "                 'linewidth': 4,\n",
    "                 'bw': 0.5,\n",
    "                 'alpha': 0.75\n",
    "             },\n",
    "             norm_hist=True,\n",
    "             label='Greater')\n",
    "\n",
    "sns.distplot(df_less['Distance distribution'],\n",
    "             hist=False,\n",
    "             kde=True,\n",
    "             bins=int(180 / 5),\n",
    "             color='orange',\n",
    "             hist_kws={\n",
    "                 'edgecolor': 'gray',\n",
    "                 'alpha': 0.75\n",
    "             },\n",
    "             kde_kws={\n",
    "                 'linewidth': 4,\n",
    "                 'bw': 0.5,\n",
    "                 'alpha': 0.75\n",
    "             },\n",
    "             norm_hist=True,\n",
    "             label='Less')\n",
    "\n",
    "print(\n",
    "    'ks_test',\n",
    "    kstest([i * 0.65 for i in greater_agg_dist],\n",
    "           [i * 0.65 for i in less_agg_dist]))\n",
    "plt.savefig('./vectorized_figures/fig3_v3_1.pdf')\n",
    "\n",
    "# PLOT 2\n",
    "fig, ax = plt.subplots()\n",
    "agg = copy.deepcopy(gene_group_cl_agg[group])\n",
    "\n",
    "df_all = pd.DataFrame.from_dict({'Value': [i for i in agg]})\n",
    "\n",
    "sns.distplot(df_all['Value'],\n",
    "             hist=False,\n",
    "             kde=True,\n",
    "             bins=int(180 / 10),\n",
    "             color='black',\n",
    "             hist_kws={\n",
    "                 'edgecolor': 'gray',\n",
    "                 'alpha': 0.75\n",
    "             },\n",
    "             kde_kws={\n",
    "                 'linewidth': 2,\n",
    "                 'bw': 0.3,\n",
    "                 'alpha': .75\n",
    "             },\n",
    "             norm_hist=True,\n",
    "             label='Less')\n",
    "plt.axvline(x=cutoff, c='black', linewidth=3)\n",
    "\n",
    "sns.distplot(df_all['Value'],\n",
    "             hist=True,\n",
    "             kde=False,\n",
    "             bins=int(180 / 10),\n",
    "             color='orange',\n",
    "             hist_kws={\n",
    "                 'edgecolor': 'gray',\n",
    "                 'alpha': 0.75\n",
    "             },\n",
    "             kde_kws={\n",
    "                 'linewidth': 2,\n",
    "                 'bw': 0.3,\n",
    "                 'alpha': .75\n",
    "             },\n",
    "             norm_hist=True,\n",
    "             label='Less')\n",
    "plt.axvline(x=cutoff, c='black', linewidth=3)\n",
    "\n",
    "for p in ax.patches:\n",
    "    if p.get_xy()[0] >= cutoff * .95:\n",
    "        p.set_color('darkblue')\n",
    "    if p.get_xy()[1] >= cutoff:\n",
    "        p.set_color('darkblue')\n",
    "plt.savefig('./vectorized_figures/fig3_v3.pdf')\n",
    "\n",
    "######\n",
    "\n",
    "all_pvals = []\n",
    "group = 'Bad response to ICP (from Sade-Feldman et al. 2018)'\n",
    "plotting_df = {}\n",
    "plotting_df['less_or_greater'] = []\n",
    "plotting_df['value'] = []\n",
    "plotting_df['clonotype'] = []\n",
    "\n",
    "for cl in gene_group_cl[group]:\n",
    "    less = gene_group_cl_less[group][cl]\n",
    "    greater = gene_group_cl_greater[group][cl]\n",
    "\n",
    "    less_dist = [\n",
    "        distance_between_points(pt, closest_node(pt, puck.boundary_points))\n",
    "        for pt in less if pt in puck.tumor_beads\n",
    "    ]\n",
    "    greater_dist = [\n",
    "        distance_between_points(pt, closest_node(pt, puck.boundary_points))\n",
    "        for pt in greater if pt in puck.tumor_beads\n",
    "    ]\n",
    "\n",
    "    if len(less_dist) < 10:\n",
    "        continue\n",
    "    if len(greater_dist) < 10:\n",
    "        continue\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.hist(less_dist)\n",
    "#     plt.hist(greater_dist)\n",
    "\n",
    "    pval = round(kstest(less_dist, greater_dist)[1], 2)\n",
    "    all_pvals.append(kstest(less_dist, greater_dist)[1])\n",
    "    #     plt.title(cl + ' ' +  str(pval))\n",
    "\n",
    "    plotting_df['clonotype'] = plotting_df['clonotype'] + [cl] * (\n",
    "        len(less_dist) + len(greater_dist))\n",
    "    plotting_df['value'] = plotting_df['value'] + less_dist + greater_dist\n",
    "    plotting_df['less_or_greater'] = plotting_df['less_or_greater'] + [\n",
    "        'less'\n",
    "    ] * len(less_dist) + ['greater'] * len(greater_dist)\n",
    "\n",
    "plotting_df['value'] = [i * 0.65 for i in plotting_df['value']]\n",
    "\n",
    "color_palette_to_use = [sns.color_palette(\"tab10\")[2]\n",
    "                        ] + [sns.color_palette(\"tab10\")[4]]\n",
    "plotting_df = pd.DataFrame(plotting_df)\n",
    "plotting_df.clonotype = [\n",
    "    pretty_clonotype_name[i] for i in plotting_df.clonotype\n",
    "]\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plotting_df.sort_values('clonotype', inplace=True)\n",
    "plt.figure(figsize=(6, 3))\n",
    "plotting_df.sort_values('less_or_greater', inplace=True, ascending=True)\n",
    "plotting_df.sort_values('clonotype', inplace=True)\n",
    "sns.violinplot(x=\"clonotype\",\n",
    "               y=\"value\",\n",
    "               hue=\"less_or_greater\",\n",
    "               hue_order=['less', 'greater'],\n",
    "               data=plotting_df,\n",
    "               palette=color_palette_to_use,\n",
    "               split=True,\n",
    "               bw=0.5)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.savefig('./vectorized_figures/figure3f_new.pdf')\n",
    "\n",
    "cl_distances = {}\n",
    "cl_medians = {}\n",
    "for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "    cl_distances[cl] = [\n",
    "        (pt, distance_between_points(pt, closest_node(pt,\n",
    "                                                      puck.boundary_points)))\n",
    "        for pt in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if pt in puck.tumor_beads\n",
    "    ]\n",
    "    cl_medians[cl] = np.median([i[1] for i in cl_distances[cl]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adjust p values for above plot\n",
    "p_values_all_corrected = stats.multitest.multipletests(all_pvals,\n",
    "                                                       alpha=0.05,\n",
    "                                                       method='fdr_bh',\n",
    "                                                       is_sorted=False,\n",
    "                                                       returnsorted=False)\n",
    "conversion_dict = dict(zip(all_pvals, p_values_all_corrected[1]))\n",
    "conversion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot geneset expression spatially on puck separated by median geneset expression\n",
    "\n",
    "# plot significant clonotypes on all pucks\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "for puck in tqdm([puck8]):\n",
    "\n",
    "    for group in gene_group_cl:\n",
    "        if group != 'Bad response to ICP (from Sade-Feldman et al. 2018)':\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        puck.tumor_beads = [\n",
    "            j for j in [\n",
    "                i for i in puck.tll_loc_cluster_dict\n",
    "                if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "            ]\n",
    "        ]\n",
    "        puck.til_beads = [\n",
    "            j for j in [\n",
    "                i for i in puck.tll_loc_cluster_dict\n",
    "                if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "            ]\n",
    "        ]\n",
    "        puck.lung_beads = [\n",
    "            j for j in [\n",
    "                i for i in puck.tll_loc_cluster_dict\n",
    "                if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        plt.scatter([i[0] for i in puck.til_beads],\n",
    "                    [i[1] for i in puck.til_beads],\n",
    "                    label='tll',\n",
    "                    s=3,\n",
    "                    alpha=0.01,\n",
    "                    color=sns.color_palette()[1])\n",
    "        plt.scatter([i[0] for i in puck.lung_beads],\n",
    "                    [i[1] for i in puck.lung_beads],\n",
    "                    label='lung',\n",
    "                    s=3,\n",
    "                    alpha=0.01,\n",
    "                    color=sns.color_palette()[2])\n",
    "        plt.scatter([i[0] for i in puck.tumor_beads],\n",
    "                    [i[1] for i in puck.tumor_beads],\n",
    "                    label='tumor',\n",
    "                    s=3,\n",
    "                    alpha=0.01,\n",
    "                    color=sns.color_palette()[0])\n",
    "\n",
    "        all_tcr_bcs = all_locs  ##\n",
    "        coloring_for_each_loc = gene_group_cl_agg[group]\n",
    "\n",
    "        #         x = [i[0] for i in all_tcr_locs  if i in puck.tumor_beads] #\n",
    "        #         y = [i[1] for i in all_tcr_locs  if i in puck.tumor_beads] #\n",
    "        x = [i[0] for i in all_locs]  #\n",
    "        y = [i[1] for i in all_locs]  #\n",
    "        ge = coloring_for_each_loc\n",
    "        plotting_df = pd.DataFrame.from_dict({'x': x, 'y': y, 'ge': ge})\n",
    "        cutoff = np.median(plotting_df['ge'])  ## FOR AGGREGATE\n",
    "        test_df = plotting_df\n",
    "        plotting_df_less = plotting_df[plotting_df['ge'] < cutoff]\n",
    "        plotting_df_greater = plotting_df[plotting_df['ge'] >= cutoff]\n",
    "        #         sns.scatterplot(data = plotting_df, x= x, y = y, hue = 'blue',alpha=0.5)\n",
    "\n",
    "        ### FOR ORIGINAL SEPARATED PLOTS\n",
    "        sns.scatterplot(data=plotting_df_less,\n",
    "                        x='x',\n",
    "                        y='y',\n",
    "                        color='orange',\n",
    "                        alpha=0.5,\n",
    "                        label='lower_than_median')\n",
    "        sns.scatterplot(data=plotting_df_greater,\n",
    "                        x='x',\n",
    "                        y='y',\n",
    "                        color='darkblue',\n",
    "                        alpha=0.5,\n",
    "                        label='greater_than_median')\n",
    "        ### FOR PLOTS COLORED BY EXPRESSION\n",
    "        #         sns.scatterplot(data = plotting_df, x= 'x', y = 'y', hue='ge',alpha=0.5)\n",
    "        plt.xlim([0, 6000])\n",
    "        plt.ylim([0, 6000])\n",
    "        ax.set_xlim([0, 6000])\n",
    "        ax.set_ylim([0, 6000])\n",
    "        #plt.title(group)\n",
    "        lgd = plt.legend(bbox_to_anchor=(2, 1), loc='upper left')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        fontprops = fm.FontProperties(size=18)\n",
    "        scalebar = AnchoredSizeBar(ax.transData,\n",
    "                                   pixels_needed,\n",
    "                                   '',\n",
    "                                   'lower right',\n",
    "                                   pad=0.1,\n",
    "                                   color='black',\n",
    "                                   frameon=False,\n",
    "                                   size_vertical=1,\n",
    "                                   fontproperties=fontprops)\n",
    "\n",
    "        ax.add_artist(scalebar)\n",
    "        plt.savefig(\n",
    "            './vectorized_figures/figure3b_spatial_legend_{}.pdf'.format(\n",
    "                group),\n",
    "            bbox_extra_artists=(lgd, ),\n",
    "            bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# for ax, col in zip(ax[0], significant_clonotypes):\n",
    "#     ax.set_title(col,fontsize=40)\n",
    "\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot gene expression for each clonotype against aggregated, ks_values_all\n",
    "# Looking at all beads (can try tumor only next)\n",
    "# ignore beads with 0s\n",
    "\n",
    "make_plot = True\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "ks_values_good_pval = [[], []]  # greater and less\n",
    "ks_values_good_stat = [[], []]\n",
    "ks_values_bad_pval = [[], []]\n",
    "ks_values_bad_stat = [[], []]\n",
    "\n",
    "ks_values_all = {}\n",
    "cls_order = []\n",
    "iterct = 0\n",
    "\n",
    "for group in tqdm(gene_group_cl):\n",
    "    iterct += 1\n",
    "\n",
    "    for cl in gene_group_cl[group]:\n",
    "        if cl in puck.clonotypes['1b']:\n",
    "            #             if cl not in significant_clonotypes:\n",
    "            #                 continue\n",
    "\n",
    "            lowest = min(min(gene_group_cl[group][cl]),\n",
    "                         min(gene_group_cl_agg[group]))\n",
    "            highest = max(max(gene_group_cl[group][cl]),\n",
    "                          max(gene_group_cl_agg[group]))\n",
    "            agg_remove_query = []\n",
    "            agg_remove_query = copy.deepcopy(gene_group_cl_agg[group])\n",
    "            for value in gene_group_cl[group][cl]:\n",
    "                agg_remove_query.remove(value)\n",
    "\n",
    "            kstest_greater = kstest(\n",
    "                gene_group_cl[group][cl],\n",
    "                agg_remove_query)  #,alternative='two-sided'\n",
    "            kstest_greater_pval = kstest_greater[1]\n",
    "\n",
    "            #             kstest_greater = scipy.stats.ttest_ind(gene_group_cl[group][cl],agg_remove_query)\n",
    "            #             kstest_greater_pval = scipy.stats.ttest_ind(gene_group_cl[group][cl],agg_remove_query)[1]\n",
    "\n",
    "            ## CHANGE THIS line for different metrics\n",
    "            metric = cohens_d(gene_group_cl[group][cl], agg_remove_query)\n",
    "\n",
    "            if iterct == 1:\n",
    "                cls_order.append(cl)\n",
    "\n",
    "            if group not in ks_values_all:\n",
    "                ks_values_all[group] = [[], []]\n",
    "                # Change sign depending on mean differences\n",
    "            if np.mean(agg_remove_query) < np.mean(gene_group_cl[group][cl]):\n",
    "                ks_values_all[group][0].append(metric)\n",
    "            elif np.mean(agg_remove_query) > np.mean(gene_group_cl[group][cl]):\n",
    "                ks_values_all[group][0].append(metric)\n",
    "\n",
    "            ks_values_all[group][1].append(kstest_greater[1])\n",
    "\n",
    "            if cl in significant_clonotypes:  #['CASRYGSLAEGGTQYF']: #,'CASSQGLAGVLGQFF','CASSPTVYNEQFF'\n",
    "                print((np.mean(gene_group_cl[group][cl]),\n",
    "                       np.mean(agg_remove_query),\n",
    "                       np.mean(gene_group_cl[group][cl]) -\n",
    "                       np.mean(agg_remove_query)))\n",
    "                #                 if group not in ['Bad response to ICP (from Sade-Feldman et al. 2018)']: #Good response to ICP (from Sade-Feldman et al. 2018)'\n",
    "                #                     continue\n",
    "                #             if (kstest_greater_pval < 0.05 or kstest_less_pval < 0.05): #(kstest_greater < 0.05 or kstest_less < 0.05)\n",
    "                if make_plot:\n",
    "                    if group not in [\n",
    "                            'Bad response to ICP (from Sade-Feldman et al. 2018)'\n",
    "                    ]:  #Good response to ICP (from Sade-Feldman et al. 2018)'\n",
    "                        continue\n",
    "                    plt.figure(figsize=(5, 3))\n",
    "                    df = pd.DataFrame.from_dict({\n",
    "                        'Gene expression':\n",
    "                        gene_group_cl[group][cl],\n",
    "                        'Clonotype': [cl] * len(gene_group_cl[group][cl])\n",
    "                    })\n",
    "                    df_agg = pd.DataFrame.from_dict({\n",
    "                        'Clonotype': ['Aggregated'] * len(agg_remove_query),\n",
    "                        'Aggregated gene expression':\n",
    "                        agg_remove_query\n",
    "                    })\n",
    "\n",
    "                    sns.distplot(df_agg['Aggregated gene expression'],\n",
    "                                 hist=False,\n",
    "                                 kde=True,\n",
    "                                 bins=int(180 / 18),\n",
    "                                 color='black',\n",
    "                                 hist_kws={'edgecolor': 'black'},\n",
    "                                 kde_kws={\n",
    "                                     'linewidth': 2,\n",
    "                                     'bw': 0.2,\n",
    "                                     'alpha': 0.5\n",
    "                                 },\n",
    "                                 norm_hist=True,\n",
    "                                 label='Aggregated')\n",
    "\n",
    "                    sns.distplot(df['Gene expression'],\n",
    "                                 hist=True,\n",
    "                                 kde=True,\n",
    "                                 bins=int(180 / 18),\n",
    "                                 color='red',\n",
    "                                 hist_kws={'edgecolor': 'none'},\n",
    "                                 kde_kws={\n",
    "                                     'linewidth': 2,\n",
    "                                     'bw': 0.5,\n",
    "                                     'alpha': 0.5\n",
    "                                 },\n",
    "                                 norm_hist=True,\n",
    "                                 label=cl)\n",
    "\n",
    "                    #                 x1, bins1, p1 = plt.hist(gene_group_cl[group][cl],label=cl,alpha=0.3,\n",
    "                    #                         range=(lowest,highest),bins=50)\n",
    "                    #                 x2, bins2, p2 = plt.hist(agg_remove_query,label='All Clonotypes',\n",
    "                    #                          alpha=0.3,range=(lowest,highest),bins=50)\n",
    "                    #                 all_heights_to_find_max = []\n",
    "                    #                 for item in p1:\n",
    "                    #                     item.set_height(item.get_height()/sum(x1))\n",
    "                    #                     all_heights_to_find_max.append(item.get_height())\n",
    "                    #                 for item in p2:\n",
    "                    #                     item.set_height(item.get_height()/sum(x2))\n",
    "                    #                     all_heights_to_find_max.append(item.get_height())\n",
    "                    #                 max_height = max(all_heights_to_find_max)\n",
    "\n",
    "                    #                 plt.ylim([0,max_height*1.1])\n",
    "                    pval_to_show = kstest(\n",
    "                        gene_group_cl[group][cl],\n",
    "                        agg_remove_query)[1]  #,alternative='two-sided'\n",
    "                    #             kstest_less_pval = kstest_less[1]\n",
    "\n",
    "                    plt.title(cl + ' ' + group + '\\n pval_greater = ' +\n",
    "                              str(round(pval_to_show, 2)))\n",
    "                    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                    plt.savefig(\n",
    "                        './vectorized_figures/figure3e_distribution.pdf')\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_values_all_precorrected = []\n",
    "for group in ks_values_all:\n",
    "    p_values_all_precorrected = p_values_all_precorrected + ks_values_all[\n",
    "        group][1]\n",
    "\n",
    "p_values_all_corrected = stats.multitest.multipletests(\n",
    "    p_values_all_precorrected,\n",
    "    alpha=0.05,\n",
    "    method='fdr_bh',\n",
    "    is_sorted=False,\n",
    "    returnsorted=False)\n",
    "conversion_dict = dict(zip(p_values_all_precorrected, p_values_all_corrected[1]))\n",
    "conversion_dict[0.001186844222397343]\n",
    "#conversion_dict[0.0245150836249218]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this for each puck to be able to do aggregated analysis below\n",
    "for puck in [puck8, puck9, puck10]:\n",
    "\n",
    "    remove = []\n",
    "\n",
    "    aggregated_p_values_filt = {\n",
    "        i: puck.aggregated_p_values[i]\n",
    "        for i in puck.aggregated_p_values if i not in remove\n",
    "    }\n",
    "    puck.aggregated_p_values_filt = aggregated_p_values_filt\n",
    "    aggregated_p_values_adjusted = {\n",
    "        i.split(' (')[0]: aggregated_p_values_filt[i]\n",
    "        for i in aggregated_p_values_filt\n",
    "    }  #i\n",
    "    aggregated_p_values_adjusted\n",
    "    pre_adjustment = list(puck.aggregated_p_values.values())\n",
    "    post_adjustment = statsmodels.stats.multitest.multipletests(\n",
    "        pre_adjustment,\n",
    "        alpha=0.05,\n",
    "        method='fdr_bh',\n",
    "        is_sorted=False,\n",
    "        returnsorted=False)[1]\n",
    "    adjustment_dict = dict(zip(pre_adjustment, post_adjustment))\n",
    "    aggregated_p_values_adjusted = {\n",
    "        i: adjustment_dict[aggregated_p_values_adjusted[i]]\n",
    "        for i in aggregated_p_values_adjusted\n",
    "    }\n",
    "    df = pd.DataFrame.from_dict(aggregated_p_values_adjusted, orient='index')\n",
    "    df.columns = ['p-value']\n",
    "    df = df.round(3)\n",
    "\n",
    "    df = df[~df.index.isin(remove)]\n",
    "    display(df)\n",
    "    sns.heatmap(df)\n",
    "    ##\n",
    "    ##\n",
    "    aggregated_effect_size = {\n",
    "        i: puck.aggregated_effect_size[i]\n",
    "        for i in puck.aggregated_effect_size if i not in remove\n",
    "    }  #i\n",
    "    aggregated_effect_size = {\n",
    "        i.split(' (')[0]: aggregated_effect_size[i]\n",
    "        for i in aggregated_effect_size\n",
    "    }  #i\n",
    "\n",
    "    df2 = pd.DataFrame.from_dict(aggregated_effect_size, orient='index')\n",
    "    df2.columns = ['Effect size']\n",
    "    df2 = df2.round(3)\n",
    "\n",
    "    plt.figure(figsize=(1, 10))\n",
    "    df2 = df2[~df2.index.isin(remove)]\n",
    "    df2.sort_values('Effect size', inplace=True, ascending=False)\n",
    "    display(df2)\n",
    "    puck.df2 = df2\n",
    "    puck.aggregated_p_values_filt = aggregated_p_values\n",
    "    set_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    sns.heatmap(df2,\n",
    "                cmap=set_cmap,\n",
    "                center=0,\n",
    "                yticklabels=True,\n",
    "                linewidths=.5,\n",
    "                vmin=-1,\n",
    "                vmax=1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./vectorized_figures/figure3c_{}.pdf'.format(puck.puck_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###### Aggregated analysis across all pucks\n",
    "\n",
    "aggregated_and_corrected_values = {}\n",
    "for geneset in puck8.aggregated_p_values_filt:\n",
    "    if geneset == 'Good response to ICP (from Sade-Feldman et al. 2018)':\n",
    "        continue\n",
    "    aggregated_and_corrected_values[geneset] = scipy.stats.combine_pvalues([\n",
    "        puck8.aggregated_p_values_filt[geneset],\n",
    "        puck9.aggregated_p_values_filt[geneset],\n",
    "        puck10.aggregated_p_values_filt[geneset]\n",
    "    ])[1]\n",
    "\n",
    "pre_adjustment = list(aggregated_and_corrected_values.values())\n",
    "post_adjustment = statsmodels.stats.multitest.multipletests(\n",
    "    pre_adjustment,\n",
    "    alpha=0.05,\n",
    "    method='fdr_bh',\n",
    "    is_sorted=False,\n",
    "    returnsorted=False)[1]\n",
    "adjustment_dict = dict(zip(pre_adjustment, post_adjustment))\n",
    "aggregated_and_corrected_values = {\n",
    "    i: adjustment_dict[aggregated_and_corrected_values[i]]\n",
    "    for i in aggregated_and_corrected_values\n",
    "}\n",
    "\n",
    "print(aggregated_and_corrected_values)\n",
    "aggregated_effect_size_all_pucks = {}\n",
    "for geneset in list(puck8.df2.index):\n",
    "    if geneset == 'Good response to ICP (from Sade-Feldman et al. 2018)':\n",
    "        continue\n",
    "    print([\n",
    "        float(puck8.df2[puck8.df2.index == geneset]['Effect size']),\n",
    "        float(puck9.df2[puck9.df2.index == geneset]['Effect size']),\n",
    "        float(puck10.df2[puck10.df2.index == geneset]['Effect size'])\n",
    "    ])\n",
    "    aggregated_effect_size_all_pucks[geneset] = np.mean([\n",
    "        float(puck8.df2[puck8.df2.index == geneset]['Effect size']),\n",
    "        float(puck9.df2[puck9.df2.index == geneset]['Effect size']),\n",
    "        float(puck10.df2[puck10.df2.index == geneset]['Effect size'])\n",
    "    ])\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(aggregated_effect_size_all_pucks, orient='index')\n",
    "df3.columns = ['Effect size']\n",
    "df3 = df3.round(3)\n",
    "\n",
    "plt.figure(figsize=(1, 10))\n",
    "df3 = df3[~df3.index.isin(remove)]\n",
    "df3.sort_values('Effect size', inplace=True, ascending=False)\n",
    "display(df3)\n",
    "set_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "this_plot = sns.heatmap(df3,\n",
    "                        cmap=set_cmap,\n",
    "                        center=0,\n",
    "                        yticklabels=True,\n",
    "                        linewidths=.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure3d.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot two distributions of gene expression based on distances split\n",
    "puck = puck8\n",
    "gene_group_cl_below_median = {}\n",
    "gene_group_cl_above_median = {}\n",
    "\n",
    "for clonotype in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "    if clonotype not in cl_distances:\n",
    "        continue\n",
    "    below_cl_locs = [\n",
    "        i[0] for i in cl_distances[clonotype] if i[1] <= cl_medians[clonotype]\n",
    "    ]  # if i in puck.tumor_beads\n",
    "    above_cl_locs = [\n",
    "        i[0] for i in cl_distances[clonotype] if i[1] > cl_medians[clonotype]\n",
    "    ]\n",
    "    below_bcs = [puck.loc_to_bc_s1[i] for i in below_cl_locs]\n",
    "    above_bcs = [puck.loc_to_bc_s1[i] for i in above_cl_locs]\n",
    "    all_cl_bcs = all_cl_bcs + cl_bcs\n",
    "    if len(below_cl_locs) < 10:\n",
    "        continue\n",
    "    if len(above_cl_locs) < 10:\n",
    "        continue\n",
    "    for group in gene_groups:\n",
    "        # This is a distribution of the summed normalized expression of all the genes in each group\n",
    "        if group not in gene_group_cl_below_median:\n",
    "            gene_group_cl_below_median[group] = {}\n",
    "        if group not in gene_group_cl_above_median:\n",
    "            gene_group_cl_above_median[group] = {}\n",
    "\n",
    "        gene_group_cl_below_median[group][clonotype] = list(\n",
    "            puck.s1_dge_fmtd_norm.loc[below_bcs,\n",
    "                                      gene_groups[group]].sum(axis=1))\n",
    "        gene_group_cl_above_median[group][clonotype] = list(\n",
    "            puck.s1_dge_fmtd_norm.loc[above_bcs,\n",
    "                                      gene_groups[group]].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cl_medians_pretty = {\n",
    "    pretty_clonotype_name[i]: cl_medians[i]\n",
    "    for i in cl_medians if i in pretty_clonotype_name\n",
    "}\n",
    "cl_medians_pretty['TCR-7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "significant_clonotypes\n",
    "significant_clonotypes_tumor_filt = []\n",
    "for cl in significant_clonotypes:\n",
    "    tumor_locs_for_this_cl = [\n",
    "        loc for loc in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if loc in puck.tumor_beads\n",
    "    ]\n",
    "    if len(tumor_locs_for_this_cl) >= 10:\n",
    "        print(cl, pretty_clonotype_name[cl], len(tumor_locs_for_this_cl))\n",
    "        significant_clonotypes_tumor_filt.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "significant_clonotypes = significant_clonotypes_tumor_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot for each clonotype and geneset x-axis geneset expressoin, split by distance median.\n",
    "def make_plotting_df():\n",
    "    pval_recorder = []\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plotting_df = {}\n",
    "    plotting_df['geneset'] = []\n",
    "    plotting_df['clonotype'] = []\n",
    "    plotting_df['greater_or_less'] = []\n",
    "    plotting_df['expression'] = []\n",
    "\n",
    "    for group in gene_group_cl_below_median:\n",
    "        for cl in list(gene_group_cl_below_median[group].keys()\n",
    "                       ):  ### changed to different group to test\n",
    "            if cl in gene_group_cl_below_median[group]:\n",
    "                lowest = min(gene_group_cl_below_median[group][cl])\n",
    "                highest = max(gene_group_cl_above_median[group][cl])\n",
    "                for i in range(len(gene_group_cl_below_median[group][cl])):\n",
    "                    plotting_df['geneset'].append(group)\n",
    "                    plotting_df['clonotype'].append(cl)\n",
    "                    plotting_df['greater_or_less'].append('less')\n",
    "                plotting_df['expression'] = plotting_df[\n",
    "                    'expression'] + gene_group_cl_below_median[group][cl]\n",
    "\n",
    "                for i in range(len(gene_group_cl_above_median[group][cl])):\n",
    "                    plotting_df['geneset'].append(group)\n",
    "                    plotting_df['clonotype'].append(cl)\n",
    "                    plotting_df['greater_or_less'].append('greater')\n",
    "                plotting_df['expression'] = plotting_df[\n",
    "                    'expression'] + gene_group_cl_above_median[group][cl]\n",
    "                if cl == 'CASSPRTSGRYNEQFF':\n",
    "                    pass\n",
    "\n",
    "                pval = kstest(gene_group_cl_below_median[group][cl],\n",
    "                              gene_group_cl_above_median[group][cl])[1]\n",
    "                if group in [\n",
    "                        'Bad response to ICP (from Sade-Feldman et al. 2018)',\n",
    "                        'Terminal exhausted (from Miller et al. 2019 and Feldman)'\n",
    "                ]:\n",
    "                    pval_recorder.append(pval)\n",
    "                if group == 'Bad response to ICP (from Sade-Feldman et al. 2018)':\n",
    "                    print(cl, pval)\n",
    "                if pval < 0.05:\n",
    "                    print('KS', cl, group, pval)\n",
    "                pval = scipy.stats.ttest_ind(\n",
    "                    gene_group_cl_below_median[group][cl],\n",
    "                    gene_group_cl_above_median[group][cl])[1]\n",
    "                if pval < 0.05:\n",
    "                    print('TT', cl, group, pval)\n",
    "\n",
    "    #                 plt.title('{} {} pval: {}'.format(group,cl,pval))\n",
    "    #                 plt.legend()\n",
    "    #                 plt.show()\n",
    "    plotting_df = pd.DataFrame(plotting_df)\n",
    "    return plotting_df, pval_recorder\n",
    "\n",
    "\n",
    "plotting_df, pval_recorder = make_plotting_df()\n",
    "genesets = list(set(plotting_df.geneset))\n",
    "for geneset in genesets:\n",
    "    if geneset != 'Bad response to ICP (from Sade-Feldman et al. 2018)':\n",
    "        continue\n",
    "    plotting_df, pval_recorder = make_plotting_df()\n",
    "    #plotting_df = plotting_df[plotting_df.clonotype == 'CASSPRTSGRYNEQFF']\n",
    "    plotting_df['log_expression'] = -np.log10(plotting_df['expression'])\n",
    "    #plotting_df = plotting_df[plotting_df.geneset == 'Bad response to ICP (from Sade-Feldman et al. 2018)']\n",
    "    plotting_df = plotting_df[plotting_df.geneset == geneset]\n",
    "    if len(plotting_df) == 0:\n",
    "        continue\n",
    "    #plotting_df = plotting_df[plotting_df.geneset != 'Bad response to ICP (from Sade-Feldman et al. 2018)']\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    # sns.violinplot(x=\"geneset\", y=\"expression\", hue=\"greater_or_less\",\n",
    "    #                     data=plotting_df, palette=\"Set1\",split=True,bw=0.5)\n",
    "\n",
    "    # reorder clonotypes for plotting\n",
    "    cl_to_plot = list(\n",
    "        gene_group_cl_below_median[geneset].keys()\n",
    "    ) \n",
    "\n",
    "    # Heatmap merged of e\n",
    "    plotting_df = plotting_df[plotting_df.clonotype.isin(cl_to_plot)]\n",
    "    plotting_df.clonotype = plotting_df.clonotype.astype(\"category\")\n",
    "    plotting_df.clonotype.cat.set_categories(cl_to_plot, inplace=True)\n",
    "    plotting_df.sort_values([\"clonotype\"], inplace=True)\n",
    "    plotting_df.clonotype = plotting_df.clonotype.astype(str)\n",
    "    plotting_df.clonotype = [\n",
    "        pretty_clonotype_name[cl] for cl in list(plotting_df.clonotype)\n",
    "    ]\n",
    "    plotting_df.sort_values([\"clonotype\"], inplace=True)\n",
    "    color_palette_to_use = [sns.color_palette(\"tab10\")[2]\n",
    "                            ] + [sns.color_palette(\"tab10\")[4]]\n",
    "    sns.violinplot(x=\"clonotype\",\n",
    "                   y=\"expression\",\n",
    "                   hue=\"greater_or_less\",\n",
    "                   data=plotting_df,\n",
    "                   palette=color_palette_to_use,\n",
    "                   split=True,\n",
    "                   bw=0.5)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(geneset)\n",
    "    plt.savefig('./vectorized_figures/figure3f_{}.pdf'.format(geneset))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_values_all_corrected = stats.multitest.multipletests(pval_recorder,\n",
    "                                                       alpha=0.05,\n",
    "                                                       method='fdr_bh',\n",
    "                                                       is_sorted=False,\n",
    "                                                       returnsorted=False)\n",
    "conversion_dict = dict(zip(pval_recorder, p_values_all_corrected[1]))\n",
    "\n",
    "#conversion_dict[0.001186844222397343]\n",
    "#conversion_dict[0.0245150836249218]\n",
    "conversion_dict[0.00023847725260117691]\n",
    "conversion_dict[0.020739064856711915]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# clonotypes with at least 10 beads across all samples.\n",
    "cter = {}\n",
    "for puck in [puck8, puck9, puck10]:\n",
    "    for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "        if cl not in puck.clonotypes['1b']:\n",
    "            continue\n",
    "        if cl not in cter:\n",
    "            cter[cl] = 0\n",
    "        cter[cl] += len(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "cls_to_use = [i for i in cter if cter[i] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For geneset NMF analysis for heatmaps # betas, at least 10 beads in tumor\n",
    "puck = puck8\n",
    "\n",
    "all_genes = []\n",
    "for group in gene_groups:\n",
    "    all_genes = all_genes + gene_groups[group]\n",
    "all_genes = list(set(all_genes))\n",
    "all_genes_pucks = list(\n",
    "    set(list(set(puck8.s1_dge_fmtd.columns) & set(puck9.s1_dge_fmtd.columns)))\n",
    "    & set(puck10.s1_dge_fmtd.columns))\n",
    "all_genes = [i for i in all_genes if i in all_genes_pucks]\n",
    "\n",
    "tcr_bcs_in_tumor = []\n",
    "for tcr in puck.tcr_loc_dict_s1_filtered3:\n",
    "    #     if tcr not in cls_to_use: ### COMMENT OUT FOR ONLY ONE PUCK ANALYSIS\n",
    "    #         continue\n",
    "    if tcr not in puck.clonotypes['1b']:\n",
    "        continue\n",
    "    tumor_beads_cl = set([\n",
    "        i for i in list(set(puck.tcr_loc_dict_s1_filtered3[tcr]))\n",
    "        if i in puck.tumor_beads\n",
    "    ])\n",
    "    if len(tumor_beads_cl) < 10:  # < 10: ### change to = 0 for all reps\n",
    "        continue\n",
    "    tcr_bcs_in_tumor = tcr_bcs_in_tumor + [\n",
    "        puck.loc_to_bc_s1[i] for i in tumor_beads_cl\n",
    "    ]\n",
    "dge = puck.s1_dge_fmtd_norm[all_genes]\n",
    "dge = dge[dge.index.isin(tcr_bcs_in_tumor)]\n",
    "dge['rep'] = ['p8'] * len(dge)\n",
    "\n",
    "# puck = puck9\n",
    "# tcr_bcs_in_tumor = []\n",
    "# for tcr in puck.tcr_loc_dict_s1_filtered3:\n",
    "#     if tcr not in cls_to_use:\n",
    "#         continue\n",
    "#     if len(puck.tcr_loc_dict_s1_filtered3[tcr]) == 0:\n",
    "#         continue\n",
    "#     tcr_bcs_in_tumor = tcr_bcs_in_tumor + [puck.loc_to_bc_s1[i] for i in list(set(puck.tcr_loc_dict_s1_filtered3[tcr]))]\n",
    "# dge9 = puck.s1_dge_fmtd_norm[all_genes]\n",
    "# dge9 = dge9[dge9.index.isin(tcr_bcs_in_tumor)]\n",
    "# dge9['rep'] = ['p9']*len(dge9)\n",
    "\n",
    "# puck = puck10\n",
    "# tcr_bcs_in_tumor = []\n",
    "# for tcr in puck.tcr_loc_dict_s1_filtered3:\n",
    "#     if tcr not in cls_to_use:\n",
    "#         continue\n",
    "#     if len(puck.tcr_loc_dict_s1_filtered3[tcr]) == 0:\n",
    "#         continue\n",
    "#     tcr_bcs_in_tumor = tcr_bcs_in_tumor + [puck.loc_to_bc_s1[i] for i in list(set(puck.tcr_loc_dict_s1_filtered3[tcr]))]\n",
    "# dge10 = puck.s1_dge_fmtd_norm[all_genes]\n",
    "# dge10 = dge10[dge10.index.isin(tcr_bcs_in_tumor)]\n",
    "# dge10['rep'] = ['p10']*len(dge10)\n",
    "\n",
    "# dge = pd.concat([dge,dge9,dge10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# NMF testing\n",
    "n_components = 10\n",
    "dge_values_only = dge.drop(columns=['rep'])\n",
    "X = np.array(dge_values_only)\n",
    "model = NMF(n_components, init='random', random_state=0, max_iter=1000)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_\n",
    "\n",
    "# Get top genes for each factor\n",
    "nmf_factors_to_genes = {}\n",
    "nmf_genes = list(dge.columns)  # these are all the genes\n",
    "\n",
    "###### change to loadings\n",
    "nmf_report = {}\n",
    "for factor in range(n_components):\n",
    "    H[factor, :]\n",
    "    nmf_report[factor] = H[factor, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clonotypes passing 10 filter in tumor\n",
    "puck = puck8\n",
    "cl_to_plot = []\n",
    "for cl in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "    if cl not in puck.clonotypes['1b']:\n",
    "        continue\n",
    "    if len(set(puck.tcr_loc_dict_s1_filtered3[cl])) < 10:\n",
    "        continue\n",
    "    in_tumor = [\n",
    "        i for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if i in puck.tumor_beads\n",
    "    ]\n",
    "    if len(set(in_tumor)) < 10:\n",
    "        continue\n",
    "    else:\n",
    "        cl_to_plot.append(cl)\n",
    "cl_to_plot\n",
    "\n",
    "# cl_to_plot = cls_to_use #FOR MERGED REPLICATES#\n",
    "\n",
    "nmf_df = {}\n",
    "\n",
    "for puck in [puck8]:  ######  CHANGE THIS\n",
    "    if puck == puck8:\n",
    "        puck.nmf_dge = dge[dge['rep'] == 'p8']\n",
    "    elif puck == puck9:\n",
    "        puck.nmf_dge = dge[dge['rep'] == 'p9']\n",
    "    elif puck == puck10:\n",
    "        puck.nmf_dge = dge[dge['rep'] == 'p10']\n",
    "    puck.nmf_dge.drop(columns=['rep'], inplace=True)\n",
    "\n",
    "for cl in tqdm(cl_to_plot):\n",
    "\n",
    "    for nmf_group in nmf_report:\n",
    "        if nmf_group not in nmf_df:\n",
    "            nmf_df[nmf_group] = []\n",
    "\n",
    "        this_cl_dist = []\n",
    "        other_cl_dist = []\n",
    "        for puck in [puck8]:  ######CHANGE THIS, puck9, puck10\n",
    "            if cl not in puck.tcr_loc_dict_s1_filtered3:\n",
    "                continue\n",
    "            bcs_for_this_cl = set(\n",
    "                list([\n",
    "                    puck.loc_to_bc_s1[i]\n",
    "                    for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "                    if i in puck.tumor_beads\n",
    "                ]))\n",
    "            puck.dge_filt = puck.nmf_dge[puck.nmf_dge.index.isin(\n",
    "                bcs_for_this_cl)]\n",
    "            this_cl_dist = this_cl_dist + [\n",
    "                sum(nmf_report[nmf_group] * i) for i in np.array(puck.dge_filt)\n",
    "            ]\n",
    "            dge_filt_all_others = puck.nmf_dge[~puck.nmf_dge.index.\n",
    "                                               isin(bcs_for_this_cl)]\n",
    "            other_cl_dist = other_cl_dist + [\n",
    "                sum(nmf_report[nmf_group] * i)\n",
    "                for i in np.array(dge_filt_all_others)\n",
    "            ]\n",
    "        nmf_df[nmf_group].append(cohens_d(this_cl_dist, other_cl_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nmf_df = pd.DataFrame(nmf_df)\n",
    "nmf_df.index = [pretty_clonotype_name[i] for i in cl_to_plot]\n",
    "\n",
    "corrMatrix = nmf_df.T.corr()\n",
    "significant_enriched = [\n",
    "    pretty_clonotype_name[i] for i in cl_agg_to_tumor_enrichment_average\n",
    "    if cl_agg_to_tumor_enrichment_average[i] > 0\n",
    "]\n",
    "significant_depleted = [\n",
    "    pretty_clonotype_name[i] for i in cl_agg_to_tumor_enrichment_average\n",
    "    if cl_agg_to_tumor_enrichment_average[i] < 0\n",
    "]\n",
    "\n",
    "lut = {}\n",
    "for i in corrMatrix.columns:\n",
    "    if i in significant_enriched:\n",
    "        lut[i] = 'orange'\n",
    "    elif i in significant_depleted:\n",
    "        lut[i] = 'gray'\n",
    "    else:\n",
    "        lut[i] = 'gray'\n",
    "names = corrMatrix.index\n",
    "row_colors = names.map(lut)\n",
    "cmap_use = sns.color_palette(\"vlag\", as_cmap=True)\n",
    "#corrMatrix.index = [ugly_clonotype_name[i] for i in corrMatrix.index]\n",
    "sns.clustermap(corrMatrix,\n",
    "               xticklabels=True,\n",
    "               yticklabels=True,\n",
    "               cmap=cmap_use,\n",
    "               row_colors=row_colors)  #, annot=True #row_colors=row_colors,\n",
    "#plt.savefig('./vectorized_figures/sf7_corr_plot_sig_only.pdf')\n",
    "plt.savefig('./vectorized_figures/sf7_corr_plot_all.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hm_violin_below = {}\n",
    "hm_violin_greater = {}\n",
    "cl_names = []\n",
    "for gene_group in gene_group_cl_below_median:\n",
    "    if gene_group not in hm_violin_below:\n",
    "        hm_violin_below[gene_group] = []\n",
    "    if gene_group not in hm_violin_greater:\n",
    "        hm_violin_greater[gene_group] = []\n",
    "    for cl in gene_group_cl_below_median[gene_group]:\n",
    "        hm_violin_below[gene_group].append(\n",
    "            np.mean(gene_group_cl_below_median[gene_group][cl]))\n",
    "        hm_violin_greater[gene_group].append(\n",
    "            np.mean(gene_group_cl_above_median[gene_group][cl]))\n",
    "\n",
    "        if len(cl_names) < len(hm_violin_greater[gene_group]):\n",
    "            cl_names.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gene_groups_all = []\n",
    "hm_violin_combined = []\n",
    "for gene_group in gene_group_cl_below_median:\n",
    "    gene_groups_all.append(gene_group)\n",
    "    hm_violin_combined.append(hm_violin_below[gene_group])\n",
    "    hm_violin_combined.append(hm_violin_greater[gene_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_groups_combined = [i + '_below' for i in gene_groups_all\n",
    "                        ] + [i + '_above' for i in gene_groups_all]\n",
    "\n",
    "hm_violin_combined = pd.DataFrame(hm_violin_combined)\n",
    "hm_violin_combined.columns = cl_names\n",
    "hm_violin_combined.index = gene_groups_combined\n",
    "hm_violin_combined.sort_index(inplace=True)\n",
    "sns.clustermap(hm_violin_combined,\n",
    "               xticklabels=True,\n",
    "               yticklabels=True,\n",
    "               row_cluster=False,\n",
    "               z_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_dict = {i: ks_values_all[i][0] for i in ks_values_all}\n",
    "\n",
    "cls_order = cls_order[\n",
    "    0:len(test_dict['Bad response to ICP (from Sade-Feldman et al. 2018)']\n",
    "          )]  ## custom stuff\n",
    "#cls_order = cls_order[0] ## custom stuff\n",
    "test_dict['clonotype'] = cls_order\n",
    "\n",
    "cmap_use = sns.color_palette(\"vlag\",\n",
    "                             as_cmap=True)  #sns.diverging_palette(240, 10)\n",
    "\n",
    "metagene_df = pd.DataFrame.from_dict(test_dict)\n",
    "\n",
    "metagene_df.set_index(['clonotype'], inplace=True)\n",
    "metagene_df\n",
    "#metagene_df = metagene_df[metagene_df.index.isin(significant_clonotypes)]\n",
    "metagene_df = metagene_df.rename(pretty_clonotype_name)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "metagene_df.sort_values('Bad response to ICP (from Sade-Feldman et al. 2018)',\n",
    "                        inplace=True)\n",
    "sns.heatmap(metagene_df, cmap=cmap_use, yticklabels=True, xticklabels=True)\n",
    "sns.clustermap(metagene_df,\n",
    "               cmap=cmap_use,\n",
    "               figsize=(10, 20),\n",
    "               yticklabels=True,\n",
    "               xticklabels=True)  # 0 is rows, 1 is column\n",
    "plt.savefig('./vectorized_figures/figure6d.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cl_agg_to_tumor_enrichment_average = {\n",
    "    cl: np.mean(cl_agg_to_tumor_enrichment[cl])\n",
    "    for cl in cl_agg_to_tumor_enrichment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "corrMatrix = metagene_df.T.corr()\n",
    "\n",
    "# Set colors for each group\n",
    "# significant_enriched = ['TCR-1','TCR-4','TCR-3','TCR-5','TCR-6']\n",
    "# significant_depleted = ['TCR-2','TCR-6','TCR-21','TCR-9']\n",
    "\n",
    "# significant_enriched = list(plot_df[(plot_df.tumor_enrichment>=0) & (plot_df.volcano_merged>-np.log10(0.05))].clonotype)\n",
    "# significant_depleted = list(plot_df[(plot_df.tumor_enrichment<0) & (plot_df.volcano_merged>-np.log10(0.05))].clonotype)\n",
    "significant_enriched = [\n",
    "    pretty_clonotype_name[i] for i in cl_agg_to_tumor_enrichment_average\n",
    "    if cl_agg_to_tumor_enrichment_average[i] > 0\n",
    "]\n",
    "significant_depleted = [\n",
    "    pretty_clonotype_name[i] for i in cl_agg_to_tumor_enrichment_average\n",
    "    if cl_agg_to_tumor_enrichment_average[i] < 0\n",
    "]\n",
    "\n",
    "lut = {}\n",
    "for i in corrMatrix.columns:\n",
    "    if i in significant_enriched:\n",
    "        lut[i] = 'orange'\n",
    "    elif i in significant_depleted:\n",
    "        lut[i] = 'gray'\n",
    "    else:\n",
    "        lut[i] = 'gray'\n",
    "names = corrMatrix.index\n",
    "row_colors = names.map(lut)\n",
    "sns.clustermap(corrMatrix,\n",
    "               xticklabels=True,\n",
    "               yticklabels=True,\n",
    "               row_colors=row_colors,\n",
    "               cmap=cmap_use)  #, annot=True\n",
    "#plt.savefig('./vectorized_figures/sf7_corr_plot_sig_only.pdf')\n",
    "plt.savefig('./vectorized_figures/sf7_corr_plot_all.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = np.array(corrMatrix)\n",
    "\n",
    "#this is your array with the values\n",
    "X = dataset\n",
    "\n",
    "#This function creates the classifier\n",
    "#n_clusters is the number of clusters you want to use to classify your data\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(kmeans.labels_)\n",
    "corrMatrix['kmeans'] = kmeans.labels_\n",
    "corrMatrix.sort_values('kmeans', inplace=True)\n",
    "column_order = list(corrMatrix.index) + ['kmeans']\n",
    "corrMatrix = corrMatrix[column_order]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corrMatrix, xticklabels=True, yticklabels=True, cmap=cmap_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metagene_df['clonotype'] = list(metagene_df.index)\n",
    "metagene_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cl_to_plot = significant_clonotypes + [\n",
    "    'TCR-1', 'TCR-2', 'TCR-3'\n",
    "]  #list(metagene_df.clonotype) #significant_clonotypes\n",
    "metagene_df = metagene_df[metagene_df.clonotype.isin(cl_to_plot)]\n",
    "\n",
    "metagene_df.clonotype = metagene_df.clonotype.astype(\"category\")\n",
    "metagene_df.clonotype.cat.set_categories(cl_to_plot, inplace=True)\n",
    "\n",
    "metagene_df.sort_values([\"clonotype\"], inplace=True)\n",
    "metagene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metagene_df.sort_values('Bad response to ICP (from Sade-Feldman et al. 2018)',\n",
    "                        ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metagene_df.clonotype = metagene_df.clonotype.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try a dot plot instead\n",
    "group = 'Bad response to ICP (from Sade-Feldman et al. 2018)'\n",
    "metagene_df.sort_values(group, ascending=False, inplace=True)\n",
    "metagene_df_group = metagene_df[[group, 'clonotype']].copy()\n",
    "\n",
    "g = sns.PairGrid(metagene_df_group,\n",
    "                 x_vars='Bad response to ICP (from Sade-Feldman et al. 2018)',\n",
    "                 y_vars=[\"clonotype\"],\n",
    "                 height=5,\n",
    "                 aspect=.8)\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "# g = sns.PairGrid(metagene_df.sort_values('Bad response to ICP (from Sade-Feldman et al. 2018)',\n",
    "#                                          ascending=False),\n",
    "#                  x_vars=metagene_df.columns[:8], y_vars=[\"clonotype\"],\n",
    "#                  height=10, aspect=.25)\n",
    "\n",
    "g.map(sns.stripplot,\n",
    "      size=10,\n",
    "      orient=\"h\",\n",
    "      jitter=False,\n",
    "      linewidth=1,\n",
    "      edgecolor=\"w\",\n",
    "      color='black')  # palette=\"flare_r\",\n",
    "xmin = min([i for i in list(np.min(metagene_df_group)) if type(i) != str])\n",
    "xmax = max([i for i in list(np.max(metagene_df_group)) if type(i) != str])\n",
    "g.set(xlim=(xmin * 1.5, xmax * 1.5), xlabel=\"Effect size Cohen's\",\n",
    "      ylabel=\"\")  # 0.5 for ks test and -2.5, 2.5 for t\n",
    "titles = list(metagene_df_group.columns)\n",
    "\n",
    "for ax, title in zip(g.axes.flat, titles):\n",
    "\n",
    "    # Set a different title for each axes\n",
    "    ax.set(title=title)\n",
    "\n",
    "    # Make the grid horizontal instead of vertical\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure3e_{}.pdf'.format(group))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "group = 'Terminal exhausted (from Miller et al. 2019 and Feldman)'\n",
    "metagene_df.sort_values(group, ascending=False, inplace=True)\n",
    "metagene_df_group = metagene_df[[group, 'clonotype']].copy()\n",
    "\n",
    "g = sns.PairGrid(metagene_df_group,\n",
    "                 x_vars=group,\n",
    "                 y_vars=[\"clonotype\"],\n",
    "                 height=5,\n",
    "                 aspect=.8)\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "# g = sns.PairGrid(metagene_df.sort_values('Bad response to ICP (from Sade-Feldman et al. 2018)',\n",
    "#                                          ascending=False),\n",
    "#                  x_vars=metagene_df.columns[:8], y_vars=[\"clonotype\"],\n",
    "#                  height=10, aspect=.25)\n",
    "\n",
    "g.map(sns.stripplot,\n",
    "      size=10,\n",
    "      orient=\"h\",\n",
    "      jitter=False,\n",
    "      linewidth=1,\n",
    "      edgecolor=\"w\",\n",
    "      color='black')  # palette=\"flare_r\",\n",
    "xmin = min([i for i in list(np.min(metagene_df_group)) if type(i) != str])\n",
    "xmax = max([i for i in list(np.max(metagene_df_group)) if type(i) != str])\n",
    "g.set(xlim=(xmin * 1.5, xmax * 1.5), xlabel=\"Effect size Cohen's\",\n",
    "      ylabel=\"\")  # 0.5 for ks test and -2.5, 2.5 for t\n",
    "titles = list(metagene_df_group.columns)\n",
    "\n",
    "for ax, title in zip(g.axes.flat, titles):\n",
    "\n",
    "    # Set a different title for each axes\n",
    "    ax.set(title=title)\n",
    "\n",
    "    # Make the grid horizontal instead of vertical\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure3e_{}.pdf'.format(group))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Find distance of genes from tumor boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck=puck9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Determine beads at the boundary of tumor and anything else\n",
    "def c(l1, l2):\n",
    "    return scipy.spatial.distance.cdist(l1, l2)\n",
    "\n",
    "\n",
    "distarray = c(puck.tumor_beads,\n",
    "              [j for j in [i for i in puck.tll_loc_cluster_dict]\n",
    "               ])  # tumor beads vs all beads\n",
    "\n",
    "all_beads = [j for j in [i for i in puck.tll_loc_cluster_dict]]\n",
    "boundary_points = []\n",
    "distance = 50\n",
    "skip_these_beads = set(\n",
    "    [])  # for the tumor beads that are just too far away from the boundary\n",
    "\n",
    "tumor_beads_loc_to_index = {}\n",
    "for i in range(len(puck.tumor_beads)):\n",
    "    tumor_beads_loc_to_index[puck.tumor_beads[i]] = i\n",
    "\n",
    "for each_loc in tqdm(puck.tumor_beads):\n",
    "\n",
    "    if each_loc in skip_these_beads:\n",
    "        continue\n",
    "\n",
    "    nearby_cell_types = [0, 0]  # First is tumor, second is anything else\n",
    "    # Get nearest points within distance\n",
    "\n",
    "    all_beads_indices = [\n",
    "        i for i, x in enumerate(distarray[puck.tumor_beads.index(each_loc), ])\n",
    "        if x < distance\n",
    "    ]\n",
    "    cell_types = [\n",
    "        puck.tll_loc_cluster_dict[all_beads[idx]] for idx in all_beads_indices\n",
    "    ]\n",
    "    for i in cell_types:\n",
    "        if i == 'Tumor':\n",
    "            nearby_cell_types[0] += 1\n",
    "        else:\n",
    "            nearby_cell_types[1] += 1\n",
    "    if (nearby_cell_types[0] / sum(nearby_cell_types) <= 0.9):\n",
    "        boundary_points.append(each_loc)\n",
    "\n",
    "    else:\n",
    "        skip_these_beads |= set([\n",
    "            all_beads[i] for i in all_beads_indices\n",
    "            if all_beads[i] in puck.tumor_beads\n",
    "        ])\n",
    "puck.boundary_points = boundary_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot boundary\n",
    "x = [i[0] for i in puck.boundary_points]\n",
    "y = [i[1] for i in puck.boundary_points]\n",
    "plt.scatter([\n",
    "    i[0] for i in puck.tll_loc_cluster_dict\n",
    "    if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "], [\n",
    "    i[1] for i in puck.tll_loc_cluster_dict\n",
    "    if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "])\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tcr_locs_all = []\n",
    "for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "    tcr_locs_all = tcr_locs_all + list(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "tcr_locs_all = list(set(tcr_locs_all))\n",
    "tcr_bcs_all = [puck.loc_to_bc_s1[loc] for loc in tcr_locs_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dge_df_to_use = puck.s1_dge_fmtd[puck.s1_dge_fmtd.index.isin(tcr_bcs_all)]\n",
    "dge_np = np.transpose(dge_df_to_use.to_numpy())\n",
    "\n",
    "gene_distributions = {}\n",
    "bcs = list(dge_df_to_use.index)\n",
    "genes = list(dge_df_to_use.columns)\n",
    "max_d = 0\n",
    "genes_used = []\n",
    "for geneidx in tqdm(range(np.shape(dge_np)[0])):\n",
    "    if sum(dge_np[geneidx]) < 100:\n",
    "        continue\n",
    "    genes_used.append(genes[geneidx])\n",
    "    bcs_for_this_gene = []\n",
    "    this_gene_counts = dge_np[geneidx]\n",
    "    for idx in range(len(bcs)):\n",
    "        bcs_for_this_gene = bcs_for_this_gene + [bcs[idx]] * int(\n",
    "            this_gene_counts[idx])\n",
    "    locs_for_this_gene = [puck.bc_loc_dict_s1[i] for i in bcs_for_this_gene]\n",
    "    distance_distribution = [\n",
    "        distance_between_points(pt, closest_node(pt, boundary_points))\n",
    "        for pt in locs_for_this_gene if pt in puck.tumor_beads\n",
    "    ]\n",
    "    gene_distributions[genes[geneidx]] = distance_distribution\n",
    "    if len(distance_distribution) > 0:\n",
    "        if max(distance_distribution) > max_d:\n",
    "            max_d = max(distance_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bin_number = 7\n",
    "bins = np.array(range(0, 2000, 200))\n",
    "bins = np.append(bins, [4000])\n",
    "bins = [int((max_d + 1) / 2), max_d + 1]\n",
    "bins = [1750, 3500]\n",
    "\n",
    "# Find number of beads in each bin to normalize\n",
    "bins_norm_count = [0] * len(bins)\n",
    "for idx in tqdm(range(len(tcr_locs_all))):\n",
    "    # using enumerate() + next() to find index of\n",
    "    # first element just greater than 0.6\n",
    "    point = tcr_locs_all[idx]\n",
    "    dis = distance_between_points(point, closest_node(point, boundary_points))\n",
    "    res = [x for x, val in enumerate(list(bins)) if val > dis][0]\n",
    "    #bins_norm_count[res] += 1\n",
    "    bins_norm_count[res] += sum(puck.s1_dge_fmtd.loc[puck.loc_to_bc_s1[\n",
    "        tcr_locs_all[idx]]])  # add counts of the bead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_plot = False\n",
    "if show_plot:\n",
    "    for gene in gene_distributions:\n",
    "        plt.hist(gene_distributions[gene])\n",
    "        plt.title(gene)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gene_dists_hists = []\n",
    "for gene in gene_distributions:\n",
    "    gene_dists_np_dig = np.digitize(gene_distributions[gene], bins)\n",
    "    gene_dists_np_cter = Counter(gene_dists_np_dig)\n",
    "    gene_dists_np_hist = [\n",
    "        gene_dists_np_cter[i] if i in gene_dists_np_cter else 0\n",
    "        for i in range(len(bins))\n",
    "    ]\n",
    "    #gene_dists_hists.append(np.array(gene_dists_np_hist))\n",
    "\n",
    "    # To normalize by counts in bins\n",
    "    #gene_dists_hists.append(np.divide(np.array(gene_dists_np_hist),np.array(bins_norm_count)))\n",
    "\n",
    "    # To normalize each row of genes\n",
    "    normalized_by_bins = np.nan_to_num(\n",
    "        np.divide(np.array(gene_dists_np_hist), np.array(bins_norm_count)))\n",
    "    gene_dists_hists.append(normalized_by_bins / sum(normalized_by_bins))\n",
    "# >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "# ...               [10, 2], [10, 4], [10, 0]])\n",
    "\n",
    "gene_dists_hists = np.array(gene_dists_hists)\n",
    "gene_dists_hists[np.isnan(gene_dists_hists)] = 0\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(gene_dists_hists)\n",
    "kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "cluster_num = 0\n",
    "genes_binned_hist_thisone = pd.DataFrame.from_dict(\n",
    "    dict(zip(hists_all_agg[cluster_num][1],\n",
    "                        hists_all_agg[cluster_num][0])\n",
    "        ),\n",
    "    orient='index')\n",
    "sns.heatmap(\n",
    "    genes_binned_hist_thisone)  #,yticklabels=1 #,vmax=1,col_cluster=False\n",
    "plt.title('Cluster: {}'.format(cluster_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Order tcr beads based on distance in tumor and find correlated genes\n",
    "tcr_dists = [\n",
    "    distance_between_points(pt, closest_node(pt, boundary_points))\n",
    "    for pt in tcr_locs_all if pt in puck.tumor_beads\n",
    "]\n",
    "tcr_bcs = [\n",
    "    puck.loc_to_bc_s1[pt] for pt in tcr_locs_all if pt in puck.tumor_beads\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tcr_tuples = [(i, j) for i, j in zip(tcr_dists, tcr_bcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tcr_tuples_sorted = sorted(tcr_tuples, key=lambda x: x[0])\n",
    "tcr_bcs_sorted = [i[1] for i in tcr_tuples_sorted]\n",
    "tcr_dists_sorted = [i[0] for i in tcr_tuples_sorted]\n",
    "\n",
    "tcr_bcs_sorted_df = puck.s1_dge_fmtd.reindex(tcr_bcs_sorted)\n",
    "\n",
    "for gene in tqdm(genes):\n",
    "\n",
    "    if sum(tcr_bcs_sorted_df[gene]) < 10:  \n",
    "        continue\n",
    "    m, b = np.polyfit(tcr_dists_sorted, tcr_bcs_sorted_df[gene], 1)\n",
    "    if m != 0:\n",
    "        print(m, b)\n",
    "        plt.figure()\n",
    "        plt.scatter(tcr_dists_sorted, tcr_bcs_sorted_df[gene], alpha=0.2)\n",
    "        plt.title(gene)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Boundary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distarray = c(puck.tumor_beads,\n",
    "              [j for j in [i for i in puck.tll_loc_cluster_dict]\n",
    "               ])  # tumor beads vs all beads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Determine beads at the boundary of tumor and anything else\n",
    "\n",
    "all_beads = [j for j in [i for i in puck.tll_loc_cluster_dict]]\n",
    "boundary_points = []\n",
    "distance = 50\n",
    "skip_these_beads = set(\n",
    "    [])  # for the tumor beads that are just too far away from the boundary\n",
    "\n",
    "tumor_beads_loc_to_index = {}\n",
    "for i in range(len(puck.tumor_beads)):\n",
    "    tumor_beads_loc_to_index[puck.tumor_beads[i]] = i\n",
    "\n",
    "for each_loc in tqdm(puck.tumor_beads):\n",
    "\n",
    "    if each_loc in skip_these_beads:\n",
    "        continue\n",
    "\n",
    "    nearby_cell_types = [0, 0]  # First is tumor, second is anything else\n",
    "    # Get nearest points within distance\n",
    "\n",
    "    all_beads_indices = [\n",
    "        i for i, x in enumerate(distarray[puck.tumor_beads.index(each_loc), ])\n",
    "        if x < distance\n",
    "    ]\n",
    "    cell_types = [\n",
    "        puck.tll_loc_cluster_dict[all_beadods[idx]] for idx in all_beads_indices\n",
    "    ]\n",
    "    for i in cell_types:\n",
    "        if i == 'Tumor':\n",
    "            nearby_cell_types[0] += 1\n",
    "        else:\n",
    "            nearby_cell_types[1] += 1\n",
    "    if (nearby_cell_types[0] / sum(nearby_cell_types) <= 0.9):\n",
    "        boundary_points.append(each_loc)\n",
    "\n",
    "    else:\n",
    "        skip_these_beads |= set([\n",
    "            all_beads[i] for i in all_beads_indices\n",
    "            if all_beads[i] in puck.tumor_beads\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "x = [i[0] for i in boundary_points]\n",
    "y = [i[1] for i in boundary_points]\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "f = interp1d(x, y)\n",
    "#f2 = interp1d(x, y, kind='cubic')\n",
    "xnew = np.linspace(min(x), max(x), num=100, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter([i[0] for i in testl], [i[1] for i in testl], label='lung', s=0.5)\n",
    "plt.scatter([i[0] for i in testtil], [i[1] for i in testtil],\n",
    "            label='til',\n",
    "            s=0.5)\n",
    "plt.scatter([i[0] for i in testtu], [i[1] for i in testtu],\n",
    "            label='tumor',\n",
    "            s=0.5)\n",
    "# plt.scatter([i[0] for i in testb],[i[1] for i in testb],label='B',s=0.5)\n",
    "plt.legend()\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "plt.plot(x, y, 'o', xnew, f(xnew), 'o')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter([i[0] for i in testl], [i[1] for i in testl], label='lung', s=0.5)\n",
    "plt.scatter([i[0] for i in testtil], [i[1] for i in testtil],\n",
    "            label='til',\n",
    "            s=0.5)\n",
    "plt.scatter([i[0] for i in testtu], [i[1] for i in testtu],\n",
    "            label='tumor',\n",
    "            s=0.5)\n",
    "# plt.scatter([i[0] for i in testb],[i[1] for i in testb],label='B',s=0.5)\n",
    "plt.legend()\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "plt.plot(x, y, 'o')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Distance to closest point in spline\n",
    "tcr_loc_dict_to_use = puck.tcr_loc_dict_s1_filtered3\n",
    "clonotype_distance_distributions = {}\n",
    "for cl in tqdm(tcr_loc_dict_to_use):\n",
    "    this_cl_beads = set(tcr_loc_dict_to_use[cl])\n",
    "    this_cl_beads_in_tumor = [\n",
    "        i for i in this_cl_beads if i in puck.tumor_beads\n",
    "    ]\n",
    "    if len(this_cl_beads_in_tumor) < 10:\n",
    "        continue\n",
    "    # Find distances between point and closest point\n",
    "    distance_distribution = [\n",
    "        distance_between_points(pt, closest_node(pt, boundary_points))\n",
    "        for pt in this_cl_beads if pt in puck.tumor_beads\n",
    "    ]\n",
    "    clonotype_distance_distributions[cl] = distance_distribution\n",
    "\n",
    "# Distance to closest point in spline\n",
    "tcr_loc_dict_to_use = puck.tcr_loc_dict_s1_filtered3\n",
    "clonotype_distance_distributions_not_tumor = {}\n",
    "for cl in tqdm(clonotype_distance_distributions):\n",
    "    this_cl_beads = set(tcr_loc_dict_to_use[cl])\n",
    "    this_cl_beads_in_tumor = [\n",
    "        i for i in this_cl_beads if i not in puck.tumor_beads\n",
    "    ]\n",
    "    # Find distances between point and closest point\n",
    "    distance_distribution = [\n",
    "        -distance_between_points(pt, closest_node(pt, boundary_points))\n",
    "        for pt in this_cl_beads if pt not in puck.tumor_beads\n",
    "    ]\n",
    "    clonotype_distance_distributions_not_tumor[cl] = distance_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_val = 0\n",
    "min_val = 0\n",
    "for cl in clonotype_distance_distributions:\n",
    "    if max(clonotype_distance_distributions[cl]) > max_val:\n",
    "        max_val = max(clonotype_distance_distributions[cl])\n",
    "for cl in clonotype_distance_distributions_not_tumor:\n",
    "    if min(clonotype_distance_distributions_not_tumor[cl]) < min_val:\n",
    "        min_val = min(clonotype_distance_distributions_not_tumor[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "min_dist_til_to_boundary = -1000\n",
    "max_dist_til_to_boundary = 0\n",
    "min_dist_lung_to_boundary = -1000\n",
    "max_dist_lung_to_boundary = 0\n",
    "for loc in tqdm(puck.tll_loc_cluster_dict):\n",
    "    if puck.tll_loc_cluster_dict[loc] == 'TIL':\n",
    "        if -distance_between_points(loc, closest_node(\n",
    "                loc, boundary_points)) > min_dist_til_to_boundary:\n",
    "            min_dist_til_to_boundary = -distance_between_points(\n",
    "                loc, closest_node(loc, boundary_points))\n",
    "        if distance_between_points(loc, closest_node(\n",
    "                loc, boundary_points)) > max_dist_til_to_boundary:\n",
    "            max_dist_til_to_boundary = distance_between_points(\n",
    "                loc, closest_node(loc, boundary_points))\n",
    "\n",
    "    elif puck.tll_loc_cluster_dict[loc] == 'Lung':\n",
    "        if -distance_between_points(loc, closest_node(\n",
    "                loc, boundary_points)) > min_dist_lung_to_boundary:\n",
    "            min_dist_lung_to_boundary = -distance_between_points(\n",
    "                loc, closest_node(loc, boundary_points))\n",
    "        if distance_between_points(loc, closest_node(\n",
    "                loc, boundary_points)) > max_dist_lung_to_boundary:\n",
    "            max_dist_lung_to_boundary = distance_between_points(\n",
    "                loc, closest_node(loc, boundary_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_val = max_val + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##### for cl in clonotype_distance_distributions:\n",
    "for cl in clonotype_distance_distributions:\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    # background color\n",
    "    ax1.axvspan(0, max_val, facecolor=sns.color_palette(\"tab10\")[2], alpha=0.1)\n",
    "    ax1.axvspan(-max_dist_til_to_boundary,\n",
    "                min_dist_til_to_boundary,\n",
    "                facecolor=sns.color_palette(\"tab10\")[1],\n",
    "                alpha=0.1)\n",
    "\n",
    "    ax1.axvspan(-max_dist_lung_to_boundary,\n",
    "                min_dist_lung_to_boundary,\n",
    "                facecolor=sns.color_palette(\"tab10\")[0],\n",
    "                alpha=0.2)\n",
    "\n",
    "    #     n,xvals,_ = ax1.hist(clonotype_distance_distributions_not_tumor[cl],\n",
    "    #                          bins=8,color='black')\n",
    "    n, xvals, patches = ax1.hist(\n",
    "        clonotype_distance_distributions[cl] +\n",
    "        clonotype_distance_distributions_not_tumor[cl],\n",
    "        bins=16,\n",
    "        range=(min_val, max_val),\n",
    "        color='gray',\n",
    "        alpha=1)\n",
    "\n",
    "    for idx in [idx for idx in range(len(n)) if xvals[idx] >= -50]:\n",
    "        patches[idx].set_facecolor('k')\n",
    "\n",
    "    histx = [i - (xvals[1] - xvals[0]) / 2 for i in xvals[1:]]\n",
    "    poly = np.polyfit(histx, n, 3)\n",
    "    poly_y = np.poly1d(poly)(histx)\n",
    "    ax1.plot(histx, poly_y, 'k')\n",
    "\n",
    "    ax1.set_title(cl)\n",
    "    ax1.set_ylim(0, max(n) * 1.3)\n",
    "    ax1.set_xlim(min(-max_dist_lung_to_boundary, -max_dist_til_to_boundary),\n",
    "                 max_val)\n",
    "\n",
    "    ## Plot faded background of tumor, lung, til\n",
    "\n",
    "    t_plotx = [\n",
    "        j[0] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "        ]\n",
    "    ]\n",
    "    t_ploty = [\n",
    "        j[1] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "        ]\n",
    "    ]\n",
    "    ax2.scatter(t_plotx,\n",
    "                t_ploty,\n",
    "                s=0.5,\n",
    "                alpha=0.03,\n",
    "                label='Tumor',\n",
    "                c=sns.color_palette(\"tab10\")[2])\n",
    "    l_plotx = [\n",
    "        j[0] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "        ]\n",
    "    ]\n",
    "    l_ploty = [\n",
    "        j[1] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "        ]\n",
    "    ]\n",
    "    ax2.scatter(l_plotx,\n",
    "                l_ploty,\n",
    "                s=0.5,\n",
    "                alpha=0.03,\n",
    "                label='Lung',\n",
    "                c=sns.color_palette(\"tab10\")[0])\n",
    "    til_plotx = [\n",
    "        j[0] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "        ]\n",
    "    ]\n",
    "    til_ploty = [\n",
    "        j[1] for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "        ]\n",
    "    ]\n",
    "    ax2.scatter(til_plotx,\n",
    "                til_ploty,\n",
    "                s=0.5,\n",
    "                alpha=0.03,\n",
    "                label='TIL Chemokines',\n",
    "                c=sns.color_palette(\"tab10\")[1])\n",
    "    #######\n",
    "\n",
    "    ax2.plot(x, y, 'or', alpha=1, markersize=3, marker=\"_\",\n",
    "             c='gray')  # Boundary\n",
    "    points_to_plot = set(tcr_loc_dict_to_use[cl])\n",
    "    ax2.scatter(\n",
    "        [i[0] for i in points_to_plot if i in puck.tumor_beads],  # points\n",
    "        [i[1] for i in points_to_plot if i in puck.tumor_beads],\n",
    "        alpha=0.8,\n",
    "        s=20,\n",
    "        c='black')\n",
    "    ax2.scatter(\n",
    "        [i[0] for i in points_to_plot if i not in puck.tumor_beads],  # points\n",
    "        [i[1] for i in points_to_plot if i not in puck.tumor_beads],\n",
    "        alpha=0.3,\n",
    "        s=20,\n",
    "        c='gray')\n",
    "    ax2.set_title(cl)\n",
    "    ax2.axes.get_xaxis().set_ticks([])\n",
    "    ax2.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "    loc_for_this_cl = list(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "\n",
    "    plt.xlim(0, 6000)\n",
    "    plt.ylim(0, 6000)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Looking at the effect of different filters (two reads per UMI) in space with constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Two reads per UMI\n",
    "puck8.tcr_bcumi_dict_filtered_reads_per_umi = {}\n",
    "for cl in puck8.tcr_bcumi_dict:\n",
    "    cter = Counter(puck8.tcr_bcumi_dict[cl])\n",
    "    puck8.tcr_bcumi_dict_filtered_reads_per_umi[cl] = [\n",
    "        i for i in cter if cter[i] > 1\n",
    "    ]\n",
    "\n",
    "puck.tcr_loc_dict_s1_filtered_reads_per_umi, errors = clonotype_to_spatial(\n",
    "    puck.tcr_bcumi_dict_filtered_reads_per_umi,\n",
    "    puck.bc_loc_dict_s1,\n",
    "    display_missed_barcodes=False,\n",
    "    hamming_correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated clonotype plots with different filters\n",
    "plt.figure(figsize=(5, 5))\n",
    "for cl in clonotype_distance_distributions:\n",
    "    #plt.figure(figsize=(3,3))\n",
    "    #     plt.scatter([i[0] for i in set(puck.tcr_loc_dict_s1[cl])],\n",
    "    #                [i[1] for i in set(puck.tcr_loc_dict_s1[cl])],\n",
    "    #                alpha =0.5,s=5,label='no_filter',c='green')\n",
    "    plt.scatter([\n",
    "        i[0] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ], [\n",
    "        i[1] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ],\n",
    "                alpha=0.5,\n",
    "                s=5,\n",
    "                label='added',\n",
    "                c='blue')\n",
    "    plt.scatter([i[0] for i in set(puck.tcr_loc_dict_s1_filtered[cl])],\n",
    "                [i[1] for i in set(puck.tcr_loc_dict_s1_filtered[cl])],\n",
    "                alpha=0.5,\n",
    "                s=5,\n",
    "                label='original',\n",
    "                c='orange')\n",
    "    plt.scatter([\n",
    "        i[0] for i in set(puck.tcr_loc_dict_s1_filtered_reads_per_umi[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ], [\n",
    "        i[1] for i in set(puck.tcr_loc_dict_s1_filtered_reads_per_umi[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ],\n",
    "                alpha=1,\n",
    "                s=5,\n",
    "                label='added from reads per umi filter',\n",
    "                c='green')\n",
    "\n",
    "    plt.title('Aggregated')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Individual clonotype plots with different filters\n",
    "for cl in clonotype_distance_distributions:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    #     plt.scatter([i[0] for i in set(puck.tcr_loc_dict_s1[cl])],\n",
    "    #                [i[1] for i in set(puck.tcr_loc_dict_s1[cl])],\n",
    "    #                alpha =0.5,s=5,label='no_filter',c='green')\n",
    "    plt.scatter([\n",
    "        i[0] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ], [\n",
    "        i[1] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ],\n",
    "                alpha=1,\n",
    "                s=5,\n",
    "                label='added',\n",
    "                c='blue')\n",
    "    plt.scatter([i[0] for i in set(puck.tcr_loc_dict_s1_filtered[cl])],\n",
    "                [i[1] for i in set(puck.tcr_loc_dict_s1_filtered[cl])],\n",
    "                alpha=1,\n",
    "                s=5,\n",
    "                label='original',\n",
    "                c='orange')\n",
    "    plt.scatter([\n",
    "        i[0] for i in set(puck.tcr_loc_dict_s1_filtered_reads_per_umi[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ], [\n",
    "        i[1] for i in set(puck.tcr_loc_dict_s1_filtered_reads_per_umi[cl])\n",
    "        if i not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "    ],\n",
    "                alpha=1,\n",
    "                s=5,\n",
    "                label='added from reads per umi filter',\n",
    "                c='green')\n",
    "\n",
    "    plt.title(cl)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "bcs = puck8.s1_dge_fmtd[puck8.s1_dge_fmtd['TRAC'] > 1].index\n",
    "plt.scatter([puck.bc_loc_dict_s1[bc][0] for bc in bcs],\n",
    "            [puck.bc_loc_dict_s1[bc][1] for bc in bcs])\n",
    "plt.title('TRAC > 1')\n",
    "plt.figure(figsize=(5, 5))\n",
    "bcs = puck8.s1_dge_fmtd[puck8.s1_dge_fmtd['TRBC2'] > 1].index\n",
    "plt.scatter([puck.bc_loc_dict_s1[bc][0] for bc in bcs],\n",
    "            [puck.bc_loc_dict_s1[bc][1] for bc in bcs],\n",
    "            alpha=0.2)\n",
    "\n",
    "agg_x = []\n",
    "agg_y = []\n",
    "for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "    if cl in puck.tcr_loc_dict_s1_filtered:\n",
    "        agg_x = agg_x + [\n",
    "            i[0] for i in set([\n",
    "                j for j in puck.tcr_loc_dict_s1_filtered3[cl]\n",
    "                if j not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "            ])\n",
    "        ]\n",
    "        agg_y = agg_y + [\n",
    "            i[1] for i in set([\n",
    "                j for j in puck.tcr_loc_dict_s1_filtered3[cl]\n",
    "                if j not in puck.tcr_loc_dict_s1_filtered[cl]\n",
    "            ])\n",
    "        ]\n",
    "plt.scatter(agg_x, agg_y, alpha=1, s=5, label='added', c='orange')\n",
    "plt.title('TRBC2 > 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fraction of UMIs in tumor (need KNN assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fraction of UMIs in tumor\n",
    "palette = sns.color_palette('hls', len(fraction_df))\n",
    "cl_names = []\n",
    "fractions = []\n",
    "for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "    if len(set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "           ) < 10:  # at least ten locations\n",
    "        continue\n",
    "    assignments = [\n",
    "        puck.tll_loc_cluster_dict[loc]\n",
    "        for loc in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "    ]\n",
    "    tumor_assignments = [i for i in assignments if i == 'Tumor']\n",
    "    fractions.append(len(tumor_assignments) / len(assignments))\n",
    "    cl_names.append(cl)\n",
    "fraction_df = pd.DataFrame.from_dict({\n",
    "    'clonotype': cl_names,\n",
    "    'fraction': fractions\n",
    "})\n",
    "fraction_df.sort_values('fraction', inplace=True, ascending=False)\n",
    "fraction_df.index = [i for i in range(len(fraction_df))]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for index, row in fraction_df.iterrows():\n",
    "    plt.scatter(index,\n",
    "                row['fraction'],\n",
    "                label=row['clonotype'],\n",
    "                c=palette[index])\n",
    "plt.ylabel('Fraction of each clonotype in tumor')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clonotype enrichment in tumor vs lung vs immune (and comparison with bulk) (need KNN assignments)\n",
    "Genes correlated with clonotype enrichment in tumor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Randomness testing, expected values, Fisher testing\n",
    "\n",
    "show_plot = False\n",
    "\n",
    "puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered3\n",
    "\n",
    "##### Randomness between lung, tumor, and TIL\n",
    "\n",
    "\n",
    "# Gets locations of all cells of a certain cluster\n",
    "def get_locations(cluster_labels, clustername):\n",
    "    x = cluster_labels[cluster_labels.cluster_name == clustername].x\n",
    "    y = cluster_labels[cluster_labels.cluster_name == clustername].y\n",
    "    coords = [(i, j) for i, j in zip(x, y)]\n",
    "    return list(set(coords))\n",
    "\n",
    "\n",
    "def get_locations_distribution(all_locations, locations_reference):\n",
    "    lung_locs = set(locations_reference['Lung'])\n",
    "    #til_locs = []\n",
    "    til_locs = set(locations_reference['TIL Chemokines'])\n",
    "    tumor_locs = set(locations_reference['Tumor'])\n",
    "    #b_locs = set(locations_reference['B'])\n",
    "\n",
    "    #     lung_locs = set(locations_reference['NonImmuneCell'])\n",
    "    #     til_locs = set(locations_reference['PlasmaCell'])\n",
    "    #     tumor_locs = set(locations_reference['TumorCell_CA9'])\n",
    "\n",
    "    #b_locs = set(locations_reference['B'])\n",
    "    ltt_dist = [0, 0, 0]\n",
    "    #ltt_dist = [0,0]\n",
    "    for location in all_locations:\n",
    "        if location in lung_locs:\n",
    "            ltt_dist[0] += 1\n",
    "\n",
    "        elif location in til_locs:\n",
    "            ltt_dist[1] += 1\n",
    "\n",
    "        elif location in tumor_locs:\n",
    "            ltt_dist[2] += 1\n",
    "\n",
    "\n",
    "#         elif location in b_locs:\n",
    "#             ltt_dist[3]+=1\n",
    "#ltt_dist[1] += 1\n",
    "# #         if location in b_locs:\n",
    "# #             ltt_dist[3] += 1\n",
    "#         else:\n",
    "#             ltt_dist[3] += 1\n",
    "\n",
    "    return ltt_dist\n",
    "\n",
    "puck.locations_reference = switch_dict(copy.deepcopy(\n",
    "    puck.tll_loc_cluster_dict))\n",
    "\n",
    "puck.ltt_dist_dict = {}\n",
    "for tcr in tqdm(puck_tcr_loc_dict):\n",
    "    if tcr not in puck.clonotypes['1b']:\n",
    "        continue\n",
    "    ltt_dist = get_locations_distribution(set(puck_tcr_loc_dict[tcr]),\n",
    "                                          puck.locations_reference)\n",
    "    if sum(ltt_dist) < 10:\n",
    "        continue\n",
    "\n",
    "    puck.ltt_dist_dict[tcr] = ltt_dist\n",
    "\n",
    "##### EXPECTED VALUES\n",
    "\n",
    "# Sampling expected only from tcr locations\n",
    "all_tcr_locs = []\n",
    "for clonotype in puck_tcr_loc_dict:\n",
    "    #all_tcr_locs = all_tcr_locs + puck.tcr_loc_dict_s1_filtered3[clonotype]\n",
    "    all_tcr_locs = all_tcr_locs + list(\n",
    "        set(puck_tcr_loc_dict[clonotype]\n",
    "            ))  # only look at locations with at least 5 counts per clonotype\n",
    "    #print(len(set(puck.tcr_loc_dict_s1_filtered3[clonotype])) - len(set([i for i in cter if cter[i] > 5 ])))\n",
    "#all_tcr_locs = list(set(all_tcr_locs))\n",
    "expected = get_locations_distribution(all_tcr_locs, puck.locations_reference)\n",
    "\n",
    "#### SET UP CLONO PLOT DF FOR Clonotype Analysis Plot\n",
    "\n",
    "puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered3\n",
    "\n",
    "cl_all = [\n",
    "    i for i in puck.tcr_loc_dict_s1_filtered3\n",
    "    if ((len(set(puck.tcr_loc_dict_s1_filtered3[i])) >= 10) and (\n",
    "        i in puck.clonotypes['1b']))\n",
    "]\n",
    "num_locs = [len(list(set(puck_tcr_loc_dict[i]))) for i in cl_all]\n",
    "puck.x_ltt = [\n",
    "    puck.ltt_dist_dict[clonotype][0] / sum(puck.ltt_dist_dict[clonotype]) /\n",
    "    expected[0] * sum(expected) - 1 for clonotype in cl_all\n",
    "]  #lung\n",
    "puck.y_ltt = [\n",
    "    puck.ltt_dist_dict[clonotype][1] / sum(puck.ltt_dist_dict[clonotype]) /\n",
    "    expected[1] * sum(expected) - 1 for clonotype in cl_all\n",
    "]  #til\n",
    "puck.z_ltt = [\n",
    "    puck.ltt_dist_dict[clonotype][2] / sum(puck.ltt_dist_dict[clonotype]) /\n",
    "    expected[2] * sum(expected) - 1 for clonotype in cl_all\n",
    "]  #tumor\n",
    "\n",
    "\n",
    "clono_plot_df = pd.DataFrame.from_dict({\n",
    "    'Lung': puck.x_ltt,\n",
    "    'TIL': puck.y_ltt,\n",
    "    'Tumor': puck.z_ltt,\n",
    "    'clonotype': cl_all,\n",
    "    'num_points': num_locs\n",
    "})\n",
    "puck.clono_plot_df = clono_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MAKE AGGREGATED ANALYSES\n",
    "cl_agg_to_tumor_enrichment = {}\n",
    "cl_agg_to_lung_enrichment = {}\n",
    "cl_agg_to_til_enrichment = {}\n",
    "\n",
    "for cl in puck8.clono_plot_df.clonotype:\n",
    "    cl_agg_to_tumor_enrichment[cl] = [\n",
    "        float(\n",
    "            puck8.clono_plot_df[puck8.clono_plot_df.clonotype == cl]['Tumor'])\n",
    "    ]\n",
    "    cl_agg_to_lung_enrichment[cl] = [\n",
    "        float(puck8.clono_plot_df[puck8.clono_plot_df.clonotype == cl]['Lung'])\n",
    "    ]\n",
    "    cl_agg_to_til_enrichment[cl] = [\n",
    "        float(puck8.clono_plot_df[puck8.clono_plot_df.clonotype == cl]['TIL'])\n",
    "    ]\n",
    "\n",
    "for cl in puck9.clono_plot_df.clonotype:\n",
    "    if cl not in cl_agg_to_tumor_enrichment:\n",
    "        cl_agg_to_tumor_enrichment[cl] = []\n",
    "    cl_agg_to_tumor_enrichment[cl].append(\n",
    "        float(\n",
    "            puck9.clono_plot_df[puck9.clono_plot_df.clonotype == cl]['Tumor']))\n",
    "\n",
    "    if cl not in cl_agg_to_lung_enrichment:\n",
    "        cl_agg_to_lung_enrichment[cl] = []\n",
    "    cl_agg_to_lung_enrichment[cl].append(\n",
    "        float(\n",
    "            puck9.clono_plot_df[puck9.clono_plot_df.clonotype == cl]['Lung']))\n",
    "\n",
    "    if cl not in cl_agg_to_til_enrichment:\n",
    "        cl_agg_to_til_enrichment[cl] = []\n",
    "    cl_agg_to_til_enrichment[cl].append(\n",
    "        float(puck9.clono_plot_df[puck9.clono_plot_df.clonotype == cl]['TIL']))\n",
    "\n",
    "for cl in puck10.clono_plot_df.clonotype:\n",
    "\n",
    "    if cl not in cl_agg_to_tumor_enrichment:\n",
    "        cl_agg_to_tumor_enrichment[cl] = []\n",
    "    cl_agg_to_tumor_enrichment[cl].append(\n",
    "        float(puck10.clono_plot_df[puck10.clono_plot_df.clonotype == cl]\n",
    "              ['Tumor']))\n",
    "\n",
    "    if cl not in cl_agg_to_lung_enrichment:\n",
    "        cl_agg_to_lung_enrichment[cl] = []\n",
    "    cl_agg_to_lung_enrichment[cl].append(\n",
    "        float(puck10.clono_plot_df[puck10.clono_plot_df.clonotype == cl]\n",
    "              ['Lung']))\n",
    "\n",
    "    if cl not in cl_agg_to_til_enrichment:\n",
    "        cl_agg_to_til_enrichment[cl] = []\n",
    "    cl_agg_to_til_enrichment[cl].append(\n",
    "        float(\n",
    "            puck10.clono_plot_df[puck10.clono_plot_df.clonotype == cl]['TIL']))\n",
    "\n",
    "cl_agg_to_tumor_enrichment_means = {\n",
    "    i: np.mean(cl_agg_to_tumor_enrichment[i])\n",
    "    for i in cl_agg_to_tumor_enrichment\n",
    "}\n",
    "cl_agg_to_lung_enrichment_means = {\n",
    "    i: np.mean(cl_agg_to_lung_enrichment[i])\n",
    "    for i in cl_agg_to_lung_enrichment\n",
    "}\n",
    "cl_agg_to_til_enrichment_means = {\n",
    "    i: np.mean(cl_agg_to_til_enrichment[i])\n",
    "    for i in cl_agg_to_til_enrichment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boundary-based distance testing\n",
    "# Only look at TCR betas with at least 10 beads.\n",
    "# Compare against all other beads.\n",
    "analyze_tumor = True\n",
    "\n",
    "if analyze_tumor:\n",
    "    bin_them = False\n",
    "    num_bins = 10\n",
    "    show_plot = False\n",
    "    aggregated_distribution_for_this_cl = {}\n",
    "    aggregated_p_values_greater = {}\n",
    "    aggregated_p_values_less = {}\n",
    "    num_counts = {}\n",
    "    for puck in [puck8, puck9, puck10]:\n",
    "        # Try distance from boundary instead\n",
    "        distance_vectors_for_cls = {}\n",
    "        aggregate_distance = []\n",
    "        for cl in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "            if cl not in puck.clonotypes['1b']:\n",
    "                continue\n",
    "            all_pts = list(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "\n",
    "            distance_distribution = [\n",
    "                distance_between_points(pt,\n",
    "                                        closest_node(pt, puck.boundary_points))\n",
    "                for pt in all_pts if pt in puck.tumor_beads\n",
    "            ]\n",
    "            # if you want to include the distance not in tumor\n",
    "            distance_distribution = distance_distribution + [\n",
    "                -distance_between_points(\n",
    "                    pt, closest_node(pt, puck.boundary_points))\n",
    "                for pt in all_pts if pt not in puck.tumor_beads\n",
    "            ]\n",
    "\n",
    "            if cl not in num_counts:\n",
    "                num_counts[cl] = 0\n",
    "            num_counts[cl] += len(all_pts)\n",
    "\n",
    "            if len(all_pts) < 10:\n",
    "                aggregate_distance = aggregate_distance + distance_distribution\n",
    "                continue\n",
    "            else:\n",
    "                distance_vectors_for_cls[cl] = distance_distribution\n",
    "                aggregate_distance = aggregate_distance + distance_distribution\n",
    "\n",
    "        print(len(aggregate_distance))\n",
    "\n",
    "        if bin_them:\n",
    "            min_val = min(aggregate_distance)\n",
    "            max_val = max(aggregate_distance)\n",
    "            bins = np.linspace(min_val, max_val, num_bins)\n",
    "\n",
    "            for cl in distance_vectors_for_cls:\n",
    "                distance_vectors_for_cls[cl] = np.digitize(\n",
    "                    distance_vectors_for_cls[cl], bins)\n",
    "            aggregate_distance_for_this_cl = copy.deepcopy(aggregate_distance)\n",
    "            aggregate_distance_for_this_cl = np.digitize(\n",
    "                aggregate_distance_for_this_cl, bins)\n",
    "\n",
    "        for cl in distance_vectors_for_cls:\n",
    "            if cl not in aggregated_p_values_greater:\n",
    "                aggregated_p_values_greater[cl] = []\n",
    "            if cl not in aggregated_p_values_less:\n",
    "                aggregated_p_values_less[cl] = []\n",
    "\n",
    "    #\n",
    "\n",
    "            if bin_them == False:\n",
    "                aggregate_distance_for_this_cl = copy.deepcopy(\n",
    "                    aggregate_distance)\n",
    "            aggregate_distance_for_this_cl = list(\n",
    "                aggregate_distance_for_this_cl)\n",
    "            for i in distance_vectors_for_cls[\n",
    "                    cl]:  # remove clonotype you're testing\n",
    "                aggregate_distance_for_this_cl.remove(i)\n",
    "            aggregated_distribution_for_this_cl[\n",
    "                cl] = aggregate_distance_for_this_cl\n",
    "\n",
    "            if show_plot:\n",
    "                plt.figure()\n",
    "                plt.title(cl)\n",
    "                plt.hist(distance_vectors_for_cls[cl],\n",
    "                         alpha=0.5,\n",
    "                         density=True,\n",
    "                         range=(min_val, max_val),\n",
    "                         bins=20)\n",
    "                plt.hist(aggregate_distance_for_this_cl,\n",
    "                         alpha=0.5,\n",
    "                         density=True,\n",
    "                         range=(min_val, max_val),\n",
    "                         bins=20)\n",
    "\n",
    "            min_val = min(min(distance_vectors_for_cls[cl]),\n",
    "                          min(aggregate_distance))\n",
    "            max_val = max(max(distance_vectors_for_cls[cl]),\n",
    "                          max(aggregate_distance))\n",
    "            aggregated_p_values_greater[cl].append(\n",
    "                kstest(distance_vectors_for_cls[cl],\n",
    "                       aggregate_distance_for_this_cl,\n",
    "                       alternative='less')[1])\n",
    "            aggregated_p_values_less[cl].append(\n",
    "                kstest(distance_vectors_for_cls[cl],\n",
    "                       aggregate_distance_for_this_cl,\n",
    "                       alternative='greater')[1])\n",
    "            #         aggregated_p_values_greater[cl].append(ttest_ind(distance_vectors_for_cls[cl],aggregate_distance_for_this_cl)[1])\n",
    "            #         aggregated_p_values_less[cl].append(ttest_ind(distance_vectors_for_cls[cl],aggregate_distance_for_this_cl)[1])\n",
    "\n",
    "            print(\n",
    "                cl,\n",
    "                kstest(distance_vectors_for_cls[cl],\n",
    "                       aggregate_distance_for_this_cl,\n",
    "                       alternative='less')[1])\n",
    "            print(\n",
    "                cl,\n",
    "                ttest_ind(distance_vectors_for_cls[cl],\n",
    "                          aggregate_distance_for_this_cl)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#statsmodels.stats.multitest.multipletests\n",
    "aggregated_p_values_greater_adj = {}\n",
    "aggregated_p_values_less_adj = {}\n",
    "cls_to_look_at = list(aggregated_p_values_greater.keys())\n",
    "for cl in cls_to_look_at:\n",
    "    print(cl)\n",
    "    aggregated_p_values_greater_adj[cl] = scipy.stats.combine_pvalues(\n",
    "        aggregated_p_values_greater[cl])[1]\n",
    "    aggregated_p_values_less_adj[cl] = scipy.stats.combine_pvalues(\n",
    "        aggregated_p_values_less[cl])[1]\n",
    "\n",
    "# Adjust p values\n",
    "all_p_vals = list(aggregated_p_values_greater_adj.values()\n",
    "                  )  #+ list(aggregated_p_values_less_adj.values())\n",
    "p_val_adj_dict = dict(zip(\n",
    "        all_p_vals,\n",
    "        statsmodels.stats.multitest.multipletests(all_p_vals, method='fdr_bh')\n",
    "        [1])\n",
    "                     )\n",
    "pvalue_greater = [\n",
    "    -np.log10(aggregated_p_values_greater_adj[cl]) for cl in cls_to_look_at\n",
    "]\n",
    "pvalue_greater_adjusted = [\n",
    "    -np.log10(i)\n",
    "    for i in statsmodels.stats.multitest.multipletests(all_p_vals,\n",
    "                                                       method='fdr_bh')[1]\n",
    "]\n",
    "\n",
    "pvalue_less = [\n",
    "    -np.log10(aggregated_p_values_less_adj[cl]) for cl in cls_to_look_at\n",
    "]\n",
    "pvalue_less_adjusted = [\n",
    "    -np.log10(i) for i in statsmodels.stats.multitest.multipletests(\n",
    "        list(aggregated_p_values_less_adj.values()), method='fdr_bh')[1]\n",
    "]\n",
    "\n",
    "dict_plot = {\n",
    "    'clonotype': [cl for cl in cls_to_look_at],\n",
    "    'tumor_enrichment':\n",
    "    [cl_agg_to_tumor_enrichment_means[cl] for cl in cls_to_look_at],\n",
    "    'lung_enrichment':\n",
    "    [cl_agg_to_lung_enrichment_means[cl] for cl in cls_to_look_at],\n",
    "    'pvalue_greater':\n",
    "    pvalue_greater,\n",
    "    'pvalue_greater_adjusted':\n",
    "    pvalue_greater_adjusted,\n",
    "    'pvalue_less':\n",
    "    pvalue_less,\n",
    "    'pvalue_less_adjusted':\n",
    "    pvalue_less_adjusted,\n",
    "    'counts': [num_counts[cl] for cl in cls_to_look_at]\n",
    "}\n",
    "\n",
    "plot_df = pd.DataFrame.from_dict(dict_plot)\n",
    "plot_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "pvalue_to_use_greater = 'pvalue_greater'\n",
    "pvalue_to_use_less = 'pvalue_less'\n",
    "\n",
    "pvalue_to_use_greater = 'pvalue_greater'\n",
    "pvalue_to_use_less = 'pvalue_less'\n",
    "\n",
    "## MAKE VOLCANO MERGED COLUMN\n",
    "volcano_merged = []\n",
    "for index, row in plot_df.iterrows():\n",
    "    if row['tumor_enrichment'] < 0:\n",
    "        volcano_merged.append(row[pvalue_to_use_less])\n",
    "    elif row['tumor_enrichment'] > 0:\n",
    "        volcano_merged.append(row[pvalue_to_use_greater])\n",
    "    else:\n",
    "        print('we have a zero over here!')\n",
    "plot_df['volcano_merged'] = volcano_merged\n",
    "###\n",
    "plot_df['clonotype'] = [pretty_clonotype_name[i] for i in plot_df['clonotype']]\n",
    "\n",
    "plot_df['sig_name'] = [plot_df.clonotype[idx] if \\\n",
    "    ((plot_df[pvalue_to_use_greater][idx] > -np.log10(0.05)) or (plot_df[pvalue_to_use_less][idx] > -np.log10(0.05))) else 'insig' for idx in range(len(plot_df.clonotype)) ]\n",
    "plot_df['sig_name_greater'] = [\n",
    "    plot_df.clonotype[idx] if\n",
    "    (plot_df[pvalue_to_use_greater][idx] > -np.log10(0.05)) else 'insig'\n",
    "    for idx in range(len(plot_df.clonotype))\n",
    "]\n",
    "\n",
    "y_metric = 'volcano_merged'  #'pvalue_greater_adjusted'#'volcano_merged'\n",
    "hue_metric = 'sig_name'\n",
    "#plot_df.sort_values(hue_metric,inplace = True,ascending=True)\n",
    "plot_df.sort_values('volcano_merged', inplace=True, ascending=False)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "colors_to_use = sns.color_palette(\n",
    "    \"hls\",\n",
    "    len(set(plot_df[hue_metric])) - 1) + ['gray']\n",
    "# sns.scatterplot(data = plot_df, x = 'tumor_enrichment',y = y_metric,hue=hue_metric,\n",
    "#                palette = colors_to_use,sizes=(30,300),size='counts') #volcano_merged\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.scatterplot(data=plot_df,\n",
    "                x='tumor_enrichment',\n",
    "                y=y_metric,\n",
    "                hue=hue_metric,\n",
    "                palette=colors_to_use,\n",
    "                sizes=(30, 300),\n",
    "                size='counts')  #volcano_merged\n",
    "lgd = plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0., frameon=False)\n",
    "ax.axvline(0, c='black', alpha=0.9)\n",
    "ax.axhline(-np.log10(0.05), c='black', alpha=0.9, linestyle='--')\n",
    "#plt.savefig('./vectorized_figures/volcano_plot_lung.pdf')\n",
    "plt.savefig('./vectorized_figures/volcano_plot_tumor.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_df[(plot_df.tumor_enrichment < 0)\n",
    "        & (plot_df.volcano_merged > -np.log10(0.05))]\n",
    "significant_clonotypes = [\n",
    "    i for i in plot_df[plot_df.volcano_merged > -np.log10(0.05)].clonotype\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot spatial distribution histograms\n",
    "##### for cl in clonotype_distance_distributions:\n",
    "\n",
    "for cl in distance_vectors_for_cls:\n",
    "    fig, ax1 = plt.subplots(figsize=(3, 3))\n",
    "    max_val = float(max(distance_vectors_for_cls[cl]) * 1.1)\n",
    "    min_val = float(min(distance_vectors_for_cls[cl]) * 1.1)\n",
    "    ax1.axvspan(0, max_val, facecolor=sns.color_palette(\"tab10\")[2], alpha=0.2)\n",
    "    ax1.axvspan(min_val, 0, facecolor='gray', alpha=0.1)\n",
    "    ax1.set_xlim([min_val, max_val])\n",
    "\n",
    "    not_tumor = [i for i in distance_vectors_for_cls[cl] if i < 0]\n",
    "    tumor = [i for i in distance_vectors_for_cls[cl] if i >= 0]\n",
    "\n",
    "    #plotting_df.plot.hist(density=True, ax=ax)\n",
    "    #     n,xvals,patches = ax1.hist(not_tumor + tumor,\n",
    "    #                          bins=16,\n",
    "    #                          range=(min_val,max_val),color='gray',alpha=1,density=True)\n",
    "\n",
    "    #     for idx in [idx for idx in range(len(n)) if xvals[idx] >= -50]:\n",
    "    #         patches[idx].set_facecolor('k')\n",
    "    plotting_df = pd.DataFrame.from_dict({\n",
    "        'clonotype': [cl] * len(distance_vectors_for_cls[cl]),\n",
    "        'distances':\n",
    "        distance_vectors_for_cls[cl]\n",
    "    })\n",
    "    plotting_df.plot.kde(ax=ax1, legend=False, color='r', bw_method=0.3)\n",
    "    aggregated_plotting_df = pd.DataFrame.from_dict(\n",
    "        {'distances': aggregated_distribution_for_this_cl[cl]})\n",
    "    aggregated_plotting_df.plot.kde(ax=ax1,\n",
    "                                    legend=False,\n",
    "                                    color='k',\n",
    "                                    bw_method=0.3)\n",
    "\n",
    "#     ax1.set_title(cl)\n",
    "#     ax1.set_ylim(0,max(n)*1.3)\n",
    "#     ax1.set_xlim(min(-max_dist_lung_to_boundary,-max_dist_til_to_boundary),max_val)\n",
    "\n",
    "#     ## Plot faded background of tumor, lung, til\n",
    "\n",
    "#     t_plotx = [j[0] for j in [i for i in puck.tll_loc_cluster_dict if puck.tll_loc_cluster_dict[i] == 'Tumor']]\n",
    "#     t_ploty = [j[1] for j in [i for i in puck.tll_loc_cluster_dict if puck.tll_loc_cluster_dict[i] == 'Tumor']]\n",
    "#     ax2.scatter(t_plotx,t_ploty, s=0.5,alpha=0.03,label='Tumor',c=sns.color_palette(\"tab10\")[2])\n",
    "#     l_plotx = [j[0] for j in [i for i in puck.tll_loc_cluster_dict if puck.tll_loc_cluster_dict[i] == 'Lung']]\n",
    "#     l_ploty = [j[1] for j in [i for i in puck.tll_loc_cluster_dict if puck.tll_loc_cluster_dict[i] == 'Lung']]\n",
    "#     ax2.scatter(l_plotx,l_ploty,s=0.5,alpha=0.03,label='Lung',c=sns.color_palette(\"tab10\")[0])\n",
    "#     til_plotx = [j[0] for j in [i for i in puck.tll_loc_cluster_dict if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines']]\n",
    "#     til_ploty = [j[1] for j in [i for i in puck.tll_loc_cluster_dict if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines']]\n",
    "#     ax2.scatter(til_plotx,til_ploty,s=0.5,alpha=0.03,label='TIL Chemokines',c=sns.color_palette(\"tab10\")[1])\n",
    "# #######\n",
    "\n",
    "#     ax2.plot(x, y, 'or',alpha=1,markersize=3,marker=\"_\",c='gray') # Boundary\n",
    "#     points_to_plot = set(tcr_loc_dict_to_use[cl])\n",
    "#     ax2.scatter([i[0] for i in points_to_plot if i in puck.tumor_beads], # points\n",
    "#                 [i[1] for i in points_to_plot if i in puck.tumor_beads],\n",
    "#                alpha =0.8,s=20,c='black')\n",
    "#     ax2.scatter([i[0] for i in points_to_plot if i not in puck.tumor_beads], # points\n",
    "#                 [i[1] for i in points_to_plot if i not in puck.tumor_beads],\n",
    "#                alpha =0.3,s=20, c='gray')\n",
    "#     ax2.set_title(cl)\n",
    "#     ax2.axes.get_xaxis().set_ticks([])\n",
    "#     ax2.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "#     loc_for_this_cl = list(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "\n",
    "#     plt.xlim(0,6000)\n",
    "#     plt.ylim(0,6000)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ugly_clonotype_name = {\n",
    "    pretty_clonotype_name[i]: i\n",
    "    for i in pretty_clonotype_name\n",
    "}\n",
    "significant_clonotypes = [\n",
    "    ugly_clonotype_name[i] for i in list(plot_df.sig_name) if i != 'insig'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "# plot boundaries on all pucks\n",
    "\n",
    "for puck in tqdm([puck8, puck9, puck10]):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    puck.tumor_beads = [\n",
    "        j for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "        ]\n",
    "    ]\n",
    "    puck.til_beads = [\n",
    "        j for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "        ]\n",
    "    ]\n",
    "    puck.lung_beads = [\n",
    "        j for j in [\n",
    "            i for i in puck.tll_loc_cluster_dict\n",
    "            if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    plt.scatter([i[0] for i in puck.tumor_beads],\n",
    "                [i[1] for i in puck.tumor_beads],\n",
    "                label='tumor',\n",
    "                s=0.5,\n",
    "                alpha=1,\n",
    "                color=sns.color_palette()[0])\n",
    "    plt.scatter([i[0] for i in puck.til_beads], [i[1] for i in puck.til_beads],\n",
    "                label='tll',\n",
    "                s=0.5,\n",
    "                alpha=1,\n",
    "                color=sns.color_palette()[1])\n",
    "    plt.scatter([i[0] for i in puck.lung_beads],\n",
    "                [i[1] for i in puck.lung_beads],\n",
    "                label='lung',\n",
    "                s=0.5,\n",
    "                alpha=1,\n",
    "                color=sns.color_palette()[2])\n",
    "    scalebar = ScaleBar(0.65,\n",
    "                        'um',\n",
    "                        length_fraction=1 / 3 / 2,\n",
    "                        frameon=False,\n",
    "                        label_loc='bottom',\n",
    "                        label=None,\n",
    "                        location='lower right')  # 1 pixel = 0.2 meter\n",
    "    plt.gca().add_artist(scalebar)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./vectorized_figures/figure2g_{}_with_scalebar.pdf'.format(\n",
    "        puck.puck_name))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test = [4, 5, 8, 11]\n",
    "tcr_name = ['TCR-' + str(i) for i in test]\n",
    "plotting_clonotypes = [\n",
    "    i for i in pretty_clonotype_name if pretty_clonotype_name[i] in tcr_name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot significant clonotypes on all pucks\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, ax = plt.subplots(3,\n",
    "                       len(plotting_clonotypes),\n",
    "                       figsize=(3 * len(plotting_clonotypes), 9))\n",
    "\n",
    "for puck in tqdm([puck8, puck9, puck10]):  #puck8,puck9,\n",
    "\n",
    "    if puck == puck8:\n",
    "        loc_x = 0\n",
    "    elif puck == puck9:\n",
    "        loc_x = 1\n",
    "    else:\n",
    "        loc_x = 2\n",
    "    for cl in plotting_clonotypes:\n",
    "\n",
    "        puck.tumor_beads = [\n",
    "            j for j in [\n",
    "                i for i in puck.tll_loc_cluster_dict\n",
    "                if puck.tll_loc_cluster_dict[i] == 'Tumor'\n",
    "            ]\n",
    "        ]\n",
    "        puck.til_beads = [\n",
    "            j for j in [\n",
    "                i for i in puck.tll_loc_cluster_dict\n",
    "                if puck.tll_loc_cluster_dict[i] == 'TIL Chemokines'\n",
    "            ]\n",
    "        ]\n",
    "        puck.lung_beads = [\n",
    "            j for j in [\n",
    "                i for i in puck.tll_loc_cluster_dict\n",
    "                if puck.tll_loc_cluster_dict[i] == 'Lung'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].scatter(\n",
    "            [i[0] for i in puck.til_beads], [i[1] for i in puck.til_beads],\n",
    "            label='tll',\n",
    "            s=0.5,\n",
    "            alpha=0.05,\n",
    "            color=sns.color_palette()[1])\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].scatter(\n",
    "            [i[0] for i in puck.lung_beads], [i[1] for i in puck.lung_beads],\n",
    "            label='lung',\n",
    "            s=0.5,\n",
    "            alpha=0.05,\n",
    "            color=sns.color_palette()[2])\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].scatter(\n",
    "            [i[0] for i in puck.tumor_beads], [i[1] for i in puck.tumor_beads],\n",
    "            label='tumor',\n",
    "            s=0.5,\n",
    "            alpha=0.05,\n",
    "            color=sns.color_palette()[0])\n",
    "\n",
    "        # Plot beads in tumor in red and other beads in gray\n",
    "        color_index = significant_clonotypes.index(cl)\n",
    "        print(cl, color_index)\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].scatter(\n",
    "            [\n",
    "                i[0] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "                if i not in puck.tumor_beads\n",
    "            ], [\n",
    "                i[1] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "                if i not in puck.tumor_beads\n",
    "            ],\n",
    "            color=sns.color_palette('hls',\n",
    "                                    len(significant_clonotypes))[color_index],\n",
    "            s=50,\n",
    "            edgecolors='k',\n",
    "            alpha=0.5)\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].scatter(\n",
    "            [\n",
    "                i[0] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "                if i in puck.tumor_beads\n",
    "            ], [\n",
    "                i[1] for i in set(puck.tcr_loc_dict_s1_filtered3[cl])\n",
    "                if i in puck.tumor_beads\n",
    "            ],\n",
    "            color=sns.color_palette('hls',\n",
    "                                    len(significant_clonotypes))[color_index],\n",
    "            s=50,\n",
    "            edgecolors='k')\n",
    "\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].axis('off')\n",
    "        plt.rcParams.update({'font.size': 5})\n",
    "        scalebar = ScaleBar(0.65,\n",
    "                            'um',\n",
    "                            length_fraction=1 / 3 / 2,\n",
    "                            frameon=False,\n",
    "                            label_loc='bottom',\n",
    "                            label=None,\n",
    "                            location='lower right')  # 1 pixel = 0.2 meter\n",
    "        ax[loc_x, plotting_clonotypes.index(cl)].add_artist(scalebar)\n",
    "\n",
    "for ax, col in zip(ax[0], plotting_clonotypes):\n",
    "    ax.set_title(pretty_clonotype_name[col], fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig('./vectorized_figures/figure2h.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_file = 'nmf_sample10_adata.h5ad'\n",
    "\n",
    "if path.exists(results_file) == False:\n",
    "    adata = sc.read(results_file)\n",
    "else:\n",
    "\n",
    "    sc.settings.verbosity = 3\n",
    "    sc.logging.print_versions()\n",
    "    sc.settings.set_figure_params(dpi=80, frameon=False)  #figsize\n",
    "\n",
    "    adata = sc.AnnData(s1_dge_fmtd)\n",
    "    sc.pl.highest_expr_genes(adata, n_top=20)\n",
    "    sc.pp.filter_cells(adata, min_counts=100)\n",
    "    sc.pp.filter_cells(adata, min_genes=5)\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "    mito_genes = adata.var_names.str.startswith('MT-')\n",
    "    # for each cell compute fraction of counts in mito genes vs. all genes\n",
    "    # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing)\n",
    "    adata.obs['percent_mito'] = np.sum(adata[:, mito_genes].X,\n",
    "                                       axis=1) / np.sum(adata.X, axis=1)\n",
    "    # add the total counts per cell as observations-annotation to adata\n",
    "    adata.obs['n_counts'] = adata.X.sum(axis=1)\n",
    "\n",
    "    sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],\n",
    "                 jitter=0.4,\n",
    "                 multi_panel=True)\n",
    "\n",
    "    sc.pl.scatter(adata, x='n_counts', y='percent_mito')\n",
    "    sc.pl.scatter(adata, x='n_counts', y='n_genes')\n",
    "\n",
    "    # adata = adata[adata.obs.n_genes < 2500, :]\n",
    "    adata = adata[adata.obs.percent_mito < 0.05, :]\n",
    "\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    #adata.raw = adata\n",
    "    sc.pp.highly_variable_genes(adata,\n",
    "                                min_mean=0.0125,\n",
    "                                max_mean=3,\n",
    "                                min_disp=0.5)\n",
    "    sc.pl.highly_variable_genes(adata)\n",
    "    adata.raw = adata\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    adata.write(results_file)\n",
    "\n",
    "    #sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])\n",
    "    #sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RCTD neighbors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregate_list = []\n",
    "for cl in puck8.tcr_loc_dict_s1_filtered3:\n",
    "    if len(set(puck8.tcr_loc_dict_s1_filtered3)) < 5:\n",
    "        continue\n",
    "    aggregate_list = []\n",
    "    #print(cl)\n",
    "    for loc in set(puck8.tcr_loc_dict_s1_filtered3[cl]):\n",
    "        if loc in loc_to_cluster_dict:\n",
    "            aggregate_list = aggregate_list + loc_to_cluster_dict[loc]\n",
    "\n",
    "    print(Counter(aggregate_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc_cluster_dict = {}\n",
    "loc_cluster_dict_all = {}\n",
    "\n",
    "for index, row in cluster_labels.iterrows():\n",
    "    loc_cluster_dict_all[(float(row['x']),\n",
    "                          float(row['y']))] = row['cluster_name']\n",
    "    loc_cluster_dict[(float(row['x']), float(row['y']))] = row['cluster_name']\n",
    "\n",
    "unassigned_points = set(\n",
    "    [i for i in puck.all_locs if i not in list(loc_cluster_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only use for RCTD\n",
    "# Expand mapping of beads to clusters iteratively based on majority cluster as a function of closest beads and then once as function of\n",
    "# closest beads that have a cell type label\n",
    "\n",
    "old_length = len(unassigned_points)\n",
    "while True:\n",
    "    for idx in range(len(puck.all_locs)):  # For every location\n",
    "        loc = puck.all_locs[idx]\n",
    "        dist_vector = [0] * len(cell_type_list)  # Make a distance vector\n",
    "        total = 0\n",
    "        if loc in unassigned_points:\n",
    "            locations_closest = [puck.all_locs[i] for i in puck.idxs[idx]\n",
    "                                 ]  # Find list of all closest points\n",
    "            local_total = 0\n",
    "            for loc2 in locations_closest:\n",
    "                #total += 1 # sum all beads, including unassigned\n",
    "                total += 1\n",
    "                if loc2 in loc_cluster_dict:  # Get\n",
    "                    local_total += 1\n",
    "                    if loc_cluster_dict[loc2] in cell_type_list:\n",
    "                        dist_vector[cell_type_list.index(\n",
    "                            loc_cluster_dict[loc2])] += 1\n",
    "            if local_total == 0:\n",
    "                continue\n",
    "            dist_vector_norm = [i / total for i in dist_vector]\n",
    "            print(dist_vector_norm)\n",
    "            break\n",
    "            if max(dist_vector_norm) >= 0.4:\n",
    "                loc_cluster_dict[loc] = cell_type_list[dist_vector_norm.index(\n",
    "                    max(dist_vector_norm))]\n",
    "\n",
    "    currently_assigned_points = set(loc_cluster_dict.keys())\n",
    "    unassigned_points = set(\n",
    "        [i for i in puck.all_locs if i not in currently_assigned_points])\n",
    "    print('Unassigned points', len(unassigned_points))\n",
    "    if len(unassigned_points) == old_length:\n",
    "        break\n",
    "    else:\n",
    "        old_length = len(unassigned_points)\n",
    "\n",
    "for idx in range(len(puck.all_locs)):\n",
    "    loc = puck.all_locs[idx]\n",
    "    dist_vector = [0] * len(cell_type_list)\n",
    "    total = 0\n",
    "    if loc in unassigned_points:\n",
    "        locations_closest = [puck.all_locs[i] for i in puck.idxs[idx]]\n",
    "        local_total = 0\n",
    "        for loc2 in locations_closest:\n",
    "            #total += 1 # sum all beads, including unassigned\n",
    "            total += 1\n",
    "            if loc2 in loc_cluster_dict:\n",
    "                local_total += 1\n",
    "                if loc_cluster_dict[loc2] in cell_type_list:\n",
    "                    dist_vector[cell_type_list.index(\n",
    "                        loc_cluster_dict[loc2])] += 1\n",
    "        if local_total == 0:\n",
    "            continue\n",
    "        dist_vector_norm = [i / local_total for i in dist_vector]\n",
    "        if max(dist_vector_norm) >= 0.5:\n",
    "            loc_cluster_dict[loc] = cell_type_list[dist_vector_norm.index(\n",
    "                max(dist_vector_norm))]\n",
    "\n",
    "currently_assigned_points = set(loc_cluster_dict.keys())\n",
    "unassigned_points = set(\n",
    "    [i for i in puck.all_locs if i not in currently_assigned_points])\n",
    "print('Unassigned points', len(unassigned_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cell_type in cell_type_list:\n",
    "    locs = [i for i in loc_cluster_dict if loc_cluster_dict[i] == cell_type]\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.scatter([i[0] for i in locs], [i[1] for i in locs], s=0.1)\n",
    "    plt.title(cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc_cluster_dict\n",
    "# Update bc_to_cluster_label_dict\n",
    "bcs = [loc_to_bc_s1[loc] for loc in loc_cluster_dict]\n",
    "clusters = [loc_cluster_dict[loc] for loc in loc_cluster_dict]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(zip(bcs, clusters))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tumor_beads = [\n",
    "    j for j in\n",
    "    [i for i in loc_cluster_dict if loc_cluster_dict[i] != 'NonImmuneCell']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tumor_beads = [\n",
    "    j for j in [i for i in puck.loc_to_cluster_dict if loc_to_cluster_dict[i]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate random values\n",
    "def c(l1, l2):\n",
    "    return scipy.spatial.distance.cdist(l1, l2)\n",
    "\n",
    "\n",
    "distarray = c(tumor_beads, tumor_beads)\n",
    "\n",
    "dist_vect = {}\n",
    "d = 20\n",
    "\n",
    "\n",
    "def bc_list_to_clusters_vector(barcode_list):\n",
    "    clusters = [0 for i in range(len(cell_type_list))]\n",
    "    for barcode in barcode_list:\n",
    "        if barcode not in bc_to_cluster_label_dict:\n",
    "            print(barcode, 'not in cluster labels')\n",
    "            continue\n",
    "        cl = cell_type_name_to_num_dict[bc_to_cluster_label_dict[barcode]]\n",
    "        clusters[cl] += 1\n",
    "    return clusters\n",
    "\n",
    "\n",
    "tumor_beads_loc_to_index = {}\n",
    "for i in range(len(tumor_beads)):\n",
    "    tumor_beads_loc_to_index[tumor_beads[i]] = i\n",
    "\n",
    "random_tumor_dict = {}\n",
    "for each_loc in tqdm(tumor_beads):\n",
    "    bead_barcodes_within_dist_of_this_clonotype = []\n",
    "    for loc in tumor_beads:  #bc in puck.bc_loc_dict_s1:\n",
    "        dist = distarray[tumor_beads_loc_to_index[each_loc],\n",
    "                         tumor_beads_loc_to_index[loc]]\n",
    "        if dist < d:\n",
    "            bead_barcodes_within_dist_of_this_clonotype.append(loc)\n",
    "    #cl_convert = bc_list_to_clusters_vector(bead_barcodes_within_dist_of_this_clonotype)\n",
    "    cl_convert = bc_list_to_clusters_vector([\n",
    "        loc_to_bc_s1[loc]\n",
    "        for loc in bead_barcodes_within_dist_of_this_clonotype\n",
    "    ])\n",
    "    if sum(cl_convert) > 0:\n",
    "        random_tumor_dict[each_loc] = np.array(cl_convert) / sum(cl_convert)\n",
    "    else:\n",
    "        random_tumor_dict[each_loc] = np.array(cl_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "puck = puck8\n",
    "normalize = True\n",
    "num_iters = 500\n",
    "random_samplings = {}\n",
    "# Look at only cell locations within tumor region tumor_beads\n",
    "\n",
    "# Perform spatial neighborhood analysis for clonotype beads\n",
    "\n",
    "\n",
    "def bc_list_to_clusters_vector(barcode_list):\n",
    "    clusters = [0 for i in range(len(cell_type_list))]\n",
    "    for barcode in barcode_list:\n",
    "        if barcode not in bc_to_cluster_label_dict:\n",
    "            print(barcode, 'not in cluster labels')\n",
    "            continue\n",
    "        cl = cell_type_name_to_num_dict[bc_to_cluster_label_dict[barcode]]\n",
    "        clusters[cl] += 1\n",
    "    return clusters\n",
    "\n",
    "\n",
    "tumor_beads_loc_to_index = {}\n",
    "for i in range(len(tumor_beads)):\n",
    "    tumor_beads_loc_to_index[tumor_beads[i]] = i\n",
    "\n",
    "# Spatial analysis\n",
    "# Are certain clonotypes around certain cell types more often? Plot distribution of cell clusters within a certain\n",
    "# distance from a clonotype\n",
    "d = 20\n",
    "cl_bc_dist_dict = {}\n",
    "random_samplings = {}\n",
    "for each_clonotype in tqdm(puck.tcr_loc_dict_s1_filtered3):\n",
    "    if len(set(puck.tcr_loc_dict_s1_filtered3[each_clonotype])) < 10:\n",
    "        continue\n",
    "    print(each_clonotype, 'has this many locations:',\n",
    "          len(set(puck.tcr_loc_dict_s1_filtered3[each_clonotype])))\n",
    "    clonotype_barcode_vectors = []\n",
    "    for each_loc in list(set(puck.tcr_loc_dict_s1_filtered3[each_clonotype])):\n",
    "        if each_loc not in tumor_beads_loc_to_index:  ## Tumor filter to only look at beads i tumor region\n",
    "            continue\n",
    "\n",
    "        clonotype_barcode_vectors.append(random_tumor_dict[each_loc])\n",
    "    avg_vector = np.mean(np.array(clonotype_barcode_vectors), axis=0)\n",
    "    print(avg_vector)\n",
    "    # Calculate distance to every other barcode and only keep if <= distance\n",
    "    # Done. Normalize each bead belonging to a cluster before summing\n",
    "    cl_bc_dist_dict[each_clonotype] = avg_vector\n",
    "\n",
    "    if normalize:\n",
    "        iteration = 0\n",
    "        random_vectors = []\n",
    "        random_samplings[each_clonotype] = []\n",
    "\n",
    "        while iteration < num_iters:\n",
    "            iteration += 1\n",
    "            sample_num = len(\n",
    "                set(puck.tcr_loc_dict_s1_filtered3[each_clonotype]))\n",
    "            random_locs = random.sample(tumor_beads, sample_num)\n",
    "            for loc in random_locs:  #bc in puck.bc_loc_dict_s1:\n",
    "                random_vectors.append(random_tumor_dict[loc])\n",
    "            avg_vector_random = np.mean(np.array(random_vectors), axis=0)\n",
    "            random_samplings[each_clonotype].append(avg_vector_random)\n",
    "\n",
    "            # Calculate distance to every other barcode and only keep if <= distance\n",
    "        # Done. Normalize each bead belonging to a cluster before summing\n",
    "        #cl_bc_dist_dict[each_clonotype] = avg_vector\n",
    "        print('Random:', avg_vector_random)\n",
    "        #random_samplings[each_clonotype] = random_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pvalue_mask_df = {}\n",
    "pvalue_mask_df_1minus = {}\n",
    "for cl in cl_bc_dist_dict:\n",
    "    random_vectors = random_samplings[cl]\n",
    "    measured_vector = cl_bc_dist_dict[cl]\n",
    "    random_vectors_converted = [[] for i in range(len(measured_vector))]\n",
    "    for each_random_vector in random_vectors:\n",
    "        for idx in range(len(measured_vector)):\n",
    "            random_vectors_converted[idx].append(each_random_vector[idx])\n",
    "    fraction_less_than_measured = []\n",
    "    for cluster in range(len(random_vectors_converted)):\n",
    "        fraction_less = len([\n",
    "            i for i in random_vectors_converted[cluster]\n",
    "            if i < measured_vector[cluster]\n",
    "        ]) / len(random_vectors_converted[cluster])\n",
    "        fraction_less_than_measured.append(fraction_less)\n",
    "    #print(cl,fraction_less_than_measured)\n",
    "    pvalue_mask_df[cl] = fraction_less_than_measured\n",
    "    # subtract 1 to make it a p value\n",
    "    pvalue_mask_df_1minus[cl] = [1 - x for x in fraction_less_than_measured]\n",
    "\n",
    "pvalue_mask_df = pd.DataFrame.from_dict(pvalue_mask_df, orient='index')\n",
    "pvalue_mask_df_1minus = pd.DataFrame.from_dict(pvalue_mask_df_1minus,\n",
    "                                               orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cl_bc_dist_dict_back_to_clusters = copy.deepcopy(cl_bc_dist_dict)\n",
    "\n",
    "show_plot = False\n",
    "# X axis is clusters, y axis is counts\n",
    "cl_bc_dist_dict_back_to_clusters\n",
    "counter = 0\n",
    "pos_count = 0\n",
    "all_vectors = {}\n",
    "less_than_10 = 0\n",
    "cluster_num = len(cell_type_list)\n",
    "sum_across_all = np.array([0] * cluster_num)\n",
    "for i in cl_bc_dist_dict_back_to_clusters:\n",
    "\n",
    "    pos_count += 1\n",
    "    if show_plot:\n",
    "        plt.plot(range(cluster_num), cl_bc_dist_dict_back_to_clusters[i])\n",
    "        plt.show()\n",
    "    if np.isnan(np.array(cl_bc_dist_dict_back_to_clusters[i])).any():\n",
    "        continue\n",
    "    else:\n",
    "        sum_across_all = sum_across_all + np.array(\n",
    "            cl_bc_dist_dict_back_to_clusters[i])\n",
    "    all_vectors[i] = cl_bc_dist_dict_back_to_clusters[i]\n",
    "\n",
    "print(counter, 'had no counts vs', less_than_10,\n",
    "      'had less than 10 cells closeby', pos_count, 'had >= 10 cells closeby')\n",
    "plt.plot(range(cluster_num), sum_across_all)\n",
    "plt.show()\n",
    "\n",
    "all_vectors_normed = {}\n",
    "for i in all_vectors:\n",
    "    all_vectors_normed[i] = [j / sum(all_vectors[i]) for j in all_vectors[i]]\n",
    "all_vectors_df = pd.DataFrame.from_dict(all_vectors_normed, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_p_vals = list(itertools.chain.from_iterable(pvalue_mask_df.values))\n",
    "all_p_vals_1minus = list(\n",
    "    itertools.chain.from_iterable(pvalue_mask_df_1minus.values))\n",
    "\n",
    "corrected = statsmodels.stats.multitest.multipletests(all_p_vals,\n",
    "                                                      method='fdr_bh')\n",
    "p_val_correction_dict = dict(zip(all_p_vals, corrected[1]))\n",
    "\n",
    "corrected_1minus = statsmodels.stats.multitest.multipletests(all_p_vals_1minus,\n",
    "                                                             method='fdr_bh')\n",
    "p_val_correction_1minus_dict = dict(zip(all_p_vals_1minus, corrected_1minus[1]))\n",
    "\n",
    "pvalue_mask_df_corrected = pvalue_mask_df.copy(deep=True)\n",
    "pvalue_mask_df_1minus_corrected = pvalue_mask_df_1minus.copy(deep=True)\n",
    "\n",
    "for col in pvalue_mask_df_corrected.columns:\n",
    "    pvalue_mask_df_corrected[col] = pvalue_mask_df_corrected[col].map(\n",
    "        p_val_correction_dict)\n",
    "\n",
    "for col in pvalue_mask_df_1minus_corrected.columns:\n",
    "    pvalue_mask_df_1minus_corrected[col] = pvalue_mask_df_1minus_corrected[\n",
    "        col].map(p_val_correction_1minus_dict)\n",
    "\n",
    "cell_type_num_to_name = {}\n",
    "for i in range(len(cell_type_list)):\n",
    "    cell_type_num_to_name[i] = cell_type_list[i]\n",
    "\n",
    "all_vectors_df.drop(columns=[5, 7, 13, 14, 15], inplace=True)\n",
    "pvalue_mask_df_corrected.drop(columns=[5, 7, 13, 14, 15], inplace=True)\n",
    "pvalue_mask_df_1minus_corrected.drop(columns=[5, 7, 13, 14, 15], inplace=True)\n",
    "\n",
    "all_vectors_df.rename(columns=cell_type_num_to_name, inplace=True)\n",
    "pvalue_mask_df_corrected.rename(columns=cell_type_num_to_name, inplace=True)\n",
    "pvalue_mask_df_1minus_corrected.rename(columns=cell_type_num_to_name,\n",
    "                                       inplace=True)\n",
    "\n",
    "all_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# filtered for tumor\n",
    "h = sns.clustermap(all_vectors_df,\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   figsize=(20, 20),\n",
    "                   col_cluster=False,\n",
    "                   z_score=1)\n",
    "plt.savefig('{}_cossim_heatmap_euclidean.pdf'.format(\n",
    "    puck.abbrev_sample_reference))\n",
    "\n",
    "h = sns.clustermap(all_vectors_df,\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   figsize=(20, 20),\n",
    "                   col_cluster=False,\n",
    "                   mask=(pvalue_mask_df_corrected > 0.05),\n",
    "                   z_score=1)\n",
    "plt.savefig('{}_cossim_heatmap_euclidean.pdf'.format(\n",
    "    puck.abbrev_sample_reference))\n",
    "\n",
    "h = sns.clustermap(all_vectors_df,\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   figsize=(20, 20),\n",
    "                   col_cluster=False,\n",
    "                   mask=(pvalue_mask_df_1minus_corrected > 0.05),\n",
    "                   z_score=1)\n",
    "plt.savefig('{}_cossim_heatmap_euclidean.pdf'.format(\n",
    "    puck.abbrev_sample_reference))\n",
    "\n",
    "h = sns.clustermap(all_vectors_df,\n",
    "                   yticklabels=True,\n",
    "                   xticklabels=True,\n",
    "                   figsize=(20, 20),\n",
    "                   metric='cosine',\n",
    "                   col_cluster=False)\n",
    "\n",
    "#plt.savefig('{}_cossim_heatmap_cosine.pdf'.format(puck.abbrev_sample_reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck8\n",
    "for cluster_num in puck.cluster_labels.cluster:\n",
    "    puck.cluster_labels[puck.cluster_labels.cluster == cluster_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Unsupervised neighbors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fn = './Aggregated_clusterassignments.csv'\n",
    "aggregated_clusters = pd.read_csv(fn)\n",
    "rep = [i.split('_')[0] for i in list(aggregated_clusters.barcode)]\n",
    "barcode = [i.split('_')[1] for i in list(aggregated_clusters.barcode)]\n",
    "aggregated_clusters['rep'] = rep\n",
    "aggregated_clusters['barcode'] = barcode\n",
    "\n",
    "if puck == puck8:\n",
    "    puck.cluster_labels = aggregated_clusters[aggregated_clusters.rep ==\n",
    "                                              'rep8']\n",
    "if puck == puck9:\n",
    "    puck.cluster_labels = aggregated_clusters[aggregated_clusters.rep ==\n",
    "                                              'rep9']\n",
    "if puck == puck10:\n",
    "    puck.cluster_labels = aggregated_clusters[aggregated_clusters.rep ==\n",
    "                                              'rep10']\n",
    "\n",
    "puck_tcr_loc_dict = puck.tcr_loc_dict_s1_filtered3\n",
    "\n",
    "cluster_num = len(list(set(puck.cluster_labels.cluster)))\n",
    "puck.cluster_labels['x'] = [\n",
    "    puck.bc_loc_dict_s1[bc][0] for bc in puck.cluster_labels.barcode\n",
    "]\n",
    "puck.cluster_labels['y'] = [\n",
    "    puck.bc_loc_dict_s1[bc][1] for bc in puck.cluster_labels.barcode\n",
    "]\n",
    "\n",
    "bc_to_cluster_label_dict = dict(\n",
    "    zip(puck.cluster_labels.barcode, puck.cluster_labels.cluster))\n",
    "loc_to_cluster_dict = {\n",
    "    puck.bc_loc_dict_s1[i]: bc_to_cluster_label_dict[i]\n",
    "    for i in list(bc_to_cluster_label_dict.keys())\n",
    "}\n",
    "\n",
    "barcodes = [\n",
    "    puck.loc_to_bc_s1[(float(i), float(j))]\n",
    "    for i, j in zip(puck.cluster_labels.x, puck.cluster_labels.y)\n",
    "]\n",
    "puck.cluster_labels['barcode'] = barcodes\n",
    "puck.cluster_labels['cluster_name'] = puck.cluster_labels.cluster\n",
    "cell_type_list = list(set(puck.cluster_labels.cluster_name))\n",
    "cell_type_list_nums = [i for i in range(len(cell_type_list))]\n",
    "cell_type_name_to_num_dict = dict(zip(cell_type_list, cell_type_list_nums))\n",
    "\n",
    "loc_to_cluster_dict = {}\n",
    "for index, row in puck.cluster_labels.iterrows():\n",
    "    location = (row['x'], row['y'])\n",
    "    if location not in loc_to_cluster_dict:\n",
    "        loc_to_cluster_dict[location] = []\n",
    "    loc_to_cluster_dict[location].append(row['cluster_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distarray = c(puck.tumor_beads, puck.tumor_beads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     11,
     21
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find nearest beads and generate dictionary of normalized nearest neighbors vectors\n",
    "# for every point\n",
    "\n",
    "d = 100  # distance\n",
    "\n",
    "loc_list_sort = sorted(puck.tumor_beads, key=lambda x: x[0])\n",
    "loc_list_sort_x = [i[0] for i in loc_list_sort]\n",
    "\n",
    "tumor_beads_loc_to_index = {}\n",
    "for i in range(len(puck.tumor_beads)):\n",
    "    tumor_beads_loc_to_index[puck.tumor_beads[i]] = i\n",
    "\n",
    "random_tumor_dict = {}\n",
    "for each_loc in tqdm(puck.tumor_beads):\n",
    "\n",
    "    # Filter for x values within distance in either direction to reduce number of points needed to search.\n",
    "\n",
    "    x_lower_bound = each_loc[0] - d\n",
    "    x_upper_bound = each_loc[0] + d\n",
    "\n",
    "    locs_within_bounds = loc_list_sort[\n",
    "        find_le(loc_list_sort_x, x_lower_bound\n",
    "                ):find_ge(loc_list_sort_x, x_upper_bound) + 1]\n",
    "    locs_within_bounds = [\n",
    "        loc for loc in locs_within_bounds\n",
    "        if ((each_loc[0] - loc[0])**2 + (each_loc[1] - loc[1])**2)**0.5 < d\n",
    "    ]\n",
    "    cl_convert = bc_list_to_clusters_vector(\n",
    "        [puck.loc_to_bc_s1[loc] for loc in locs_within_bounds])\n",
    "    if sum(cl_convert) > 0:\n",
    "        random_tumor_dict[each_loc] = np.array(cl_convert) / sum(cl_convert)\n",
    "    else:\n",
    "        random_tumor_dict[each_loc] = np.array(cl_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iters = 1000\n",
    "random_samplings = {}\n",
    "# Look at only cell locations within tumor region tumor_beads\n",
    "\n",
    "# Perform spatial neighborhood analysis for clonotype beads\n",
    "\n",
    "# Spatial analysis\n",
    "# Are certain clonotypes around certain cell types more often? Plot distribution of cell clusters within a certain\n",
    "# distance from a clonotype\n",
    "\n",
    "cl_bc_dist_dict = {}\n",
    "cl_bc_dist_dict_all_vectors = {}\n",
    "random_samplings = {}\n",
    "random_samplings_all_vectors = {}\n",
    "for each_clonotype in tqdm(puck_tcr_loc_dict):\n",
    "    if len([\n",
    "            i for i in set(puck_tcr_loc_dict[each_clonotype])\n",
    "            if i in puck.tumor_beads\n",
    "    ]) < 10:\n",
    "        continue\n",
    "    print(\n",
    "        each_clonotype, 'has this many locations:',\n",
    "        len([\n",
    "            i for i in set(puck_tcr_loc_dict[each_clonotype])\n",
    "            if i in puck.tumor_beads\n",
    "        ]))\n",
    "    clonotype_barcode_vectors = []\n",
    "    for each_loc in list(set(puck_tcr_loc_dict[each_clonotype])):\n",
    "        if each_loc not in puck.tumor_beads:  ## Tumor filter to only look at beads i tumor region\n",
    "            continue\n",
    "        clonotype_barcode_vectors.append(random_tumor_dict[each_loc])\n",
    "    avg_vector = np.mean(np.array(clonotype_barcode_vectors), axis=0)\n",
    "    # Calculate distance to every other barcode and only keep if <= distance\n",
    "    # Done. Normalize each bead belonging to a cluster before summing\n",
    "    cl_bc_dist_dict[each_clonotype] = avg_vector\n",
    "    cl_bc_dist_dict_all_vectors[each_clonotype] = clonotype_barcode_vectors\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    random_samplings[each_clonotype] = []\n",
    "    random_samplings_all_vectors[each_clonotype] = []\n",
    "\n",
    "    while iteration < num_iters:\n",
    "        random_vectors = []\n",
    "        iteration += 1\n",
    "        sample_num = len(set(puck_tcr_loc_dict[each_clonotype]))\n",
    "        random_locs = random.sample(puck.tumor_beads, sample_num)\n",
    "        for loc in random_locs:  #bc in puck.bc_loc_dict_s1:\n",
    "            random_vectors.append(random_tumor_dict[loc])\n",
    "        avg_vector_random = np.mean(np.array(random_vectors),\n",
    "                                    axis=0)  #np.mea =n\n",
    "        random_samplings[each_clonotype].append(avg_vector_random)\n",
    "        random_samplings_all_vectors[each_clonotype].append(random_vectors)\n",
    "        # Calculate distance to every other barcode and only keep if <= distance\n",
    "    # Done. Normalize each bead belonging to a cluster before summing\n",
    "    #cl_bc_dist_dict[each_clonotype] = avg_vector\n",
    "    print('Random:', avg_vector_random)\n",
    "    #random_samplings[each_clonotype] = random_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tcr_locs = []\n",
    "for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "    tcr_locs = tcr_locs + list(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "tcr_locs_noset = copy.deepcopy(tcr_locs)\n",
    "tcr_locs = set(tcr_locs)\n",
    "\n",
    "num_cell_clusters = 22\n",
    "random_samplings_all_vectors_transposed = {}\n",
    "for cl in random_samplings_all_vectors:\n",
    "    random_samplings_all_vectors_transposed[cl] = {}\n",
    "    transposed1 = np.transpose(random_samplings_all_vectors[cl])\n",
    "    for cluster in range(num_cell_clusters):\n",
    "        random_samplings_all_vectors_transposed[cl][cluster] = np.transpose(\n",
    "            transposed1[cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_plot = False\n",
    "num_cell_clusters = 22\n",
    "updated_pval = {}\n",
    "updated_pval_lowtail = {}\n",
    "\n",
    "all_distribution = [[]] * num_cell_clusters\n",
    "test = 0\n",
    "shared_locs = []\n",
    "for loc in tcr_locs_noset:\n",
    "    if loc in puck.tumor_beads:\n",
    "        for idx in range(num_cell_clusters):\n",
    "            all_distribution[idx] = all_distribution[idx] + [\n",
    "                random_tumor_dict[loc][idx]\n",
    "            ]\n",
    "\n",
    "distribution_for_cluster_all_iterations_separate = {}\n",
    "for cl in tqdm(cl_bc_dist_dict):\n",
    "    if cl_bc_dist_dict_all_vectors[cl] == []:\n",
    "        continue\n",
    "    if cl in puck.clonotypes['1b']:\n",
    "\n",
    "        updated_pval[cl] = [[]] * num_cell_clusters\n",
    "\n",
    "        updated_pval_lowtail[cl] = [[]] * num_cell_clusters\n",
    "\n",
    "        distribution_for_cluster_all_iterations_separate[cl] = {}\n",
    "\n",
    "        for cell_cluster in range(num_cell_clusters):\n",
    "            measured = [\n",
    "                i[cell_cluster] for i in cl_bc_dist_dict_all_vectors[cl]\n",
    "            ]  # Measured distribution for a cluster\n",
    "\n",
    "            for i in measured:\n",
    "                all_distribution[cell_cluster].remove(i)\n",
    "            #####kstest_for_all_iterations = [kstest(iteration,all_distribution[cell_cluster])[0] for iteration in random_samplings_all_vectors_transposed[cl][cell_cluster]]\n",
    "            kstest_for_measured = kstest(measured,\n",
    "                                         all_distribution[cell_cluster],\n",
    "                                         alternative='greater')[0]\n",
    "            print(\n",
    "                kstest(measured,\n",
    "                       all_distribution[cell_cluster],\n",
    "                       alternative='greater'), 'greater')\n",
    "            print(\n",
    "                kstest(measured,\n",
    "                       all_distribution[cell_cluster],\n",
    "                       alternative='less'), 'less')\n",
    "            #####pval = len([i for i in kstest_for_all_iterations if i > kstest_for_measured])/len(kstest_for_all_iterations)\n",
    "            pval = kstest(measured,\n",
    "                          all_distribution[cell_cluster],\n",
    "                          alternative='greater')[1]\n",
    "            updated_pval[cl][cell_cluster] = pval\n",
    "\n",
    "            #####pval_lowtail = len([i for i in kstest_for_all_iterations if i < kstest_for_measured])/len(kstest_for_all_iterations)\n",
    "            pval_lowtail = kstest(measured,\n",
    "                                  all_distribution[cell_cluster],\n",
    "                                  alternative='less')[1]\n",
    "            updated_pval_lowtail[cl][cell_cluster] = pval_lowtail\n",
    "\n",
    "            lowest = min(min(measured), min(all_distribution[cell_cluster]))\n",
    "            highest = max(max(measured), max(all_distribution[cell_cluster]))\n",
    "\n",
    "            if show_plot:\n",
    "                plt.figure()\n",
    "                #####plt.hist(kstest_for_all_iterations,label='KS test of {} iterations'.format(num_iters))\n",
    "                plt.hist(measured,\n",
    "                         label='measured',\n",
    "                         bins=10,\n",
    "                         alpha=0.5,\n",
    "                         range=(lowest, highest),\n",
    "                         density=True)\n",
    "                plt.hist(all_distribution[cell_cluster],\n",
    "                         bins=10,\n",
    "                         label='all_distribution',\n",
    "                         alpha=0.5,\n",
    "                         range=(lowest, highest),\n",
    "                         density=True)\n",
    "                #plt.axvline(kstest_for_measured,label='measured',c='black')\n",
    "                plt.title('Clonotype: {} Cluster: {}'.format(cl, cell_cluster))\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            #print(ks_2samp(measured,distribution_for_cluster_all_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save KS test\n",
    "save = True\n",
    "if save:\n",
    "    with open('updated_pval_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'wb') as handle:\n",
    "        pkl.dump(updated_pval, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    with open('updated_pval_lowtail_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'wb') as handle:\n",
    "        pkl.dump(updated_pval_lowtail, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('updated_pval_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'rb') as handle:\n",
    "        updated_pval = pkl.load(handle)\n",
    "    with open('updated_pval_lowtail_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'rb') as handle:\n",
    "        updated_pval_lowtail = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save random samplings\n",
    "save = False\n",
    "if save:\n",
    "    with open('cl_bc_dist_dict_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'wb') as handle:\n",
    "        pkl.dump(cl_bc_dist_dict, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    with open('random_samplings_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'wb') as handle:\n",
    "        pkl.dump(random_samplings, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('cl_bc_dist_dict_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'rb') as handle:\n",
    "        cl_bc_dist_dict = pkl.load(handle)\n",
    "    with open('random_samplings_{}_{}.pickle'.format(puck.puck_name, d),\n",
    "              'rb') as handle:\n",
    "        random_samplings = pkl.load(handle)\n",
    "\n",
    "puck = puck10\n",
    "puck.cl_bc_dist_dict = cl_bc_dist_dict\n",
    "puck.random_samplings = random_samplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merged p-values\n",
    "clonotypes_to_neighbors_vectors = {}\n",
    "for puck in [puck8, puck9, puck10]:\n",
    "    for index, row in puck.pvalue_mask_df.iterrows():\n",
    "        if index not in clonotypes_to_neighbors_vectors:\n",
    "            clonotypes_to_neighbors_vectors[index] = []\n",
    "        clonotypes_to_neighbors_vectors[index].append(list(row))\n",
    "\n",
    "\n",
    "def collapse_columns(list_of_lists):  # each list is same length\n",
    "    number_of_entries = len(list_of_lists[0])\n",
    "    new_list = [[]] * number_of_entries\n",
    "    for this_list in list_of_lists:\n",
    "        for idx in range(len(new_list)):\n",
    "            new_list[idx] = new_list[idx] + [this_list[idx]]\n",
    "    return new_list\n",
    "\n",
    "\n",
    "clonotypes_to_neighbors_vectors_aggregated = {}\n",
    "for cl in clonotypes_to_neighbors_vectors:\n",
    "    clonotypes_to_neighbors_vectors_aggregated[cl] = collapse_columns(\n",
    "        clonotypes_to_neighbors_vectors[cl])\n",
    "\n",
    "clonotypes_to_neighbors_vectors_aggregated_fisher = {}\n",
    "for cl in clonotypes_to_neighbors_vectors_aggregated:\n",
    "    aggregated_fisher = [0] * len(\n",
    "        clonotypes_to_neighbors_vectors_aggregated[cl])\n",
    "    for idx in range(len(clonotypes_to_neighbors_vectors_aggregated[cl])):\n",
    "        aggregated_fisher[idx] = scipy.stats.combine_pvalues(\n",
    "            clonotypes_to_neighbors_vectors_aggregated[cl][idx])[1]\n",
    "    clonotypes_to_neighbors_vectors_aggregated_fisher[cl] = aggregated_fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# FOR KS TEST\n",
    "def make_pvalue_mask_df(cl_pvalue_dict, correction=True, log=True):\n",
    "    pvalue_mask_df = pd.DataFrame.from_dict(cl_pvalue_dict, orient='index')\n",
    "    pvalue_mask_df.replace({0.0: 1 / num_iters}, inplace=True)\n",
    "    if correction:\n",
    "        all_p_vals = list(itertools.chain.from_iterable(pvalue_mask_df.values))\n",
    "        corrected = statsmodels.stats.multitest.multipletests(\n",
    "            all_p_vals,\n",
    "            method='fdr_bh',\n",
    "            alpha=0.05,\n",
    "            is_sorted=False,\n",
    "            returnsorted=False)\n",
    "        p_value_dict = dict(zip(all_p_vals, list(corrected[1])))\n",
    "        pvalue_mask_df.replace(p_value_dict, inplace=True)\n",
    "    if log:\n",
    "        pvalue_mask_df = -np.log10(pvalue_mask_df)\n",
    "    return pvalue_mask_df\n",
    "\n",
    "\n",
    "# FOR KS TEST\n",
    "pvalue_mask_df_low = make_pvalue_mask_df(updated_pval_lowtail,\n",
    "                                         correction=False,\n",
    "                                         log=True)\n",
    "pvalue_mask_df = make_pvalue_mask_df(updated_pval, correction=False, log=True)\n",
    "pvalue_mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate enrichments\n",
    "cl_bc_dist_dict_back_to_clusters = copy.deepcopy(cl_bc_dist_dict)\n",
    "r\n",
    "show_plot = False\n",
    "# X axis is clusters, y axis is counts\n",
    "cl_bc_dist_dict_back_to_clusters\n",
    "counter = 0\n",
    "pos_count = 0\n",
    "all_vectors = {}\n",
    "less_than_10 = 0\n",
    "cluster_num = len(cell_type_list)\n",
    "sum_across_all = np.array([0] * cluster_num)\n",
    "for i in cl_bc_dist_dict_back_to_clusters:\n",
    "    if i in puck.clonotypes['1b']:\n",
    "        pos_count += 1\n",
    "        if show_plot:\n",
    "            plt.plot(range(cluster_num), cl_bc_dist_dict_back_to_clusters[i])\n",
    "            plt.show()\n",
    "        if np.isnan(np.array(cl_bc_dist_dict_back_to_clusters[i])).any():\n",
    "            continue\n",
    "        else:\n",
    "            sum_across_all = sum_across_all + np.array(\n",
    "                cl_bc_dist_dict_back_to_clusters[i])\n",
    "        all_vectors[i] = cl_bc_dist_dict_back_to_clusters[i]\n",
    "\n",
    "print(counter, 'had no counts vs', less_than_10,\n",
    "      'had less than 10 cells closeby', pos_count, 'had >= 10 cells closeby')\n",
    "plt.plot(range(cluster_num), sum_across_all)\n",
    "plt.show()\n",
    "\n",
    "all_vectors_normed = {}\n",
    "for i in all_vectors:\n",
    "    all_vectors_normed[i] = [j / sum(all_vectors[i]) for j in all_vectors[i]]\n",
    "all_vectors_df = pd.DataFrame.from_dict(all_vectors_normed, orient='index')\n",
    "\n",
    "all_vectors_df_zscore = (all_vectors_df -\n",
    "                         all_vectors_df.mean()) / all_vectors_df.std()\n",
    "all_vectors_df_zscore_signonly = np.sign(all_vectors_df_zscore)\n",
    "\n",
    "# multiply by + or minus dependign on z score\n",
    "pvalue_mask_df_corrected_minussignlog_adj_sign = np.abs(\n",
    "    pvalue_mask_df_corrected_minussignlog) * all_vectors_df_zscore_signonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set_cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(all_vectors_df,cmap=set_cmap,center=0,yticklabels=True)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(all_vectors_df_zscore,cmap=set_cmap,center=0,yticklabels=True)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(pvalue_mask_df,cmap=set_cmap,yticklabels=True)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(pvalue_mask_df_corrected,cmap=set_cmap,yticklabels=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(pvalue_mask_df, cmap=set_cmap, yticklabels=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(pvalue_mask_df_low, cmap=set_cmap, yticklabels=True)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(pvalue_mask_df_corrected_minussignlog_adj_sign,cmap=set_cmap,center=0,yticklabels=True)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.clustermap(pvalue_mask_df_corrected_minussignlog_adj_sign.dropna(axis=1, how='all'),\n",
    "#                cmap=set_cmap,\n",
    "#               yticklabels=True,xticklabels=True, figsize=(15,15),\n",
    "#                   col_cluster=False,center=0)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.clustermap(all_vectors_df_zscore.dropna(axis=1, how='all'),\n",
    "#                cmap=set_cmap,\n",
    "#               yticklabels=True,xticklabels=True, figsize=(15,15),\n",
    "#                   col_cluster=False,center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot significant relationships\n",
    "\n",
    "if puck == puck8:\n",
    "    repnum = 'rep8'\n",
    "if puck == puck9:\n",
    "    repnum = 'rep9'\n",
    "if puck == puck10:\n",
    "    repnum = 'rep10'\n",
    "\n",
    "\n",
    "###########\n",
    "def save_spatial_neighborhood_plots(puck, pvalue_mask_df, descriptor):\n",
    "    pp = PdfPages('significant_neighbors_enrichments_{}_{}.pdf'.format(\n",
    "        puck.puck_name, descriptor))\n",
    "\n",
    "    for cl, row in pvalue_mask_df.iterrows():\n",
    "        for cluster_number_iter in range(num_cell_clusters):\n",
    "            pval = pvalue_mask_df.loc[cl][cluster_number_iter]\n",
    "            if pval >= 0.05:\n",
    "                continue\n",
    "\n",
    "            #### CHANGE REP\n",
    "            filtereddf = puck.cluster_labels[\n",
    "                (puck.cluster_labels.cluster == cluster_number_iter)\n",
    "                & (puck.cluster_labels.rep == repnum)]\n",
    "            x = list(filtereddf.x)\n",
    "            y = list(filtereddf.y)\n",
    "            testlocs = [(i, j) for i, j in zip(x, y)\n",
    "                        if (i, j) in puck.tumor_beads]\n",
    "            x = [i[0] for i in testlocs]\n",
    "            y = [i[1] for i in testlocs]\n",
    "            plot1 = plt.figure(figsize=(5, 5))\n",
    "            plt.scatter(x, y, s=10, label='cell cluster', c='blue', alpha=0.3)\n",
    "\n",
    "            if cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "                if len(puck.tcr_loc_dict_s1_filtered3[cl]) != 0:\n",
    "                    plt.scatter([\n",
    "                        i[0] for i in puck.tcr_loc_dict_s1_filtered3[cl]\n",
    "                        if i in puck.tumor_beads\n",
    "                    ], [\n",
    "                        i[1] for i in puck.tcr_loc_dict_s1_filtered3[cl]\n",
    "                        if i in puck.tumor_beads\n",
    "                    ],\n",
    "                                label='clonotype',\n",
    "                                s=10,\n",
    "                                c='orange',\n",
    "                                alpha=1)\n",
    "\n",
    "                    points_for_area_of_influence = list(\n",
    "                        set([\n",
    "                            i for i in puck.tcr_loc_dict_s1_filtered3[cl]\n",
    "                            if i in puck.tumor_beads\n",
    "                        ]))\n",
    "                    plt.scatter([i[0] for i in points_for_area_of_influence],\n",
    "                                [i[1] for i in points_for_area_of_influence],\n",
    "                                label='clonotype_nearest_area',\n",
    "                                s=d,\n",
    "                                c='gray',\n",
    "                                alpha=0.1,\n",
    "                                edgecolors='black')\n",
    "                    plt.xlim(0, 6000)\n",
    "                    plt.ylim(0, 6000)\n",
    "\n",
    "            plt.legend()\n",
    "\n",
    "            pval = pvalue_mask_df.loc[cl][cluster_number_iter]\n",
    "            plt.title(cl + ' p = ' + str(round(pval, 3)) + ' cluster: ' +\n",
    "                      str(cluster_number_iter))\n",
    "            plt.show()\n",
    "            pp.savefig(plot1)\n",
    "\n",
    "    pp.close()\n",
    "\n",
    "\n",
    "save_spatial_neighborhood_plots(puck, pvalue_mask_df, 'greater')\n",
    "save_spatial_neighborhood_plots(puck, pvalue_mask_df_low, 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "puck = puck8\n",
    "\n",
    "shared_clonotypes = ['casspqgsdqpqhf'.upper()]\n",
    "# Plots clonotypes\n",
    "for cl in shared_clonotypes:\n",
    "    #     if cl != 'CASSMGTAYEQYF':\n",
    "    #         continue\n",
    "    if cl != 'casspqgsdqpqhf'.upper():\n",
    "        continue\n",
    "\n",
    "    if cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "        if len(puck.tcr_loc_dict_s1_filtered3[cl]) == 0:\n",
    "            continue\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.scatter([i[0] for i in puck.tcr_loc_dict_s1_filtered3[cl]],\n",
    "                    [i[1] for i in puck.tcr_loc_dict_s1_filtered3[cl]])\n",
    "        plt.xlim(0, 6000)\n",
    "        plt.ylim(0, 6000)\n",
    "\n",
    "        plt.title(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Table of clonotype fraction in Slide-seq and CDF in Fig 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fraction calculation for betas for each clonotype\n",
    "tcrs_all = {}\n",
    "for puck in [puck12, puck13]:  #puck8,puck9,puck10\n",
    "    for tcr in puck.tcr_loc_dict_s1_filtered3:\n",
    "        if tcr not in puck.clonotypes['1b']:\n",
    "            continue\n",
    "        if tcr not in tcrs_all:\n",
    "            tcrs_all[tcr] = []\n",
    "        tcrs_all[tcr] = tcrs_all[tcr] + list(\n",
    "            set(puck.tcr_loc_dict_s1_filtered3[tcr])\n",
    "        )  # fraction of beads, not umis\n",
    "sum_all = 0\n",
    "for tcr in tcrs_all:\n",
    "    sum_all += len(tcrs_all[tcr])\n",
    "\n",
    "tcr_name = []\n",
    "fraction_all = []\n",
    "for tcr in tcrs_all:\n",
    "    if len(tcrs_all[tcr]) == 0:\n",
    "        continue\n",
    "    fraction = len(tcrs_all[tcr]) / sum_all\n",
    "    #     if fraction > 0.09: #tcr == 'CASSVTGETGELFF':\n",
    "    #print(fraction,tcr)\n",
    "    tcr_name.append(tcr)\n",
    "    fraction_all.append(fraction)\n",
    "\n",
    "clonotype_fractions = pd.DataFrame.from_dict({\n",
    "    'clonotype': tcr_name,\n",
    "    'fraction': fraction_all\n",
    "})\n",
    "clonotype_fractions.sort_values('fraction', ascending=False, inplace=True)\n",
    "clonotype_fractions.reset_index(inplace=True)\n",
    "clonotype_fractions.drop(columns=['index'], inplace=True)\n",
    "#clonotype_fractions['name'] = ['TCR-'+str(i+1) for i in clonotype_fractions.index]\n",
    "clonotype_fractions['name'] = [\n",
    "    'TCR-' + str(i + 1133) for i in clonotype_fractions.index\n",
    "]\n",
    "clonotype_fractions.to_csv(\n",
    "    './vectorized_figures/pre_treatment_clonotype_fraction_slide_seq.csv')\n",
    "#clonotype_fractions.to_csv('./vectorized_figures/post_treatment_clonotype_fraction_slide_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_treatment_df = pd.read_csv(\n",
    "    './vectorized_figures/pre_treatment_clonotype_fraction_slide_seq.csv')\n",
    "post_treatment_df = pd.read_csv(\n",
    "    './vectorized_figures/post_treatment_clonotype_fraction_slide_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "post_treatment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Histogram of percent of all beads vs clonotype\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.figure()\n",
    "df = pd.DataFrame.from_dict({'cl': cls, 'counts': counts})\n",
    "cumsum_12 = list(\n",
    "    pre_treatment_df.sort_values('fraction',\n",
    "                                 ascending=False).cumsum()['fraction'])\n",
    "cumsum_10 = list(\n",
    "    post_treatment_df.sort_values('fraction',\n",
    "                                  ascending=False).cumsum()['fraction'])\n",
    "plt.step(range(len(cumsum)), cumsum)\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Clonotype Index')\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "df = pd.DataFrame.from_dict({'cl': cls, 'counts': counts})\n",
    "plt.step(range(len(cumsum_12)), cumsum_12, label='pre-treatment')\n",
    "plt.step(range(len(cumsum_10)), cumsum_10, label='post-treatment')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Clonotype Index')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure2e.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Spleen spatial correlation between variable and constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find beads with constant Alpha or Beta sequence\n",
    "puck = puckSpleen\n",
    "constant_seq_present = puck.s1_dge_fmtd[(puck.s1_dge_fmtd['Trac'] > 0) |\n",
    "                                        (puck.s1_dge_fmtd['Trbc2'] > 0)]\n",
    "constant_seq_present_tcra_tcrb_sum = constant_seq_present[\n",
    "    'Trac'] + constant_seq_present['Trbc2']\n",
    "constant_seq_present_bcs = []\n",
    "for bc in constant_seq_present.index:\n",
    "    constant_seq_present_bcs = constant_seq_present_bcs + [\n",
    "        bc\n",
    "    ]  #*int(constant_seq_present_tcra_tcrb_sum[bc])\n",
    "\n",
    "# Find beads with variable Alpha or Beta sequence\n",
    "variable_seq_present = []\n",
    "for tcr in puck.tcr_loc_dict_s1_filtered3:\n",
    "    for loc in set(puck.tcr_loc_dict_s1_filtered3[tcr]):  # bead barcodes\n",
    "        variable_seq_present.append(loc)\n",
    "variable_seq_present = list(set(variable_seq_present))\n",
    "\n",
    "## Constant\n",
    "x = [i[0] for i in [puck.bc_loc_dict_s1[i] for i in constant_seq_present_bcs]]\n",
    "y = [i[1] for i in [puck.bc_loc_dict_s1[i] for i in constant_seq_present_bcs]]\n",
    "\n",
    "heatmap_constant, xedges, yedges = np.histogram2d(x, y, bins=50)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "## Variable\n",
    "x_var = [i[0] for i in variable_seq_present]\n",
    "y_var = [i[1] for i in variable_seq_present]\n",
    "\n",
    "heatmap_variable, xedges, yedges = np.histogram2d(x_var, y_var, bins=50)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "## Constant\n",
    "plt.imshow(heatmap_constant.T, extent=extent, origin='lower')\n",
    "plt.colorbar()\n",
    "plt.savefig('./vectorized_figures/Supplementary Figure 2A.pdf')\n",
    "\n",
    "## Variable\n",
    "plt.imshow(heatmap_variable.T, extent=extent, origin='lower')\n",
    "plt.colorbar()\n",
    "plt.savefig('./vectorized_figures/Supplementary Figure 2B.pdf')\n",
    "\n",
    "## Plot correlation between the two\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "x = heatmap_constant.reshape(-1)\n",
    "y = heatmap_variable.reshape(-1)\n",
    "pearson = np.corrcoef(x, y)\n",
    "pearson_log = np.corrcoef(np.nan_to_num(np.log10(x)),\n",
    "                          np.nan_to_num(np.log10(y)))\n",
    "print(pearson, pearson_log)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x, y, alpha=0.1)\n",
    "abline(scipy.stats.linregress(x, y)[0], scipy.stats.linregress(x, y)[1])\n",
    "print(scipy.stats.linregress(x, y))\n",
    "plt.xlabel('constant')\n",
    "plt.ylabel('variable')\n",
    "plt.savefig('./vectorized_figures/Supplementary Figure 2C.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.log10(heatmap_constant.reshape(-1)),\n",
    "            np.log10(heatmap_variable.reshape(-1)))\n",
    "plt.xlabel('constant')\n",
    "plt.ylabel('variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Venn diagram for constant and variable reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Percent of the time that we capture variable from constant\n",
    "constant_locs = []\n",
    "variable_locs = []\n",
    "constant_locs = [\n",
    "    puckSpleen.bc_loc_dict_s1[i]\n",
    "    for i in puckSpleen.s1_dge_fmtd[(puckSpleen.s1_dge_fmtd['Trac'] > 0) | (\n",
    "        puckSpleen.s1_dge_fmtd['Trbc2'] > 0)].index\n",
    "]\n",
    "for tcr in puckSpleen.tcr_loc_dict_s1_filtered3:\n",
    "    variable_locs = variable_locs + puckSpleen.tcr_loc_dict_s1_filtered3[tcr]\n",
    "\n",
    "constant_locs = set(constant_locs)\n",
    "variable_locs = set(variable_locs)\n",
    "\n",
    "shared_locs = set(list(constant_locs & variable_locs))\n",
    "print(\n",
    "    len(shared_locs) / len(constant_locs),\n",
    "    'fraction of constant that also have variable ')\n",
    "print(\n",
    "    len([i\n",
    "         for i in variable_locs if i not in shared_locs]) / len(variable_locs),\n",
    "    'new to constant')\n",
    "\n",
    "#####\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "set1 = constant_locs\n",
    "set2 = variable_locs\n",
    "\n",
    "v = venn2([set1, set2], ('Constant Locations', 'Variable Locations'))\n",
    "c = venn2_circles([set1, set2])\n",
    "c[0].set_color(\"white\")\n",
    "c[0].set_ls('solid')\n",
    "c[0].set_edgecolor('blue')\n",
    "\n",
    "c[1].set_color(\"white\")\n",
    "c[1].set_ls('solid')\n",
    "c[1].set_edgecolor('red')\n",
    "plt.savefig('./vectorized_figures/Supplementary Figure 1B.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Comparing Slide-seq replicate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make plot comparing Slide-seq replicates for post-treatment renal cell carcinoma\n",
    "\n",
    "puck8.total_reads = sum(puck8.s1_total_counts)\n",
    "puck9.total_reads = sum(puck9.s1_total_counts)\n",
    "puck10.total_reads = sum(puck10.s1_total_counts)\n",
    "\n",
    "puck8.total_cl_counts = 0\n",
    "puck9.total_cl_counts = 0\n",
    "puck10.total_cl_counts = 0\n",
    "\n",
    "puck8_umi_cl_counts = []\n",
    "puck9_umi_cl_counts = []\n",
    "for cl in puck8.tcr_loc_dict_s1_filtered3:\n",
    "    if cl in puck9.tcr_loc_dict_s1_filtered3:\n",
    "        if len(puck8.tcr_loc_dict_s1_filtered3[cl]) <= 0:\n",
    "            continue\n",
    "        if len(puck9.tcr_loc_dict_s1_filtered3[cl]) <= 0:\n",
    "            continue\n",
    "        puck8.total_cl_counts += len(puck8.tcr_loc_dict_s1_filtered3[cl])\n",
    "        puck9.total_cl_counts += len(puck9.tcr_loc_dict_s1_filtered3[cl])\n",
    "        puck8_umi_cl_counts.append(len(puck8.tcr_loc_dict_s1_filtered3[cl]))\n",
    "        puck9_umi_cl_counts.append(len(puck9.tcr_loc_dict_s1_filtered3[cl]))\n",
    "\n",
    "puck8_umi_cl_counts_vs10 = []\n",
    "puck10_umi_cl_counts = []\n",
    "for cl in puck8.tcr_loc_dict_s1_filtered3:\n",
    "    if cl in puck10.tcr_loc_dict_s1_filtered3:\n",
    "        if len(puck8.tcr_loc_dict_s1_filtered3[cl]) <= 0:\n",
    "            continue\n",
    "        if len(puck10.tcr_loc_dict_s1_filtered3[cl]) <= 0:\n",
    "            continue\n",
    "        puck8_umi_cl_counts_vs10.append(\n",
    "            len(puck8.tcr_loc_dict_s1_filtered3[cl]))\n",
    "        puck10.total_cl_counts += len(puck10.tcr_loc_dict_s1_filtered3[cl])\n",
    "        puck10_umi_cl_counts.append(len(puck10.tcr_loc_dict_s1_filtered3[cl]))\n",
    "\n",
    "puck9_umi_cl_counts_vs10 = []\n",
    "puck10_umi_cl_counts_vs9 = []\n",
    "for cl in puck9.tcr_loc_dict_s1_filtered3:\n",
    "    if cl in puck10.tcr_loc_dict_s1_filtered3:\n",
    "        if len(puck9.tcr_loc_dict_s1_filtered3[cl]) <= 0:\n",
    "            continue\n",
    "        if len(puck10.tcr_loc_dict_s1_filtered3[cl]) <= 0:\n",
    "            continue\n",
    "\n",
    "        puck9_umi_cl_counts_vs10.append(\n",
    "            len(puck9.tcr_loc_dict_s1_filtered3[cl]))\n",
    "        puck10_umi_cl_counts_vs9.append(\n",
    "            len(puck10.tcr_loc_dict_s1_filtered3[cl]))\n",
    "\n",
    "\n",
    "def normalize_by_total_reads(list_name, total_reads):\n",
    "    return [i / total_reads for i in list_name]\n",
    "\n",
    "\n",
    "puck8_umi_cl_counts = normalize_by_total_reads(puck8_umi_cl_counts,\n",
    "                                               puck8.total_cl_counts)\n",
    "puck8_umi_cl_counts_vs10 = normalize_by_total_reads(puck8_umi_cl_counts_vs10,\n",
    "                                                    puck8.total_cl_counts)\n",
    "puck9_umi_cl_counts = normalize_by_total_reads(puck9_umi_cl_counts,\n",
    "                                               puck9.total_cl_counts)\n",
    "puck9_umi_cl_counts_vs10 = normalize_by_total_reads(puck9_umi_cl_counts_vs10,\n",
    "                                                    puck9.total_cl_counts)\n",
    "puck10_umi_cl_counts = normalize_by_total_reads(puck10_umi_cl_counts,\n",
    "                                                puck10.total_cl_counts)\n",
    "puck10_umi_cl_counts_vs9 = normalize_by_total_reads(puck10_umi_cl_counts_vs9,\n",
    "                                                    puck10.total_cl_counts)\n",
    "\n",
    "puck8_umi_cl_counts = np.log10(puck8_umi_cl_counts)\n",
    "puck9_umi_cl_counts = np.log10(puck9_umi_cl_counts)\n",
    "puck10_umi_cl_counts = np.log10(puck10_umi_cl_counts)\n",
    "puck8_umi_cl_counts_vs10 = np.log10(puck8_umi_cl_counts_vs10)\n",
    "puck9_umi_cl_counts_vs10 = np.log10(puck9_umi_cl_counts_vs10)\n",
    "puck10_umi_cl_counts_vs9 = np.log10(puck10_umi_cl_counts_vs9)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax1.scatter(puck8_umi_cl_counts,\n",
    "            puck9_umi_cl_counts,\n",
    "            label='8 vs 9',\n",
    "            alpha=0.5)\n",
    "ax2.scatter(puck8_umi_cl_counts_vs10,\n",
    "            puck10_umi_cl_counts,\n",
    "            label='8 vs 10',\n",
    "            alpha=0.5)\n",
    "ax3.scatter(puck9_umi_cl_counts_vs10,\n",
    "            puck10_umi_cl_counts_vs9,\n",
    "            label='9 vs 10',\n",
    "            alpha=0.5)\n",
    "# plt.legend()\n",
    "\n",
    "abline(scipy.stats.linregress(puck8_umi_cl_counts, puck9_umi_cl_counts)[0],\n",
    "       scipy.stats.linregress(puck8_umi_cl_counts, puck9_umi_cl_counts)[1],\n",
    "       ax_name=ax1)\n",
    "abline(scipy.stats.linregress(puck8_umi_cl_counts_vs10,\n",
    "                              puck10_umi_cl_counts)[0],\n",
    "       scipy.stats.linregress(puck8_umi_cl_counts_vs10,\n",
    "                              puck10_umi_cl_counts)[1],\n",
    "       ax_name=ax2)\n",
    "abline(scipy.stats.linregress(puck9_umi_cl_counts_vs10,\n",
    "                              puck10_umi_cl_counts_vs9)[0],\n",
    "       scipy.stats.linregress(puck9_umi_cl_counts_vs10,\n",
    "                              puck10_umi_cl_counts_vs9)[1],\n",
    "       ax_name=ax3)\n",
    "\n",
    "print('r',\n",
    "      scipy.stats.linregress(puck8_umi_cl_counts, puck9_umi_cl_counts)[2],\n",
    "      'pval',\n",
    "      scipy.stats.linregress(puck8_umi_cl_counts, puck9_umi_cl_counts)[3])\n",
    "print(\n",
    "    'r',\n",
    "    scipy.stats.linregress(puck8_umi_cl_counts_vs10, puck10_umi_cl_counts)[2],\n",
    "    'pval',\n",
    "    scipy.stats.linregress(puck8_umi_cl_counts_vs10, puck10_umi_cl_counts)[3])\n",
    "print(\n",
    "    'r',\n",
    "    scipy.stats.linregress(puck9_umi_cl_counts_vs10,\n",
    "                           puck10_umi_cl_counts_vs9)[2], 'pval',\n",
    "    scipy.stats.linregress(puck9_umi_cl_counts_vs10,\n",
    "                           puck10_umi_cl_counts_vs9)[3])\n",
    "\n",
    "args = (puck9_umi_cl_counts_vs10, puck10_umi_cl_counts_vs9,\n",
    "        puck8_umi_cl_counts_vs10, puck10_umi_cl_counts, puck8_umi_cl_counts,\n",
    "        puck9_umi_cl_counts)\n",
    "all_counts = np.concatenate(args)\n",
    "\n",
    "max_val = max(all_counts)\n",
    "min_val = min(all_counts)\n",
    "plt.xlim([min_val * 0.9, max_val * 1.1])\n",
    "plt.ylim([min_val * 0.9, max_val * 1.1])\n",
    "plt.savefig('./vectorized_figures/sf3c.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bulk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_bulk_beta = pd.read_excel('RCC Bulk TCR.26Oct20.xls',\n",
    "                              sheet_name='RCCpre Beta')\n",
    "post_bulk_beta = pd.read_excel('RCC Bulk TCR.26Oct20.xls',\n",
    "                               sheet_name='RCCpost Beta')\n",
    "pre_bulk_alpha = pd.read_excel('RCC Bulk TCR.26Oct20.xls',\n",
    "                               sheet_name='RCCpre Alpha')\n",
    "post_bulk_alpha = pd.read_excel('RCC Bulk TCR.26Oct20.xls',\n",
    "                                sheet_name='RCCpost Alpha')\n",
    "\n",
    "# pre_bulk_beta = pre_bulk_beta[pre_bulk_beta.count_sum >=10]\n",
    "# post_bulk_beta = post_bulk_beta[post_bulk_beta.count_sum >=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shared_beta_bulk = list(set(post_bulk_beta.cdr3) & set(pre_bulk_beta.cdr3))\n",
    "union_beta_bulk = list(\n",
    "    set(list(post_bulk_beta.cdr3) + list(pre_bulk_beta.cdr3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_freq = []\n",
    "post_freq = []\n",
    "pre_freq_union = []\n",
    "post_freq_union = []\n",
    "for cl in shared_beta_bulk:\n",
    "    post_freq.append(float(post_bulk_beta[post_bulk_beta.cdr3 == cl]['Freq']))\n",
    "    pre_freq.append(float(pre_bulk_beta[pre_bulk_beta.cdr3 == cl]['Freq']))\n",
    "\n",
    "post_bb_cdr3 = list(post_bulk_beta.cdr3)\n",
    "pre_bb_cdr3 = list(pre_bulk_beta.cdr3)\n",
    "for cl in union_beta_bulk:\n",
    "    if cl in post_bb_cdr3:\n",
    "        post_freq_union.append(\n",
    "            float(post_bulk_beta[post_bulk_beta.cdr3 == cl]['Freq']))\n",
    "    else:\n",
    "        post_freq_union.append(min(post_bulk_beta.Freq) / 100)\n",
    "    if cl in pre_bb_cdr3:\n",
    "        pre_freq_union.append(\n",
    "            float(pre_bulk_beta[pre_bulk_beta.cdr3 == cl]['Freq']))\n",
    "    else:\n",
    "        pre_freq_union.append(min(pre_bulk_beta.Freq) / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CDF for bulk\n",
    "# Histogram of percent of all beads vs clonotype\n",
    "plt.figure()\n",
    "cumsum_12 = list(\n",
    "    pre_bulk_beta.sort_values('Freq', ascending=False).cumsum()['Freq'])\n",
    "cumsum_10 = list(\n",
    "    post_bulk_beta.sort_values('Freq', ascending=False).cumsum()['Freq'])\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.step(range(len(cumsum_12)), cumsum_12, label='pre-treatment')\n",
    "plt.step(range(len(cumsum_10)), cumsum_10, label='post-treatment')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Clonotype Index')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/supp_figure4a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# VENN DIAGRAM FOR PRE AND POST-TREATMENT CLONOTYPES\n",
    "\n",
    "# IN SLIDE-SEQ\n",
    "pre_treatment_df = pd.read_csv(\n",
    "    './vectorized_figures/pre_treatment_clonotype_fraction_slide_seq.csv')\n",
    "post_treatment_df = pd.read_csv(\n",
    "    './vectorized_figures/post_treatment_clonotype_fraction_slide_seq.csv')\n",
    "\n",
    "\n",
    "def clono_vd(pre_list, post_list, labels, filename):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    set1 = set(pre_list)\n",
    "    set2 = set(post_list)\n",
    "\n",
    "    v = venn2([set1, set2], labels)\n",
    "    c = venn2_circles([set1, set2])\n",
    "    c[0].set_color(\"white\")\n",
    "    c[0].set_ls('solid')\n",
    "    c[0].set_edgecolor('blue')\n",
    "\n",
    "    c[1].set_color(\"white\")\n",
    "    c[1].set_ls('solid')\n",
    "    c[1].set_edgecolor('red')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "clono_vd(list(pre_treatment_df.clonotype),\n",
    "         list(post_treatment_df.clonotype),\n",
    "         ('pre-treatment', 'post-treatment'),\n",
    "         filename='./vectorized_figures/Supplementary Figure 5B_slide_seq.pdf')\n",
    "clono_vd(list(pre_bulk_beta.cdr3),\n",
    "         list(post_bulk_beta.cdr3), ('pre-treatment', 'post-treatment'),\n",
    "         filename='./vectorized_figures/Supplementary Figure 5B_bulk.pdf')\n",
    "# IN BULK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     14,
     32,
     44,
     59
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# PLOT CHANGES IN CLONOTYPE FRACTIONS FOR SHARED CLONOTYPES AND ALL CLONOTYPES for slide-seq and bulk\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "shared_test = list(\n",
    "    set(pre_treatment_df.clonotype) & set(post_treatment_df.clonotype))\n",
    "x = []\n",
    "y = []\n",
    "for i in shared_test:\n",
    "    x.append(float(pre_treatment_df[pre_treatment_df.clonotype == i].fraction))\n",
    "    y.append(\n",
    "        float(post_treatment_df[post_treatment_df.clonotype == i].fraction))\n",
    "\n",
    "x_pre_higher = []\n",
    "y_pre_higher = []\n",
    "x_post_higher = []\n",
    "y_post_higher = []\n",
    "\n",
    "for (xid, yid) in zip(x, y):\n",
    "    if xid > yid:\n",
    "        x_pre_higher.append(xid)\n",
    "        y_pre_higher.append(yid)\n",
    "    else:\n",
    "        x_post_higher.append(xid)\n",
    "        y_post_higher.append(yid)\n",
    "\n",
    "x_pre_higher = np.log10(x_pre_higher)\n",
    "y_pre_higher = np.log10(y_pre_higher)\n",
    "x_post_higher = np.log10(x_post_higher)\n",
    "y_post_higher = np.log10(y_post_higher)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "#plt.scatter(x,y)\n",
    "plt.scatter(x_pre_higher,\n",
    "            y_pre_higher,\n",
    "            c='red',\n",
    "            s=10,\n",
    "            label='Higher clonotype fraction in pre-treatment')\n",
    "plt.scatter(x_post_higher,\n",
    "            y_post_higher,\n",
    "            c='blue',\n",
    "            s=10,\n",
    "            label='Higher clonotype fraction in post-treatment')\n",
    "\n",
    "for i, txt in enumerate(shared_test):\n",
    "    #ax.annotate(txt, (x[i], y[i]))\n",
    "    ax.annotate(txt, (np.log10(x[i]), np.log10(y[i])))\n",
    "plt.xlabel('Fraction in pre-treatment')\n",
    "plt.ylabel('Fraction in post-treatment')\n",
    "plt.savefig('./vectorized_figures/sf5c.pdf')\n",
    "\n",
    "############## ALL CLONOTYPES\n",
    "shared_test = list(pre_treatment_df.clonotype) + list(\n",
    "    post_treatment_df.clonotype)\n",
    "shared_test = set(shared_test)\n",
    "x = []\n",
    "y = []\n",
    "for i in shared_test:\n",
    "    if i in list(pre_treatment_df.clonotype):\n",
    "        x.append(\n",
    "            float(pre_treatment_df[pre_treatment_df.clonotype == i].fraction))\n",
    "    else:\n",
    "        x.append(0)\n",
    "    if i in list(post_treatment_df.clonotype):\n",
    "        y.append(\n",
    "            float(\n",
    "                post_treatment_df[post_treatment_df.clonotype == i].fraction))\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "x_pre_higher = []\n",
    "y_pre_higher = []\n",
    "x_post_higher = []\n",
    "y_post_higher = []\n",
    "\n",
    "for (xid, yid) in zip(x, y):\n",
    "    if xid > yid:\n",
    "        x_pre_higher.append(xid)\n",
    "        y_pre_higher.append(yid)\n",
    "    else:\n",
    "        x_post_higher.append(xid)\n",
    "        y_post_higher.append(yid)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "#plt.scatter(x,y)\n",
    "x_pre_higher = np.log(x_pre_higher)\n",
    "y_pre_higher = np.log(y_pre_higher)\n",
    "x_post_higher = np.log(x_post_higher)\n",
    "y_post_higher = np.log(y_post_higher)\n",
    "\n",
    "plt.scatter(x_pre_higher,\n",
    "            y_pre_higher,\n",
    "            c='blue',\n",
    "            s=10,\n",
    "            label='Higher clonotype fraction in pre-treatment')\n",
    "plt.scatter(x_post_higher,\n",
    "            y_post_higher,\n",
    "            c='red',\n",
    "            s=10,\n",
    "            label='Higher clonotype fraction in post-treatment')\n",
    "\n",
    "# for i, txt in enumerate(shared_test):\n",
    "#     ax.annotate(txt, (x[i], y[i]))\n",
    "plt.xlabel('Fraction in pre-treatment')\n",
    "plt.ylabel('Fraction in post-treatment')\n",
    "plt.savefig('./vectorized_figures/sf5c_all_cl.pdf')\n",
    "\n",
    "#### BULK\n",
    "\n",
    "# PLOT CHANGES IN CLONOTYPE FRACTIONS FOR SHARED CLONOTYPES AND ALL CLONOTYPES for slide-seq and bulk\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "shared_test = list(set(pre_bulk_beta.cdr3) & set(post_bulk_beta.cdr3))\n",
    "x = []\n",
    "y = []\n",
    "for i in shared_test:\n",
    "    x.append(float(pre_bulk_beta[pre_bulk_beta.cdr3 == i].Freq))\n",
    "    y.append(float(post_bulk_beta[post_bulk_beta.cdr3 == i].Freq))\n",
    "\n",
    "x_pre_higher = []\n",
    "y_pre_higher = []\n",
    "x_post_higher = []\n",
    "y_post_higher = []\n",
    "\n",
    "for (xid, yid) in zip(x, y):\n",
    "    if xid > yid:\n",
    "        x_pre_higher.append(xid)\n",
    "        y_pre_higher.append(yid)\n",
    "    else:\n",
    "        x_post_higher.append(xid)\n",
    "        y_post_higher.append(yid)\n",
    "\n",
    "x_pre_higher = np.log10(x_pre_higher)\n",
    "y_pre_higher = np.log10(y_pre_higher)\n",
    "x_post_higher = np.log10(x_post_higher)\n",
    "y_post_higher = np.log10(y_post_higher)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "#plt.scatter(x,y)\n",
    "plt.scatter(x_pre_higher,\n",
    "            y_pre_higher,\n",
    "            c='red',\n",
    "            s=10,\n",
    "            label='Higher clonotype fraction in pre-treatment',\n",
    "            alpha=0.3)\n",
    "plt.scatter(x_post_higher,\n",
    "            y_post_higher,\n",
    "            c='blue',\n",
    "            s=10,\n",
    "            label='Higher clonotype fraction in post-treatment',\n",
    "            alpha=0.3)\n",
    "\n",
    "for i, txt in enumerate(shared_test):\n",
    "    #ax.annotate(txt, (x[i], y[i]))\n",
    "    ax.annotate(txt, (np.log10(x[i]), np.log10(y[i])))\n",
    "plt.xlabel('Fraction in pre-treatment')\n",
    "plt.ylabel('Fraction in post-treatment')\n",
    "plt.savefig('./vectorized_figures/sf5c_bulk.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tcrs_counts = {}\n",
    "for puck in [puck8, puck9, puck10]:\n",
    "    for cl in puck.tcr_loc_dict_s1_filtered3:\n",
    "        if len(puck.tcr_loc_dict_s1_filtered3[cl]) == 0:\n",
    "            continue\n",
    "        if cl not in puck.clonotypes['1b']:\n",
    "            continue\n",
    "        clnum = len(set(puck.tcr_loc_dict_s1_filtered3[cl]))\n",
    "        if cl not in all_tcrs_counts:\n",
    "            all_tcrs_counts[cl] = 0\n",
    "        all_tcrs_counts[cl] += clnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Comparing bulk and slide-seq clonotype fractions\n",
    "pre_treatment_df = pd.read_csv(\n",
    "    './vectorized_figures/pre_treatment_clonotype_fraction_slide_seq.csv')\n",
    "post_treatment_df = pd.read_csv(\n",
    "    './vectorized_figures/post_treatment_clonotype_fraction_slide_seq.csv')\n",
    "post_treatment_df = post_treatment_df[\n",
    "    post_treatment_df.fraction > 0.00018889308651303364 * 10]\n",
    "pre_treatment_dict = dict(zip(pre_treatment_df.clonotype, pre_treatment_df.fraction))\n",
    "pre_treatment_dict_bulk = dict(zip(pre_bulk_beta.cdr3, pre_bulk_beta.Freq))\n",
    "\n",
    "post_treatment_dict = dict(zip(post_treatment_df.clonotype, post_treatment_df.fraction))\n",
    "post_treatment_dict_bulk = dict(zip(post_bulk_beta.cdr3, post_bulk_beta.Freq))\n",
    "\n",
    "values_in_slide_seq = []\n",
    "values_in_bulk = []\n",
    "for cl in post_treatment_dict:\n",
    "    if cl in post_treatment_dict_bulk:\n",
    "        values_in_slide_seq.append(post_treatment_dict[cl])\n",
    "        values_in_bulk.append(post_treatment_dict_bulk[cl])\n",
    "# for cl in pre_treatment_dict:\n",
    "#     if cl in pre_treatment_dict_bulk:\n",
    "#         values_in_slide_seq.append(pre_treatment_dict[cl])\n",
    "#         values_in_bulk.append(pre_treatment_dict_bulk[cl])\n",
    "\n",
    "\n",
    "x = np.log10(values_in_bulk)\n",
    "y = np.log10(values_in_slide_seq)\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = scipy.stats.linregress(\n",
    "    x, y)[1] + scipy.stats.linregress(x, y)[0] * x_vals\n",
    "ax.plot(x_vals, y_vals, '--')\n",
    "plt.savefig('./vectorized_figures/sf3d_post.pdf')\n",
    "pearsonr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lower_lim = min(min(pre_freq), min(post_freq))\n",
    "upper_lim = max(max(pre_freq), max(post_freq))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(pre_freq, post_freq, alpha=0.2)\n",
    "plt.xlabel('Pre-treatment frequency')\n",
    "plt.ylabel('Post-treatment frequency')\n",
    "plt.title('Bulk')\n",
    "plt.xlim([lower_lim - .1, upper_lim + .1])\n",
    "plt.ylim([lower_lim - .1, upper_lim + .1])\n",
    "abline(\n",
    "    scipy.stats.linregress(pre_freq, post_freq)[0],\n",
    "    scipy.stats.linregress(pre_freq, post_freq)[1])\n",
    "print(scipy.stats.linregress(pre_freq, post_freq))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(np.log10(pre_freq), np.log10(post_freq), alpha=0.2)\n",
    "plt.title('log-log version')\n",
    "plt.xlim([np.log10(lower_lim) - .1, np.log10(upper_lim) + .1])\n",
    "plt.ylim([np.log10(lower_lim) - .1, np.log10(upper_lim) + .1])\n",
    "plt.xlabel('Pre-treatment frequency')\n",
    "plt.ylabel('Post-treatment frequency')\n",
    "abline(\n",
    "    scipy.stats.linregress(np.log10(pre_freq), np.log10(post_freq))[0],\n",
    "    scipy.stats.linregress(np.log10(pre_freq), np.log10(post_freq))[1])\n",
    "print(scipy.stats.linregress(np.log10(pre_freq), np.log10(post_freq)))\n",
    "\n",
    "lower_lim = min(min(pre_freq_union), min(post_freq_union))\n",
    "upper_lim = max(max(pre_freq_union), max(post_freq_union))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(pre_freq_union, post_freq_union, alpha=0.2)\n",
    "plt.xlabel('Pre-treatment frequency')\n",
    "plt.ylabel('Post-treatment frequency')\n",
    "plt.title('Bulk')\n",
    "plt.xlim([lower_lim - .1, upper_lim + .1])\n",
    "plt.ylim([lower_lim - .1, upper_lim + .1])\n",
    "abline(\n",
    "    scipy.stats.linregress(pre_freq_union, post_freq_union)[0],\n",
    "    scipy.stats.linregress(pre_freq_union, post_freq_union)[1])\n",
    "print(scipy.stats.linregress(pre_freq_union, post_freq_union))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(np.log10(pre_freq_union), np.log10(post_freq_union), alpha=0.2)\n",
    "plt.title('log-log version')\n",
    "plt.xlim([np.log10(lower_lim) - .1, np.log10(upper_lim) + .1])\n",
    "plt.ylim([np.log10(lower_lim) - .1, np.log10(upper_lim) + .1])\n",
    "plt.xlabel('Pre-treatment frequency')\n",
    "plt.ylabel('Post-treatment frequency')\n",
    "\n",
    "abline(\n",
    "    scipy.stats.linregress(np.log10(pre_freq_union),\n",
    "                           np.log10(post_freq_union))[0],\n",
    "    scipy.stats.linregress(np.log10(pre_freq_union),\n",
    "                           np.log10(post_freq_union))[1])\n",
    "print(\n",
    "    scipy.stats.linregress(np.log10(pre_freq_union),\n",
    "                           np.log10(post_freq_union)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot bulk fraction against Slide-seq fraction for POST\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "post_betas = list(post_bulk_beta.cdr3)\n",
    "post_beta_freq = list(post_bulk_beta.Freq)\n",
    "\n",
    "aggregated_total_umi = 0\n",
    "aggregated_fraction = {}\n",
    "for puck in [puck8, puck9, puck10]:\n",
    "    bulk_val = []\n",
    "    puck_val = []\n",
    "    all_reads_deduped = 0\n",
    "    tcr_loc_dict_to_use = puck.tcr_loc_dict_s1_filtered3\n",
    "    puck.tcr_fraction = {}\n",
    "\n",
    "    for cl in tcr_loc_dict_to_use:\n",
    "        len_this_cl = len(tcr_loc_dict_to_use[cl])\n",
    "        all_reads_deduped += len_this_cl\n",
    "        aggregated_total_umi += len_this_cl\n",
    "        puck.tcr_fraction[cl] = len_this_cl\n",
    "        if cl not in aggregated_fraction:\n",
    "            aggregated_fraction[cl] = 0\n",
    "        aggregated_fraction[cl] += len_this_cl\n",
    "    for cl in tcr_loc_dict_to_use:\n",
    "        puck.tcr_fraction[cl] = puck.tcr_fraction[cl] / all_reads_deduped\n",
    "\n",
    "    for cl in tcr_loc_dict_to_use:\n",
    "        if cl in post_betas:\n",
    "            bulk_val.append(post_beta_freq[post_betas.index(cl)])\n",
    "            puck_val.append(puck.tcr_fraction[cl])\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(bulk_val, puck_val, alpha=0.3)\n",
    "    plt.xlabel('Bulk fraction')\n",
    "    plt.ylabel('Slide-seq fraction')\n",
    "    abline(\n",
    "        scipy.stats.linregress(bulk_val, puck_val)[0],\n",
    "        scipy.stats.linregress(bulk_val, puck_val)[1])\n",
    "    print('r',\n",
    "          scipy.stats.linregress(bulk_val, puck_val)[2], 'pval',\n",
    "          scipy.stats.linregress(bulk_val, puck_val)[3])\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "\n",
    "# Plot aggregated plot\n",
    "agg_puck_val = []\n",
    "agg_bulk_val = []\n",
    "for cl in aggregated_fraction:\n",
    "    if cl not in post_betas:\n",
    "        #print('missing in bulk',cl)\n",
    "        continue\n",
    "    if aggregated_fraction[cl] <= 10:  ## if the number is <= 1\n",
    "        continue\n",
    "#     if post_beta_freq[post_betas.index(cl)] <= 1: ## if the number is <= 1\n",
    "#         continue\n",
    "    aggregated_fraction[cl] = aggregated_fraction[cl] / aggregated_total_umi\n",
    "    agg_puck_val.append(aggregated_fraction[cl])\n",
    "    agg_bulk_val.append(post_beta_freq[post_betas.index(cl)])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(agg_bulk_val, agg_puck_val, alpha=0.3)\n",
    "ax.set_xlabel('Bulk fraction')\n",
    "ax.set_ylabel('Slide-seq fraction')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "abline(\n",
    "    scipy.stats.linregress(agg_bulk_val, agg_puck_val)[0],\n",
    "    scipy.stats.linregress(agg_bulk_val, agg_puck_val)[1])\n",
    "logx = np.log10(agg_bulk_val)\n",
    "logy = np.log10(agg_puck_val)\n",
    "print('r',\n",
    "      scipy.stats.linregress(logx, logy)[2], 'pval',\n",
    "      scipy.stats.linregress(logx, logy)[3])\n",
    "print(scipy.stats.linregress(logx, logy))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "ax.scatter(logx, logy, alpha=0.5)\n",
    "ax.set_xlabel('log(bulk fraction)')\n",
    "ax.set_ylabel('log(Slide-seq fraction)')\n",
    "axes = plt.gca()\n",
    "x_vals = np.array(axes.get_xlim())\n",
    "y_vals = scipy.stats.linregress(\n",
    "    logx, logy)[1] + scipy.stats.linregress(logx, logy)[0] * x_vals\n",
    "ax.plot(x_vals, y_vals, '--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure2f.pdf')\n",
    "plt.show()\n",
    "\n",
    "print('r',\n",
    "      scipy.stats.linregress(logx, logy)[2], 'pval',\n",
    "      scipy.stats.linregress(logx, logy)[3])\n",
    "print(scipy.stats.linregress(logx, logy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot bulk fraction against Slide-seq fraction for POST\n",
    "pre_betas = list(pre_bulk_beta.cdr3)\n",
    "pre_beta_freq = list(pre_bulk_beta.Freq)\n",
    "\n",
    "aggregated_total_umi = 0\n",
    "aggregated_fraction = {}\n",
    "for puck in [puck12, puck13]:\n",
    "    bulk_val = []\n",
    "    puck_val = []\n",
    "    all_reads_deduped = 0\n",
    "    tcr_loc_dict_to_use = puck.tcr_loc_dict_s1_filtered3\n",
    "    puck.tcr_fraction = {}\n",
    "\n",
    "    for cl in tcr_loc_dict_to_use:\n",
    "        len_this_cl = len(tcr_loc_dict_to_use[cl])\n",
    "        all_reads_deduped += len_this_cl\n",
    "        aggregated_total_umi += len_this_cl\n",
    "        puck.tcr_fraction[cl] = len_this_cl\n",
    "        if cl not in aggregated_fraction:\n",
    "            aggregated_fraction[cl] = 0\n",
    "        aggregated_fraction[cl] += len_this_cl\n",
    "    for cl in tcr_loc_dict_to_use:\n",
    "        puck.tcr_fraction[cl] = puck.tcr_fraction[cl] / all_reads_deduped\n",
    "\n",
    "    for cl in tcr_loc_dict_to_use:\n",
    "        if cl in pre_betas:\n",
    "            bulk_val.append(pre_beta_freq[pre_betas.index(cl)])\n",
    "            puck_val.append(puck.tcr_fraction[cl])\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(bulk_val, puck_val, alpha=0.3)\n",
    "    plt.xlabel('Bulk fraction')\n",
    "    plt.ylabel('Slide-seq fraction')\n",
    "    abline(\n",
    "        scipy.stats.linregress(bulk_val, puck_val)[0],\n",
    "        scipy.stats.linregress(bulk_val, puck_val)[1])\n",
    "    print('r',\n",
    "          scipy.stats.linregress(bulk_val, puck_val)[2], 'pval',\n",
    "          scipy.stats.linregress(bulk_val, puck_val)[3])\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "\n",
    "# Plot aggregated plot\n",
    "agg_puck_val = []\n",
    "agg_bulk_val = []\n",
    "for cl in aggregated_fraction:\n",
    "    if cl not in pre_betas:\n",
    "        #print('missing in bulk',cl)\n",
    "        continue\n",
    "    aggregated_fraction[cl] = aggregated_fraction[cl] / aggregated_total_umi\n",
    "    agg_puck_val.append(aggregated_fraction[cl])\n",
    "    agg_bulk_val.append(pre_beta_freq[pre_betas.index(cl)])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(agg_bulk_val, agg_puck_val, alpha=0.3)\n",
    "plt.xlabel('Bulk fraction')\n",
    "plt.ylabel('Slide-seq fraction')\n",
    "abline(\n",
    "    scipy.stats.linregress(agg_bulk_val, agg_puck_val)[0],\n",
    "    scipy.stats.linregress(agg_bulk_val, agg_puck_val)[1])\n",
    "print('r',\n",
    "      scipy.stats.linregress(agg_bulk_val, agg_puck_val)[2], 'pval',\n",
    "      scipy.stats.linregress(agg_bulk_val, agg_puck_val)[3])\n",
    "\n",
    "\n",
    "plt.axis('scaled')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cl_agg_list_post = []\n",
    "for cl in puck8.tcr_loc_dict_s1_filtered3:\n",
    "    cl_agg_list_post = cl_agg_list_post + [cl] * len(\n",
    "        puck8.tcr_loc_dict_s1_filtered3[cl])\n",
    "for cl in puck9.tcr_loc_dict_s1_filtered3:\n",
    "    cl_agg_list_post = cl_agg_list_post + [cl] * len(\n",
    "        puck9.tcr_loc_dict_s1_filtered3[cl])\n",
    "for cl in puck10.tcr_loc_dict_s1_filtered3:\n",
    "    cl_agg_list_post = cl_agg_list_post + [cl] * len(\n",
    "        puck10.tcr_loc_dict_s1_filtered3[cl])\n",
    "\n",
    "# cl_agg_list_pre = []\n",
    "# for cl in puck12.tcr_loc_dict_s1_filtered3:\n",
    "#     cl_agg_list_pre = cl_agg_list_pre + [cl] *len(puck12.tcr_loc_dict_s1_filtered3[cl])\n",
    "# for cl in puck13.tcr_loc_dict_s1_filtered3:\n",
    "#     cl_agg_list_pre = cl_agg_list_pre + [cl] *len(puck13.tcr_loc_dict_s1_filtered3[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_post_not_pre = []\n",
    "in_both = []\n",
    "in_pre_not_post = []\n",
    "not_in_any = []\n",
    "total_ct = 0\n",
    "alpha = 0\n",
    "all_cls = list(\n",
    "    set(\n",
    "        list([\n",
    "            i for i in puck8.tcr_loc_dict_s1_filtered3\n",
    "            if len(set(puck8.tcr_loc_dict_s1_filtered3[i])) > 10\n",
    "        ]) + list([\n",
    "            i for i in puck9.tcr_loc_dict_s1_filtered3\n",
    "            if len(set(puck9.tcr_loc_dict_s1_filtered3[i])) > 10\n",
    "        ]) + list([\n",
    "            i for i in puck10.tcr_loc_dict_s1_filtered3\n",
    "            if len(set(puck10.tcr_loc_dict_s1_filtered3[i])) > 10\n",
    "        ])))\n",
    "for cl in all_cls:\n",
    "    total_ct += 1\n",
    "    pre_beta = False\n",
    "    pre_alpha = False\n",
    "    post_beta = False\n",
    "    post_alpha = False\n",
    "    if cl in list(pre_bulk_beta.cdr3):\n",
    "        pre_beta = True\n",
    "    if cl in list(pre_bulk_alpha.cdr3):\n",
    "        pre_alpha = True\n",
    "    if cl in list(post_bulk_alpha.cdr3):\n",
    "        post_alpha = True\n",
    "    if cl in list(post_bulk_beta.cdr3):\n",
    "        post_beta = True\n",
    "\n",
    "    if pre_beta and pre_alpha:\n",
    "        print('weird, prebeta and prealpha')\n",
    "    if pre_beta and post_alpha:\n",
    "        print('weird, prebeta and postalpha')\n",
    "    if post_beta and pre_alpha:\n",
    "        print('weird, postbeta, prealpha')\n",
    "    if post_beta and post_alpha:\n",
    "        print('weird, postbeta, post alpha')\n",
    "        print(cl)\n",
    "        continue\n",
    "    if (pre_beta and post_beta):\n",
    "        #print('Present in both')\n",
    "        in_both.append(cl)\n",
    "    if (pre_beta and not post_beta):\n",
    "        #print('in pre but not in post')\n",
    "        in_pre_not_post.append(cl)\n",
    "    if (post_beta and not pre_beta):\n",
    "        #print('in post but not in pre')\n",
    "        in_post_not_pre.append(cl)\n",
    "    if (pre_alpha or post_alpha):\n",
    "        alpha += 1\n",
    "    if (not pre_beta and not pre_alpha and not post_beta and not post_alpha):\n",
    "        not_in_any.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Aggregated\n",
    "# Clonotype Analysis Plot\n",
    "#x = list(merged_p_df[region]) # not normalized by expected\n",
    "\n",
    "lung_enrichment_in_both = []\n",
    "lung_enrichment_in_post_not_pre = []\n",
    "til_enrichment_in_both = []\n",
    "til_enrichment_in_post_not_pre = []\n",
    "tumor_enrichment_in_both = []\n",
    "tumor_enrichment_in_post_not_pre = []\n",
    "\n",
    "for cl in list(df_to_plot.clonotype):\n",
    "\n",
    "    if cl in in_both:\n",
    "        #         lung_enrichment_in_both = lung_enrichment_in_both + [all_x_ltt[idx] for idx in shared_indices]\n",
    "        #         til_enrichment_in_both = til_enrichment_in_both + [all_y_ltt[idx] for idx in shared_indices]\n",
    "        tumor_enrichment_in_both.append(\n",
    "            float(df_to_plot[df_to_plot.clonotype == cl].Tumor))\n",
    "\n",
    "    if cl in in_post_not_pre:\n",
    "        #         lung_enrichment_in_post_not_pre = lung_enrichment_in_post_not_pre + [all_x_ltt[idx] for idx in shared_indices]\n",
    "        #         til_enrichment_in_post_not_pre = til_enrichment_in_post_not_pre + [all_y_ltt[idx] for idx in shared_indices]\n",
    "        tumor_enrichment_in_post_not_pre.append(\n",
    "            float(df_to_plot[df_to_plot.clonotype == cl].Tumor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    scipy.stats.ttest_ind(tumor_enrichment_in_both,\n",
    "                          tumor_enrichment_in_post_not_pre))\n",
    "# print(scipy.stats.ttest_ind(lung_enrichment_in_both,lung_enrichment_in_post_not_pre))\n",
    "# print(scipy.stats.ttest_ind(til_enrichment_in_both,til_enrichment_in_post_not_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(5, 3))\n",
    "status = ['New'] * len(tumor_enrichment_in_post_not_pre) + ['Existing'] * len(\n",
    "    tumor_enrichment_in_both)\n",
    "value = tumor_enrichment_in_post_not_pre + tumor_enrichment_in_both\n",
    "enrichment_vs_cl_status_df = pd.DataFrame.from_dict({\n",
    "    'status': status,\n",
    "    'tumor_enrichment': value\n",
    "})\n",
    "sns.violinplot(x=\"status\",\n",
    "               y=\"tumor_enrichment\",\n",
    "               data=enrichment_vs_cl_status_df)\n",
    "sns.swarmplot(x=\"status\",\n",
    "              y=\"tumor_enrichment\",\n",
    "              data=enrichment_vs_cl_status_df,\n",
    "              color=\".25\",\n",
    "              size=6)\n",
    "\n",
    "# statistical annotation\n",
    "x1, x2 = 0, 1  # columns 'Sat' and 'Sun' (first column: 0, see plt.xticks())\n",
    "y, h, col = enrichment_vs_cl_status_df['tumor_enrichment'].max(\n",
    ") + 0.1, 0.03, 'k'\n",
    "y = y + 0.4\n",
    "plt.plot([x1, x1, x2, x2], [y, y + h, y + h, y], lw=1.5, c=col)\n",
    "plt.text((x1 + x2) * .5,\n",
    "         y + h,\n",
    "         \"p>0.05\",\n",
    "         ha='center',\n",
    "         va='bottom',\n",
    "         color=col,\n",
    "         size=20)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.xlabel('Clonotype status')\n",
    "plt.ylabel('Mean fractional \\n tumor enrichment')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure2i.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    len(enrichment_vs_cl_status_df[enrichment_vs_cl_status_df.status ==\n",
    "                                   'Existing']))\n",
    "print(\n",
    "    len(enrichment_vs_cl_status_df[enrichment_vs_cl_status_df.status ==\n",
    "                                   'New']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clonotype enrichment vs percentage of bulk\n",
    "cl_to_freq_dict = dict(zip(list(post_bulk_beta.cdr3), list(post_bulk_beta.Freq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "df_to_plot = df_to_plot[df_to_plot.clonotype.isin(cl_to_freq_dict)]\n",
    "\n",
    "freq = []\n",
    "\n",
    "tumor_enrichment = list(df_to_plot.Tumor)\n",
    "freq = [cl_to_freq_dict[cl] for cl in list(df_to_plot.clonotype)]\n",
    "log_freq = [np.log10(i) for i in freq]\n",
    "plot_df = pd.DataFrame.from_dict({\n",
    "    'tumor': tumor_enrichment,\n",
    "    'log_freq': log_freq\n",
    "})\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.scatterplot(x='log_freq', y='tumor', data=plot_df, s=60, alpha=0.5)\n",
    "plt.ylabel('Mean fractional \\n tumor enrichment')\n",
    "plt.xlabel('log(bulk fraction)')\n",
    "print('r',\n",
    "      scipy.stats.linregress(log_freq, tumor_enrichment)[2], 'pval',\n",
    "      scipy.stats.linregress(log_freq, tumor_enrichment)[3])\n",
    "print(scipy.stats.linregress(log_freq, tumor_enrichment))\n",
    "plt.tight_layout()\n",
    "plt.savefig('./vectorized_figures/figure2j.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
